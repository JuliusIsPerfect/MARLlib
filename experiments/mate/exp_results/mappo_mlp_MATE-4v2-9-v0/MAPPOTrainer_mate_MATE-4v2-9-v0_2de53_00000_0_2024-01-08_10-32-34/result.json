{"episode_reward_max": -600.0, "episode_reward_min": -600.0, "episode_reward_mean": -600.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -300.0}, "policy_reward_mean": {"shared_policy": -300.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0], "episode_lengths": [10001], "policy_shared_policy_reward": [-300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18620306262671485, "mean_inference_ms": 1.0023533561862557, "mean_action_processing_ms": 0.05352385645717104, "mean_env_wait_ms": 7.374054968020337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timesteps_this_iter": 0, "agent_timesteps_total": 40000, "timers": {"sample_time_ms": 172775.42, "sample_throughput": 115.757, "load_time_ms": 0.997, "load_throughput": 20058842.659, "learn_time_ms": 4414.905, "learn_throughput": 4530.109, "update_time_ms": 1.966}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 0.0005, "total_loss": 195.0217712402344, "policy_loss": -0.0029788305186480234, "vf_loss": 195.0563201904297, "vf_explained_var": 0.0008224844932556152, "kl": 0.0029872208885223794, "entropy": 3.215794086456299, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 20000, "num_agent_steps_sampled": 40000, "num_steps_trained": 20000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 1, "training_iteration": 1, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-35-37", "timestamp": 1704681337, "time_this_iter_s": 177.15321731567383, "time_total_s": 177.15321731567383, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017D5EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 177.15321731567383, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 19.16414342629482, "ram_util_percent": 48.55059760956175}}
{"episode_reward_max": -600.0, "episode_reward_min": -600.0, "episode_reward_mean": -600.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -300.0}, "policy_reward_mean": {"shared_policy": -300.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20137410786762086, "mean_inference_ms": 1.039239222148318, "mean_action_processing_ms": 0.054415926921079404, "mean_env_wait_ms": 7.4512978592445505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 40000, "timesteps_this_iter": 0, "agent_timesteps_total": 80000, "timers": {"sample_time_ms": 178863.345, "sample_throughput": 111.817, "load_time_ms": 0.997, "load_throughput": 20063640.277, "learn_time_ms": 5221.565, "learn_throughput": 3830.269, "update_time_ms": 2.721}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 0.0005, "total_loss": 156.92011108398438, "policy_loss": -0.0017176436931826355, "vf_loss": 156.95369567871094, "vf_explained_var": 0.0033866167068481445, "kl": 0.001759702238800276, "entropy": 3.2030989646911623, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 40000, "num_agent_steps_sampled": 80000, "num_steps_trained": 40000, "num_agent_steps_trained": 80000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3, "training_iteration": 2, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-38-43", "timestamp": 1704681523, "time_this_iter_s": 186.55389833450317, "time_total_s": 363.707115650177, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301808310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 363.707115650177, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 29.04452830188679, "ram_util_percent": 50.21886792452831}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -560.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -280.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21257960355907884, "mean_inference_ms": 1.0714322422722389, "mean_action_processing_ms": 0.055518933602313844, "mean_env_wait_ms": 7.511080785722799, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 60000, "timesteps_this_iter": 0, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 184071.707, "sample_throughput": 108.653, "load_time_ms": 0.83, "load_throughput": 24100578.433, "learn_time_ms": 5654.842, "learn_throughput": 3536.792, "update_time_ms": 2.641}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 0.0005, "total_loss": 124.58780517578126, "policy_loss": -0.0016513894854672361, "vf_loss": 124.62130126953124, "vf_explained_var": 0.006478464603424073, "kl": 0.0014512570584295226, "entropy": 3.1924845695495607, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 120000, "num_steps_trained": 60000, "num_agent_steps_trained": 120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5, "training_iteration": 3, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-41-58", "timestamp": 1704681718, "time_this_iter_s": 194.9142644405365, "time_total_s": 558.6213800907135, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301987C10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 558.6213800907135, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 37.61600000000001, "ram_util_percent": 70.2949090909091}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -485.7142857142857, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -242.85714285714286}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22114028590952106, "mean_inference_ms": 1.0940310667528041, "mean_action_processing_ms": 0.05668695913622124, "mean_env_wait_ms": 7.554663931656308, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 80000, "timesteps_this_iter": 0, "agent_timesteps_total": 160000, "timers": {"sample_time_ms": 187024.043, "sample_throughput": 106.938, "load_time_ms": 0.622, "load_throughput": 32134104.578, "learn_time_ms": 5445.291, "learn_throughput": 3672.898, "update_time_ms": 2.481}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 0.0005, "total_loss": 194.04120788574218, "policy_loss": -0.0011152282959316028, "vf_loss": 194.07427368164062, "vf_explained_var": 0.0074737310409545895, "kl": 0.0009372678763440945, "entropy": 3.198210906982422, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 80000, "num_agent_steps_sampled": 160000, "num_steps_trained": 80000, "num_agent_steps_trained": 160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7, "training_iteration": 4, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-45-13", "timestamp": 1704681913, "time_this_iter_s": 194.12391829490662, "time_total_s": 752.7452983856201, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019870D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 752.7452983856201, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 31.706909090909097, "ram_util_percent": 77.80836363636364}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -466.6666666666667, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -233.33333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22655286488237047, "mean_inference_ms": 1.1078267360838383, "mean_action_processing_ms": 0.057428884528901256, "mean_env_wait_ms": 7.5794656148737705, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 100000, "timesteps_this_iter": 0, "agent_timesteps_total": 200000, "timers": {"sample_time_ms": 187370.322, "sample_throughput": 106.74, "load_time_ms": 0.597, "load_throughput": 33487457.086, "learn_time_ms": 5323.04, "learn_throughput": 3757.251, "update_time_ms": 2.277}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 0.0005, "total_loss": 96.17865753173828, "policy_loss": -0.0011474703795928854, "vf_loss": 96.21161804199218, "vf_explained_var": 0.017821431159973145, "kl": 0.0014251113360451485, "entropy": 3.1830371379852296, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 100000, "num_agent_steps_sampled": 200000, "num_steps_trained": 100000, "num_agent_steps_trained": 200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9, "training_iteration": 5, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-48-21", "timestamp": 1704682101, "time_this_iter_s": 188.73825454711914, "time_total_s": 941.4835529327393, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 941.4835529327393, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 25.45676691729323, "ram_util_percent": 81.52330827067668}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -472.72727272727275, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -236.36363636363637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22979890616584814, "mean_inference_ms": 1.116144812540987, "mean_action_processing_ms": 0.05786505327633829, "mean_env_wait_ms": 7.595353496407589, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 120000, "timesteps_this_iter": 0, "agent_timesteps_total": 240000, "timers": {"sample_time_ms": 187380.378, "sample_throughput": 106.735, "load_time_ms": 0.498, "load_throughput": 40184948.503, "learn_time_ms": 5264.438, "learn_throughput": 3799.076, "update_time_ms": 2.142}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 0.0005, "total_loss": 141.98079833984374, "policy_loss": -0.0013731833111494396, "vf_loss": 142.01405639648436, "vf_explained_var": 0.021070313453674317, "kl": 0.0019934496778704846, "entropy": 3.1904510974884035, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 120000, "num_agent_steps_sampled": 240000, "num_steps_trained": 120000, "num_agent_steps_trained": 240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11, "training_iteration": 6, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-51-29", "timestamp": 1704682289, "time_this_iter_s": 187.54310631752014, "time_total_s": 1129.0266592502594, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019933A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1129.0266592502594, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 23.06578947368421, "ram_util_percent": 81.62218045112782}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -476.9230769230769, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -238.46153846153845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23211383818621545, "mean_inference_ms": 1.1214434552962729, "mean_action_processing_ms": 0.05815583223041289, "mean_env_wait_ms": 7.60582033487374, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 140000, "timesteps_this_iter": 0, "agent_timesteps_total": 280000, "timers": {"sample_time_ms": 187331.346, "sample_throughput": 106.763, "load_time_ms": 0.501, "load_throughput": 39921310.762, "learn_time_ms": 5193.453, "learn_throughput": 3851.002, "update_time_ms": 2.045}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 0.0005, "total_loss": 90.38606414794921, "policy_loss": -0.0013070090086385378, "vf_loss": 90.41924285888672, "vf_explained_var": 0.03300842046737671, "kl": 0.001747148137431953, "entropy": 3.1874104022979735, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 140000, "num_agent_steps_sampled": 280000, "num_steps_trained": 140000, "num_agent_steps_trained": 280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13, "training_iteration": 7, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-54-36", "timestamp": 1704682476, "time_this_iter_s": 186.80641055107117, "time_total_s": 1315.8330698013306, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301987670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1315.8330698013306, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 22.440530303030304, "ram_util_percent": 81.50871212121211}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.3333333333333, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.66666666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2339110562933673, "mean_inference_ms": 1.1252537627218604, "mean_action_processing_ms": 0.058346999565839684, "mean_env_wait_ms": 7.614640979647599, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 160000, "timesteps_this_iter": 0, "agent_timesteps_total": 320000, "timers": {"sample_time_ms": 187532.595, "sample_throughput": 106.648, "load_time_ms": 0.563, "load_throughput": 35518611.199, "learn_time_ms": 5217.86, "learn_throughput": 3832.989, "update_time_ms": 2.036}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 0.0005, "total_loss": 156.11190795898438, "policy_loss": -0.0011881587812118232, "vf_loss": 156.14497985839844, "vf_explained_var": 0.014607036113739013, "kl": 0.002142475795264964, "entropy": 3.1884154796600344, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 160000, "num_agent_steps_sampled": 320000, "num_steps_trained": 160000, "num_agent_steps_trained": 320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15, "training_iteration": 8, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_10-57-45", "timestamp": 1704682665, "time_this_iter_s": 189.5357735157013, "time_total_s": 1505.3688433170319, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1505.3688433170319, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 23.829477611940302, "ram_util_percent": 76.9320895522388}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -505.88235294117646, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.94117647058823}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23545760149956585, "mean_inference_ms": 1.1291173414311475, "mean_action_processing_ms": 0.05856015621852618, "mean_env_wait_ms": 7.62593679622761, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 180000, "timesteps_this_iter": 0, "agent_timesteps_total": 360000, "timers": {"sample_time_ms": 188600.266, "sample_throughput": 106.044, "load_time_ms": 0.501, "load_throughput": 39958437.599, "learn_time_ms": 5161.089, "learn_throughput": 3875.151, "update_time_ms": 2.029}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 0.0005, "total_loss": 129.15447082519532, "policy_loss": -0.0012592926245648783, "vf_loss": 129.18759765625, "vf_explained_var": 0.018180906772613525, "kl": 0.0009447523745180986, "entropy": 3.1870775699615477, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 180000, "num_agent_steps_sampled": 360000, "num_steps_trained": 180000, "num_agent_steps_trained": 360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17, "training_iteration": 9, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-01-02", "timestamp": 1704682862, "time_this_iter_s": 196.43630194664001, "time_total_s": 1701.8051452636719, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301638E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1701.8051452636719, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 31.600722021660648, "ram_util_percent": 49.705054151624545}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -505.2631578947368, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.6315789473684}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23674962051261791, "mean_inference_ms": 1.132439861363826, "mean_action_processing_ms": 0.05873416049143258, "mean_env_wait_ms": 7.635527959524241, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 200000, "timesteps_this_iter": 0, "agent_timesteps_total": 400000, "timers": {"sample_time_ms": 188799.021, "sample_throughput": 105.933, "load_time_ms": 0.45, "load_throughput": 44398263.999, "learn_time_ms": 5147.593, "learn_throughput": 3885.311, "update_time_ms": 1.926}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 0.0005, "total_loss": 127.53942108154297, "policy_loss": -0.0013829161327518547, "vf_loss": 127.57265014648438, "vf_explained_var": 0.04769539833068848, "kl": 0.0009485337965494222, "entropy": 3.184516096115112, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 200000, "num_agent_steps_sampled": 400000, "num_steps_trained": 200000, "num_agent_steps_trained": 400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19, "training_iteration": 10, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-04-13", "timestamp": 1704683053, "time_this_iter_s": 190.88066816329956, "time_total_s": 1892.6858134269714, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301739B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1892.6858134269714, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 25.8450184501845, "ram_util_percent": 53.43837638376384}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.76190476190476, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.38095238095238}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23782878978228866, "mean_inference_ms": 1.1352430911217584, "mean_action_processing_ms": 0.05888959727380725, "mean_env_wait_ms": 7.643048387090795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 220000, "timesteps_this_iter": 0, "agent_timesteps_total": 440000, "timers": {"sample_time_ms": 190419.188, "sample_throughput": 105.031, "load_time_ms": 0.351, "load_throughput": 57018814.573, "learn_time_ms": 5204.552, "learn_throughput": 3842.79, "update_time_ms": 1.926}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 0.0005, "total_loss": 186.92091674804686, "policy_loss": -0.0014035454751178734, "vf_loss": 186.95409240722657, "vf_explained_var": 0.043531036376953124, "kl": 0.0012843120350529702, "entropy": 3.1777822017669677, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 220000, "num_agent_steps_sampled": 440000, "num_steps_trained": 220000, "num_agent_steps_trained": 440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 21, "training_iteration": 11, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-07-22", "timestamp": 1704683242, "time_this_iter_s": 188.9073293209076, "time_total_s": 2081.593142747879, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301759820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2081.593142747879, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 23.077902621722842, "ram_util_percent": 52.25767790262172}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.6521739130435, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.82608695652175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2387369678764891, "mean_inference_ms": 1.1374780601837438, "mean_action_processing_ms": 0.05900142621156008, "mean_env_wait_ms": 7.648883611148427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 240000, "timesteps_this_iter": 0, "agent_timesteps_total": 480000, "timers": {"sample_time_ms": 190708.825, "sample_throughput": 104.872, "load_time_ms": 0.251, "load_throughput": 79648765.667, "learn_time_ms": 5071.005, "learn_throughput": 3943.992, "update_time_ms": 1.778}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005, "total_loss": 79.04978485107422, "policy_loss": -0.0012361654642037757, "vf_loss": 79.08260498046874, "vf_explained_var": 0.08043152093887329, "kl": 0.0015202705194910405, "entropy": 3.15852575302124, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 240000, "num_agent_steps_sampled": 480000, "num_steps_trained": 240000, "num_agent_steps_trained": 480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 23, "training_iteration": 12, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-10-29", "timestamp": 1704683429, "time_this_iter_s": 187.53361010551453, "time_total_s": 2269.1267528533936, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2269.1267528533936, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 23.69471698113208, "ram_util_percent": 53.44150943396227}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -488.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23934284060866773, "mean_inference_ms": 1.1387142548711013, "mean_action_processing_ms": 0.05906474479713952, "mean_env_wait_ms": 7.651270335358026, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 260000, "timesteps_this_iter": 0, "agent_timesteps_total": 520000, "timers": {"sample_time_ms": 189041.124, "sample_throughput": 105.797, "load_time_ms": 0.202, "load_throughput": 99249976.337, "learn_time_ms": 4873.105, "learn_throughput": 4104.16, "update_time_ms": 1.827}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005, "total_loss": 115.5994857788086, "policy_loss": -0.0009863630565629222, "vf_loss": 115.63199615478516, "vf_explained_var": 0.09989645481109619, "kl": 0.0016279432050271935, "entropy": 3.151962089538574, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 260000, "num_agent_steps_sampled": 520000, "num_steps_trained": 260000, "num_agent_steps_trained": 520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 25, "training_iteration": 13, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-13-27", "timestamp": 1704683607, "time_this_iter_s": 177.63219451904297, "time_total_s": 2446.7589473724365, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F50D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2446.7589473724365, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 19.111507936507937, "ram_util_percent": 53.603571428571435}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -481.48148148148147, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -240.74074074074073}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23973193535531354, "mean_inference_ms": 1.1390592578587198, "mean_action_processing_ms": 0.05909002146386195, "mean_env_wait_ms": 7.651652360149923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 280000, "timesteps_this_iter": 0, "agent_timesteps_total": 560000, "timers": {"sample_time_ms": 187272.787, "sample_throughput": 106.796, "load_time_ms": 0.202, "load_throughput": 99249976.337, "learn_time_ms": 4842.209, "learn_throughput": 4130.346, "update_time_ms": 1.923}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 0.0005, "total_loss": 64.33047637939453, "policy_loss": -0.0012574136756640097, "vf_loss": 64.36346206665038, "vf_explained_var": 0.1444694995880127, "kl": 0.0015059145507130723, "entropy": 3.1725330352783203, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 280000, "num_agent_steps_sampled": 560000, "num_steps_trained": 280000, "num_agent_steps_trained": 560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 27, "training_iteration": 14, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-16-25", "timestamp": 1704683785, "time_this_iter_s": 178.13529777526855, "time_total_s": 2624.894245147705, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016B5670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2624.894245147705, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 18.415079365079364, "ram_util_percent": 52.95238095238094}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -475.86206896551727, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -237.93103448275863}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23999464839833448, "mean_inference_ms": 1.1388935035118608, "mean_action_processing_ms": 0.05908211855243089, "mean_env_wait_ms": 7.650335575351041, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 300000, "timesteps_this_iter": 0, "agent_timesteps_total": 600000, "timers": {"sample_time_ms": 186133.743, "sample_throughput": 107.45, "load_time_ms": 0.152, "load_throughput": 131709970.168, "learn_time_ms": 4807.204, "learn_throughput": 4160.423, "update_time_ms": 2.074}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 0.0005, "total_loss": 106.70336608886718, "policy_loss": -0.000920571790467939, "vf_loss": 106.73607635498047, "vf_explained_var": 0.12797397375106812, "kl": 0.002257171821404924, "entropy": 3.1789769172668456, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 300000, "num_agent_steps_sampled": 600000, "num_steps_trained": 300000, "num_agent_steps_trained": 600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 29, "training_iteration": 15, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-19-22", "timestamp": 1704683962, "time_this_iter_s": 177.31516408920288, "time_total_s": 2802.209409236908, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F54C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2802.209409236908, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 19.139840637450202, "ram_util_percent": 52.197211155378476}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -477.4193548387097, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -238.70967741935485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24015584812703603, "mean_inference_ms": 1.1384497086803744, "mean_action_processing_ms": 0.05906877902733117, "mean_env_wait_ms": 7.648049915804689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 320000, "timesteps_this_iter": 0, "agent_timesteps_total": 640000, "timers": {"sample_time_ms": 185273.757, "sample_throughput": 107.948, "load_time_ms": 0.254, "load_throughput": 78795866.992, "learn_time_ms": 4822.517, "learn_throughput": 4147.212, "update_time_ms": 2.124}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005, "total_loss": 109.857177734375, "policy_loss": -0.0015231566101126359, "vf_loss": 109.89057922363281, "vf_explained_var": 0.11907650232315063, "kl": 0.001851011941004721, "entropy": 3.18727331161499, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 320000, "num_agent_steps_sampled": 640000, "num_steps_trained": 320000, "num_agent_steps_trained": 640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 31, "training_iteration": 16, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-22-22", "timestamp": 1704684142, "time_this_iter_s": 179.4443974494934, "time_total_s": 2981.6538066864014, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2981.6538066864014, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 21.513779527559056, "ram_util_percent": 52.36220472440944}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -478.7878787878788, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -239.3939393939394}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24031687806958746, "mean_inference_ms": 1.1378735535719156, "mean_action_processing_ms": 0.05905087833923141, "mean_env_wait_ms": 7.645917056726803, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 340000, "timesteps_this_iter": 0, "agent_timesteps_total": 680000, "timers": {"sample_time_ms": 185051.385, "sample_throughput": 108.078, "load_time_ms": 0.202, "load_throughput": 99132687.308, "learn_time_ms": 4825.007, "learn_throughput": 4145.072, "update_time_ms": 2.177}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005, "total_loss": 97.7150634765625, "policy_loss": -0.0008596791565324225, "vf_loss": 97.747802734375, "vf_explained_var": 0.1434245824813843, "kl": 0.0013446341421722075, "entropy": 3.1881292819976808, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 340000, "num_agent_steps_sampled": 680000, "num_steps_trained": 340000, "num_agent_steps_trained": 680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 33, "training_iteration": 17, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-25-26", "timestamp": 1704684326, "time_this_iter_s": 184.45582246780396, "time_total_s": 3166.1096291542053, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D30199F430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3166.1096291542053, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 20.321455938697316, "ram_util_percent": 55.07241379310344}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.2857142857143, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -237.14285714285714}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24044191254554467, "mean_inference_ms": 1.1372272443568006, "mean_action_processing_ms": 0.05903447471890754, "mean_env_wait_ms": 7.643790705252347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 360000, "timesteps_this_iter": 0, "agent_timesteps_total": 720000, "timers": {"sample_time_ms": 184516.473, "sample_throughput": 108.391, "load_time_ms": 0.202, "load_throughput": 99167844.899, "learn_time_ms": 4748.907, "learn_throughput": 4211.495, "update_time_ms": 2.08}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005, "total_loss": 116.6482666015625, "policy_loss": -0.001269271998489252, "vf_loss": 116.6813949584961, "vf_explained_var": 0.12472013235092164, "kl": 0.001992640982547522, "entropy": 3.1864460945129394, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 360000, "num_agent_steps_sampled": 720000, "num_steps_trained": 360000, "num_agent_steps_trained": 720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 35, "training_iteration": 18, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-28-30", "timestamp": 1704684510, "time_this_iter_s": 183.40202069282532, "time_total_s": 3349.5116498470306, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016ADB80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3349.5116498470306, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 19.543243243243246, "ram_util_percent": 55.29382239382239}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -481.0810810810811, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -240.54054054054055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24049902276121113, "mean_inference_ms": 1.1364799422031666, "mean_action_processing_ms": 0.05901508498659515, "mean_env_wait_ms": 7.6415395116448845, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 380000, "timesteps_this_iter": 0, "agent_timesteps_total": 760000, "timers": {"sample_time_ms": 182967.208, "sample_throughput": 109.309, "load_time_ms": 0.202, "load_throughput": 99167844.899, "learn_time_ms": 4741.027, "learn_throughput": 4218.496, "update_time_ms": 1.984}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 0.0005, "total_loss": 104.30464782714844, "policy_loss": -0.0008837153398897791, "vf_loss": 104.33739318847657, "vf_explained_var": 0.14018741846084595, "kl": 0.001378023812608742, "entropy": 3.1866568088531495, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 380000, "num_agent_steps_sampled": 760000, "num_steps_trained": 380000, "num_agent_steps_trained": 760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 37, "training_iteration": 19, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-31-31", "timestamp": 1704684691, "time_this_iter_s": 181.62069272994995, "time_total_s": 3531.1323425769806, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301993AF0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3531.1323425769806, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 18.8431906614786, "ram_util_percent": 54.67859922178988}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -482.05128205128204, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -241.02564102564102}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24073834685513218, "mean_inference_ms": 1.1368978115105972, "mean_action_processing_ms": 0.05903900273218351, "mean_env_wait_ms": 7.642874051234694, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 400000, "timesteps_this_iter": 0, "agent_timesteps_total": 800000, "timers": {"sample_time_ms": 186120.513, "sample_throughput": 107.457, "load_time_ms": 0.301, "load_throughput": 66470744.849, "learn_time_ms": 5111.37, "learn_throughput": 3912.845, "update_time_ms": 2.084}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 0.0005, "total_loss": 98.83206329345703, "policy_loss": -0.0012734318203292626, "vf_loss": 98.8652099609375, "vf_explained_var": 0.1759057402610779, "kl": 0.0007149923750386477, "entropy": 3.186594009399414, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 400000, "num_agent_steps_sampled": 800000, "num_steps_trained": 400000, "num_agent_steps_trained": 800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 39, "training_iteration": 20, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-35-18", "timestamp": 1704684918, "time_this_iter_s": 226.2064085006714, "time_total_s": 3757.338751077652, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301993820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3757.338751077652, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 38.990909090909085, "ram_util_percent": 55.03730407523511}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -482.9268292682927, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -241.46341463414635}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24147930707457663, "mean_inference_ms": 1.1397334509822576, "mean_action_processing_ms": 0.05915010571214832, "mean_env_wait_ms": 7.651444985229583, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 420000, "timesteps_this_iter": 0, "agent_timesteps_total": 840000, "timers": {"sample_time_ms": 195385.902, "sample_throughput": 102.362, "load_time_ms": 0.301, "load_throughput": 66470744.849, "learn_time_ms": 5418.919, "learn_throughput": 3690.773, "update_time_ms": 1.987}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005, "total_loss": 81.93728790283203, "policy_loss": -0.0014400275157205656, "vf_loss": 81.97058563232422, "vf_explained_var": 0.1913703203201294, "kl": 0.0008711224770069581, "entropy": 3.185982847213745, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 420000, "num_agent_steps_sampled": 840000, "num_steps_trained": 420000, "num_agent_steps_trained": 840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 41, "training_iteration": 21, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-39-59", "timestamp": 1704685199, "time_this_iter_s": 280.8765637874603, "time_total_s": 4038.2153148651123, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F53A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4038.2153148651123, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 54.50253164556962, "ram_util_percent": 54.64835443037974}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -488.3720930232558, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.1860465116279}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24214077805377163, "mean_inference_ms": 1.1422112930932882, "mean_action_processing_ms": 0.05924821947035717, "mean_env_wait_ms": 7.659091075785067, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 440000, "timesteps_this_iter": 0, "agent_timesteps_total": 880000, "timers": {"sample_time_ms": 195891.692, "sample_throughput": 102.097, "load_time_ms": 0.301, "load_throughput": 66470744.849, "learn_time_ms": 5401.609, "learn_throughput": 3702.6, "update_time_ms": 1.983}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005, "total_loss": 91.47310943603516, "policy_loss": -0.0016177043639496347, "vf_loss": 91.50595092773438, "vf_explained_var": 0.168309223651886, "kl": 0.00288835593500687, "entropy": 3.123334550857544, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 440000, "num_agent_steps_sampled": 880000, "num_steps_trained": 440000, "num_agent_steps_trained": 880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 43, "training_iteration": 22, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-43-08", "timestamp": 1704685388, "time_this_iter_s": 189.33662509918213, "time_total_s": 4227.551939964294, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AFCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4227.551939964294, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 23.95634328358209, "ram_util_percent": 51.46305970149253}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -484.44444444444446, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -242.22222222222223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24267593028326967, "mean_inference_ms": 1.1441020454864463, "mean_action_processing_ms": 0.05932696787991684, "mean_env_wait_ms": 7.665141460834392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 460000, "timesteps_this_iter": 0, "agent_timesteps_total": 920000, "timers": {"sample_time_ms": 195845.651, "sample_throughput": 102.121, "load_time_ms": 0.301, "load_throughput": 66470744.849, "learn_time_ms": 5398.48, "learn_throughput": 3704.746, "update_time_ms": 1.787}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 0.0005, "total_loss": 130.30762329101563, "policy_loss": -0.0010388359763193965, "vf_loss": 130.3397003173828, "vf_explained_var": 0.10467360019683838, "kl": 0.0008542084672726214, "entropy": 3.104313516616821, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 460000, "num_agent_steps_sampled": 920000, "num_steps_trained": 460000, "num_agent_steps_trained": 920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 45, "training_iteration": 23, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-46-05", "timestamp": 1704685565, "time_this_iter_s": 177.31768155097961, "time_total_s": 4404.869621515274, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017D1790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4404.869621515274, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 18.422709163346614, "ram_util_percent": 50.1207171314741}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -485.1063829787234, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -242.5531914893617}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24309464398963743, "mean_inference_ms": 1.1455071778868775, "mean_action_processing_ms": 0.059387701876486836, "mean_env_wait_ms": 7.669906925808097, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 480000, "timesteps_this_iter": 0, "agent_timesteps_total": 960000, "timers": {"sample_time_ms": 195780.076, "sample_throughput": 102.155, "load_time_ms": 0.401, "load_throughput": 49914363.918, "learn_time_ms": 5395.979, "learn_throughput": 3706.464, "update_time_ms": 1.687}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005, "total_loss": 177.6518798828125, "policy_loss": -0.001583567443545908, "vf_loss": 177.68451538085938, "vf_explained_var": 0.11206032037734985, "kl": 0.0030329120715817393, "entropy": 3.1051400184631346, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 480000, "num_agent_steps_sampled": 960000, "num_steps_trained": 480000, "num_agent_steps_trained": 960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 47, "training_iteration": 24, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-49-03", "timestamp": 1704685743, "time_this_iter_s": 177.48579096794128, "time_total_s": 4582.355412483215, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301638E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4582.355412483215, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 18.174603174603174, "ram_util_percent": 49.12896825396825}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -485.7142857142857, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -242.85714285714286}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.243423766119083, "mean_inference_ms": 1.1465126206610292, "mean_action_processing_ms": 0.059427058149047605, "mean_env_wait_ms": 7.6734026271033375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 500000, "timesteps_this_iter": 0, "agent_timesteps_total": 1000000, "timers": {"sample_time_ms": 195550.942, "sample_throughput": 102.275, "load_time_ms": 0.401, "load_throughput": 49914363.918, "learn_time_ms": 5398.332, "learn_throughput": 3704.848, "update_time_ms": 1.587}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 0.0005, "total_loss": 91.25910797119141, "policy_loss": -0.0013889971256070056, "vf_loss": 91.29223327636718, "vf_explained_var": 0.22695814371109008, "kl": 0.000882911226613814, "entropy": 3.1731700897216797, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 500000, "num_agent_steps_sampled": 1000000, "num_steps_trained": 500000, "num_agent_steps_trained": 1000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 49, "training_iteration": 25, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-51-58", "timestamp": 1704685918, "time_this_iter_s": 175.07487773895264, "time_total_s": 4757.430290222168, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301987430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4757.430290222168, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 17.91532258064516, "ram_util_percent": 49.176612903225816}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.19607843137254, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.09803921568627}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2436679647557785, "mean_inference_ms": 1.1471871222695025, "mean_action_processing_ms": 0.05945506458158202, "mean_env_wait_ms": 7.675746003543085, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 520000, "timesteps_this_iter": 0, "agent_timesteps_total": 1040000, "timers": {"sample_time_ms": 195044.825, "sample_throughput": 102.541, "load_time_ms": 0.299, "load_throughput": 66953531.806, "learn_time_ms": 5337.381, "learn_throughput": 3747.156, "update_time_ms": 1.587}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 0.0005, "total_loss": 139.732275390625, "policy_loss": -0.0012080761575419484, "vf_loss": 139.7651824951172, "vf_explained_var": 0.1320023775100708, "kl": 0.0010089966228647995, "entropy": 3.169159746170044, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 520000, "num_agent_steps_sampled": 1040000, "num_steps_trained": 520000, "num_agent_steps_trained": 1040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 51, "training_iteration": 26, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-54-52", "timestamp": 1704686092, "time_this_iter_s": 173.75059700012207, "time_total_s": 4931.18088722229, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301987D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4931.18088722229, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 17.92154471544715, "ram_util_percent": 49.1178861788618}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.5660377358491, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.28301886792454}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24385269983560917, "mean_inference_ms": 1.14758442878639, "mean_action_processing_ms": 0.05947208666064412, "mean_env_wait_ms": 7.6773169166955295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 540000, "timesteps_this_iter": 0, "agent_timesteps_total": 1080000, "timers": {"sample_time_ms": 194219.261, "sample_throughput": 102.976, "load_time_ms": 0.299, "load_throughput": 66953531.806, "learn_time_ms": 5308.646, "learn_throughput": 3767.439, "update_time_ms": 1.484}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 0.0005, "total_loss": 91.3886001586914, "policy_loss": -0.0011875702022296152, "vf_loss": 91.42138214111328, "vf_explained_var": 0.2326080918312073, "kl": 0.002094983009976481, "entropy": 3.1590234279632567, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 540000, "num_agent_steps_sampled": 1080000, "num_steps_trained": 540000, "num_agent_steps_trained": 1080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 53, "training_iteration": 27, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_11-57-48", "timestamp": 1704686268, "time_this_iter_s": 176.52376222610474, "time_total_s": 5107.704649448395, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301987040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5107.704649448395, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 18.020400000000002, "ram_util_percent": 49.11320000000001}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.90909090909093, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.45454545454547}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2439833814046725, "mean_inference_ms": 1.1477537187431262, "mean_action_processing_ms": 0.05948098604262255, "mean_env_wait_ms": 7.6781518000857, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 560000, "timesteps_this_iter": 0, "agent_timesteps_total": 1120000, "timers": {"sample_time_ms": 193379.513, "sample_throughput": 103.424, "load_time_ms": 0.199, "load_throughput": 100498478.495, "learn_time_ms": 5297.644, "learn_throughput": 3775.263, "update_time_ms": 1.681}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 0.0005, "total_loss": 120.72759094238282, "policy_loss": -0.0018759325354546386, "vf_loss": 120.76114349365234, "vf_explained_var": 0.14095853567123412, "kl": 0.0017682449502950796, "entropy": 3.167894697189331, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 560000, "num_agent_steps_sampled": 1120000, "num_steps_trained": 560000, "num_agent_steps_trained": 1120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 55, "training_iteration": 28, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-00-43", "timestamp": 1704686443, "time_this_iter_s": 175.1806881427765, "time_total_s": 5282.885337591171, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5282.885337591171, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 17.77258064516129, "ram_util_percent": 49.15000000000001}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.7368421052632, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.3684210526316}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24406940247164605, "mean_inference_ms": 1.1477316909398136, "mean_action_processing_ms": 0.05948149744689297, "mean_env_wait_ms": 7.678398838765648, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 580000, "timesteps_this_iter": 0, "agent_timesteps_total": 1160000, "timers": {"sample_time_ms": 192783.523, "sample_throughput": 103.743, "load_time_ms": 0.199, "load_throughput": 100498478.495, "learn_time_ms": 5284.907, "learn_throughput": 3784.362, "update_time_ms": 1.779}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 0.0005, "total_loss": 210.49095458984374, "policy_loss": -0.0020457498842104903, "vf_loss": 210.52444152832032, "vf_explained_var": 0.14484721422195435, "kl": 0.003275233261022123, "entropy": 3.143457841873169, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 580000, "num_agent_steps_sampled": 1160000, "num_steps_trained": 580000, "num_agent_steps_trained": 1160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 57, "training_iteration": 29, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-03-39", "timestamp": 1704686619, "time_this_iter_s": 175.6477963924408, "time_total_s": 5458.533133983612, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5C10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5458.533133983612, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 18.1144578313253, "ram_util_percent": 47.771084337349414}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.91525423728814, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.45762711864407}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24411734925243164, "mean_inference_ms": 1.1475437141077975, "mean_action_processing_ms": 0.05947669973109776, "mean_env_wait_ms": 7.678125431848854, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 600000, "timesteps_this_iter": 0, "agent_timesteps_total": 1200000, "timers": {"sample_time_ms": 188083.061, "sample_throughput": 106.336, "load_time_ms": 0.2, "load_throughput": 100222317.802, "learn_time_ms": 4864.276, "learn_throughput": 4111.609, "update_time_ms": 1.677}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 0.0005, "total_loss": 55.98363723754883, "policy_loss": -0.0009149294662941232, "vf_loss": 56.01568756103516, "vf_explained_var": 0.28325202465057375, "kl": 0.0017792644986249877, "entropy": 3.1136077404022218, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 600000, "num_agent_steps_sampled": 1200000, "num_steps_trained": 600000, "num_agent_steps_trained": 1200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 59, "training_iteration": 30, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-06-34", "timestamp": 1704686794, "time_this_iter_s": 175.11423802375793, "time_total_s": 5633.64737200737, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301638E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5633.64737200737, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 17.946586345381526, "ram_util_percent": 49.26787148594378}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -491.8032786885246, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.9016393442623}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24413201500924964, "mean_inference_ms": 1.1472183864911583, "mean_action_processing_ms": 0.05946382970755481, "mean_env_wait_ms": 7.677330866899254, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 620000, "timesteps_this_iter": 0, "agent_timesteps_total": 1240000, "timers": {"sample_time_ms": 177269.325, "sample_throughput": 112.823, "load_time_ms": 0.2, "load_throughput": 100222317.802, "learn_time_ms": 4510.727, "learn_throughput": 4433.875, "update_time_ms": 1.877}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 0.0005, "total_loss": 78.85185852050782, "policy_loss": -0.0013245045016146762, "vf_loss": 78.88411560058594, "vf_explained_var": 0.2620249271392822, "kl": 0.0016541921749929855, "entropy": 3.093384265899658, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 620000, "num_agent_steps_sampled": 1240000, "num_steps_trained": 620000, "num_agent_steps_trained": 1240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 61, "training_iteration": 31, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-09-28", "timestamp": 1704686968, "time_this_iter_s": 173.47129893302917, "time_total_s": 5807.118670940399, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019A9C10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5807.118670940399, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 18.002032520325205, "ram_util_percent": 49.32601626016259}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -492.06349206349205, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.03174603174602}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.244115070101086, "mean_inference_ms": 1.1467754462891986, "mean_action_processing_ms": 0.059444950239719886, "mean_env_wait_ms": 7.676198694060383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 640000, "timesteps_this_iter": 0, "agent_timesteps_total": 1280000, "timers": {"sample_time_ms": 175525.255, "sample_throughput": 113.944, "load_time_ms": 0.2, "load_throughput": 100222317.802, "learn_time_ms": 4510.249, "learn_throughput": 4434.345, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 0.0005, "total_loss": 94.81394805908204, "policy_loss": -0.0017472648021764846, "vf_loss": 94.846484375, "vf_explained_var": 0.27241532802581786, "kl": 0.0013706141915591275, "entropy": 3.078349256515503, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 640000, "num_agent_steps_sampled": 1280000, "num_steps_trained": 640000, "num_agent_steps_trained": 1280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 63, "training_iteration": 32, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-12-23", "timestamp": 1704687143, "time_this_iter_s": 175.42663383483887, "time_total_s": 5982.545304775238, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019A9790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5982.545304775238, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 17.613709677419358, "ram_util_percent": 49.38145161290321}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -489.2307692307692, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.6153846153846}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24406782110356057, "mean_inference_ms": 1.1462419241126813, "mean_action_processing_ms": 0.059424551994773415, "mean_env_wait_ms": 7.674686732721191, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 660000, "timesteps_this_iter": 0, "agent_timesteps_total": 1320000, "timers": {"sample_time_ms": 175146.675, "sample_throughput": 114.19, "load_time_ms": 0.2, "load_throughput": 100222317.802, "learn_time_ms": 4511.425, "learn_throughput": 4433.189, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 0.0005, "total_loss": 78.84646301269531, "policy_loss": -0.002311613457836259, "vf_loss": 78.87962799072265, "vf_explained_var": 0.2649635553359985, "kl": 0.0028814171298361833, "entropy": 3.085485029220581, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 660000, "num_agent_steps_sampled": 1320000, "num_steps_trained": 660000, "num_agent_steps_trained": 1320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 65, "training_iteration": 33, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-15-17", "timestamp": 1704687317, "time_this_iter_s": 173.54856395721436, "time_total_s": 6156.093868732452, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301993D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6156.093868732452, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 17.72479674796748, "ram_util_percent": 49.423170731707295}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -486.56716417910445, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -243.28358208955223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2439961956023842, "mean_inference_ms": 1.1456261749281818, "mean_action_processing_ms": 0.05940224071843449, "mean_env_wait_ms": 7.6728587288376024, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 680000, "timesteps_this_iter": 0, "agent_timesteps_total": 1360000, "timers": {"sample_time_ms": 174744.638, "sample_throughput": 114.453, "load_time_ms": 0.202, "load_throughput": 99003989.142, "learn_time_ms": 4516.381, "learn_throughput": 4428.324, "update_time_ms": 1.694}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 0.0005, "total_loss": 97.40298919677734, "policy_loss": -0.001564344477653501, "vf_loss": 97.43571319580079, "vf_explained_var": 0.14234333038330077, "kl": 0.002030166101271025, "entropy": 3.116171884536743, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 680000, "num_agent_steps_sampled": 1360000, "num_steps_trained": 680000, "num_agent_steps_trained": 1360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 67, "training_iteration": 34, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-18-10", "timestamp": 1704687490, "time_this_iter_s": 173.50773429870605, "time_total_s": 6329.601603031158, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019871F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6329.601603031158, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 17.996341463414634, "ram_util_percent": 48.23170731707316}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -489.8550724637681, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.92753623188406}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24391062237189962, "mean_inference_ms": 1.1449402539418179, "mean_action_processing_ms": 0.05937591222445103, "mean_env_wait_ms": 7.670746394247587, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 700000, "timesteps_this_iter": 0, "agent_timesteps_total": 1400000, "timers": {"sample_time_ms": 174553.254, "sample_throughput": 114.578, "load_time_ms": 0.302, "load_throughput": 66271196.082, "learn_time_ms": 4522.415, "learn_throughput": 4422.415, "update_time_ms": 1.697}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 0.0005, "total_loss": 77.8465072631836, "policy_loss": -0.001293930408898758, "vf_loss": 77.87899475097656, "vf_explained_var": 0.25134016275405885, "kl": 0.0018099609862505695, "entropy": 3.119219207763672, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 700000, "num_agent_steps_sampled": 1400000, "num_steps_trained": 700000, "num_agent_steps_trained": 1400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 69, "training_iteration": 35, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-21-03", "timestamp": 1704687663, "time_this_iter_s": 173.16894054412842, "time_total_s": 6502.770543575287, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019A9280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6502.770543575287, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 17.78130081300813, "ram_util_percent": 49.49186991869917}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.14084507042253, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.07042253521126}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24380618009293506, "mean_inference_ms": 1.1441991765822581, "mean_action_processing_ms": 0.059347901243682916, "mean_env_wait_ms": 7.668491822221973, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 720000, "timesteps_this_iter": 0, "agent_timesteps_total": 1440000, "timers": {"sample_time_ms": 174738.859, "sample_throughput": 114.457, "load_time_ms": 0.302, "load_throughput": 66271196.082, "learn_time_ms": 4529.171, "learn_throughput": 4415.819, "update_time_ms": 1.696}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 0.0005, "total_loss": 83.31708068847657, "policy_loss": -0.0019414741338975362, "vf_loss": 83.35009307861328, "vf_explained_var": 0.2521869421005249, "kl": 0.0027725901386548733, "entropy": 3.1065413475036623, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 720000, "num_agent_steps_sampled": 1440000, "num_steps_trained": 720000, "num_agent_steps_trained": 1440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 71, "training_iteration": 36, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-23-59", "timestamp": 1704687839, "time_this_iter_s": 175.61456060409546, "time_total_s": 6678.385104179382, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6678.385104179382, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 17.96008064516129, "ram_util_percent": 49.391935483870974}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.4109589041096, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.2054794520548}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24368470030179357, "mean_inference_ms": 1.143407900207117, "mean_action_processing_ms": 0.059317674379249896, "mean_env_wait_ms": 7.666060644036444, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 740000, "timesteps_this_iter": 0, "agent_timesteps_total": 1480000, "timers": {"sample_time_ms": 174468.924, "sample_throughput": 114.634, "load_time_ms": 0.401, "load_throughput": 49813586.698, "learn_time_ms": 4531.417, "learn_throughput": 4413.63, "update_time_ms": 1.796}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 0.0005, "total_loss": 56.76881713867188, "policy_loss": -0.0013323715648986933, "vf_loss": 56.80129165649414, "vf_explained_var": 0.3148554801940918, "kl": 0.0022729534551164223, "entropy": 3.1142245292663575, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 740000, "num_agent_steps_sampled": 1480000, "num_steps_trained": 740000, "num_agent_steps_trained": 1480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 73, "training_iteration": 37, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-26-53", "timestamp": 1704688013, "time_this_iter_s": 173.77893543243408, "time_total_s": 6852.164039611816, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6852.164039611816, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 17.79554655870446, "ram_util_percent": 49.282591093117404}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.6666666666667, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.33333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2435562939868245, "mean_inference_ms": 1.1425789624606242, "mean_action_processing_ms": 0.05928667779979604, "mean_env_wait_ms": 7.663468876156342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 760000, "timesteps_this_iter": 0, "agent_timesteps_total": 1520000, "timers": {"sample_time_ms": 174326.265, "sample_throughput": 114.727, "load_time_ms": 0.401, "load_throughput": 49813586.698, "learn_time_ms": 4533.8, "learn_throughput": 4411.311, "update_time_ms": 1.8}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 0.0005, "total_loss": 87.5508041381836, "policy_loss": -0.0019037625142001246, "vf_loss": 87.58387298583985, "vf_explained_var": 0.25046714544296267, "kl": 0.0036921404787506164, "entropy": 3.115849828720093, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 760000, "num_agent_steps_sampled": 1520000, "num_steps_trained": 760000, "num_agent_steps_trained": 1520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 75, "training_iteration": 38, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-29-47", "timestamp": 1704688187, "time_this_iter_s": 173.75833082199097, "time_total_s": 7025.922370433807, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7025.922370433807, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 17.72113821138211, "ram_util_percent": 49.31747967479674}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.90909090909093, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.45454545454547}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24342058126202099, "mean_inference_ms": 1.1417231445774936, "mean_action_processing_ms": 0.05925440782262693, "mean_env_wait_ms": 7.6607463957189035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 780000, "timesteps_this_iter": 0, "agent_timesteps_total": 1560000, "timers": {"sample_time_ms": 174150.203, "sample_throughput": 114.843, "load_time_ms": 0.401, "load_throughput": 49813586.698, "learn_time_ms": 4536.676, "learn_throughput": 4408.514, "update_time_ms": 1.701}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 0.0005, "total_loss": 108.10017547607421, "policy_loss": -0.002314115481786416, "vf_loss": 108.1334716796875, "vf_explained_var": 0.24028078317642212, "kl": 0.0031255255950242145, "entropy": 3.0980085849761965, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 780000, "num_agent_steps_sampled": 1560000, "num_steps_trained": 780000, "num_agent_steps_trained": 1560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 77, "training_iteration": 39, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-32-41", "timestamp": 1704688361, "time_this_iter_s": 173.88905906677246, "time_total_s": 7199.81142950058, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F55E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7199.81142950058, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 17.98170731707317, "ram_util_percent": 48.271138211382116}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -491.1392405063291, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.56962025316454}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24327612952474106, "mean_inference_ms": 1.1408385812360278, "mean_action_processing_ms": 0.05922311005633828, "mean_env_wait_ms": 7.657887454237189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 800000, "timesteps_this_iter": 0, "agent_timesteps_total": 1600000, "timers": {"sample_time_ms": 173914.444, "sample_throughput": 114.999, "load_time_ms": 0.302, "load_throughput": 66281668.774, "learn_time_ms": 4539.091, "learn_throughput": 4406.168, "update_time_ms": 1.804}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 0.0005, "total_loss": 82.13858795166016, "policy_loss": -0.0021917186797782763, "vf_loss": 82.17154846191406, "vf_explained_var": 0.23518611192703248, "kl": 0.0040809257552819386, "entropy": 3.077131414413452, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 800000, "num_agent_steps_sampled": 1600000, "num_steps_trained": 800000, "num_agent_steps_trained": 1600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 79, "training_iteration": 40, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-35-33", "timestamp": 1704688533, "time_this_iter_s": 172.75224256515503, "time_total_s": 7372.563672065735, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3014BA160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7372.563672065735, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 17.933469387755103, "ram_util_percent": 49.26163265306122}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -491.358024691358, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.679012345679}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2431291339116499, "mean_inference_ms": 1.1399319726265038, "mean_action_processing_ms": 0.05919247100990935, "mean_env_wait_ms": 7.654923664305968, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 820000, "timesteps_this_iter": 0, "agent_timesteps_total": 1640000, "timers": {"sample_time_ms": 173890.732, "sample_throughput": 115.015, "load_time_ms": 0.302, "load_throughput": 66281668.774, "learn_time_ms": 4540.939, "learn_throughput": 4404.375, "update_time_ms": 1.603}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 0.0005, "total_loss": 80.78811492919922, "policy_loss": -0.0017188925838656833, "vf_loss": 80.82088623046874, "vf_explained_var": 0.24012633562088012, "kl": 0.0036046836560212903, "entropy": 3.105672550201416, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 820000, "num_agent_steps_sampled": 1640000, "num_steps_trained": 820000, "num_agent_steps_trained": 1640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 81, "training_iteration": 41, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-38-27", "timestamp": 1704688707, "time_this_iter_s": 173.21438932418823, "time_total_s": 7545.778061389923, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019898B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7545.778061389923, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 17.716734693877548, "ram_util_percent": 49.317142857142855}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -491.56626506024094, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.78313253012047}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24297410188976482, "mean_inference_ms": 1.1390072951895422, "mean_action_processing_ms": 0.05916044243006971, "mean_env_wait_ms": 7.65187775749738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 840000, "timesteps_this_iter": 0, "agent_timesteps_total": 1680000, "timers": {"sample_time_ms": 173650.795, "sample_throughput": 115.174, "load_time_ms": 0.302, "load_throughput": 66281668.774, "learn_time_ms": 4543.389, "learn_throughput": 4402.0, "update_time_ms": 1.692}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 0.0005, "total_loss": 67.73656158447265, "policy_loss": -0.0010034820030629722, "vf_loss": 67.76859588623047, "vf_explained_var": 0.4277710556983948, "kl": 0.003656181922179917, "entropy": 3.103325939178467, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 840000, "num_agent_steps_sampled": 1680000, "num_steps_trained": 840000, "num_agent_steps_trained": 1680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 83, "training_iteration": 42, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-41-20", "timestamp": 1704688880, "time_this_iter_s": 173.03830099105835, "time_total_s": 7718.816362380981, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019ADCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7718.816362380981, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 17.832926829268295, "ram_util_percent": 49.37154471544714}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.11764705882354, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.05882352941177}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24281741757665534, "mean_inference_ms": 1.1380689159454096, "mean_action_processing_ms": 0.059127670812198434, "mean_env_wait_ms": 7.648759440176354, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 860000, "timesteps_this_iter": 0, "agent_timesteps_total": 1720000, "timers": {"sample_time_ms": 173598.988, "sample_throughput": 115.208, "load_time_ms": 0.402, "load_throughput": 49807671.298, "learn_time_ms": 4545.553, "learn_throughput": 4399.905, "update_time_ms": 1.692}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 0.0005, "total_loss": 64.62243423461913, "policy_loss": -0.0019255262374691996, "vf_loss": 64.65540924072266, "vf_explained_var": 0.38461880683898925, "kl": 0.0034399392926644625, "entropy": 3.10515775680542, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 860000, "num_agent_steps_sampled": 1720000, "num_steps_trained": 860000, "num_agent_steps_trained": 1720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 85, "training_iteration": 43, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-44-13", "timestamp": 1704689053, "time_this_iter_s": 173.02690839767456, "time_total_s": 7891.843270778656, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD1F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7891.843270778656, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 17.868979591836734, "ram_util_percent": 49.419591836734675}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -491.95402298850576, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.97701149425288}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24265630919913525, "mean_inference_ms": 1.1371231061567186, "mean_action_processing_ms": 0.059093832172386125, "mean_env_wait_ms": 7.645584245024283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 880000, "timesteps_this_iter": 0, "agent_timesteps_total": 1760000, "timers": {"sample_time_ms": 173551.065, "sample_throughput": 115.24, "load_time_ms": 0.299, "load_throughput": 66825523.779, "learn_time_ms": 4546.295, "learn_throughput": 4399.187, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 0.0005, "total_loss": 46.864786529541014, "policy_loss": -0.0013035689456108556, "vf_loss": 46.897161865234374, "vf_explained_var": 0.40134692192077637, "kl": 0.0028749506455048924, "entropy": 3.106910753250122, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 880000, "num_agent_steps_sampled": 1760000, "num_steps_trained": 880000, "num_agent_steps_trained": 1760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 87, "training_iteration": 44, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-47-06", "timestamp": 1704689226, "time_this_iter_s": 173.01317715644836, "time_total_s": 8064.856447935104, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8064.856447935104, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 17.937551020408165, "ram_util_percent": 48.82448979591837}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -492.13483146067415, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.06741573033707}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24249402641165238, "mean_inference_ms": 1.136170643631481, "mean_action_processing_ms": 0.05905967193060322, "mean_env_wait_ms": 7.642369371143784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 900000, "timesteps_this_iter": 0, "agent_timesteps_total": 1800000, "timers": {"sample_time_ms": 173563.203, "sample_throughput": 115.232, "load_time_ms": 0.298, "load_throughput": 67157217.196, "learn_time_ms": 4545.875, "learn_throughput": 4399.593, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 0.0005, "total_loss": 89.2579833984375, "policy_loss": -0.0011839707117341502, "vf_loss": 89.2905029296875, "vf_explained_var": 0.3075084209442139, "kl": 0.0014391528027081434, "entropy": 3.1331923961639405, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 900000, "num_agent_steps_sampled": 1800000, "num_steps_trained": 900000, "num_agent_steps_trained": 1800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 89, "training_iteration": 45, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-49-59", "timestamp": 1704689399, "time_this_iter_s": 173.27841544151306, "time_total_s": 8238.134863376617, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019935E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8238.134863376617, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 17.864081632653065, "ram_util_percent": 49.39877551020407}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.5054945054945, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.25274725274724}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24232970367081144, "mean_inference_ms": 1.1352138064922153, "mean_action_processing_ms": 0.0590252472500468, "mean_env_wait_ms": 7.639158663778412, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 920000, "timesteps_this_iter": 0, "agent_timesteps_total": 1840000, "timers": {"sample_time_ms": 173464.11, "sample_throughput": 115.298, "load_time_ms": 0.298, "load_throughput": 67157217.196, "learn_time_ms": 4545.344, "learn_throughput": 4400.107, "update_time_ms": 1.695}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005, "total_loss": 115.52046203613281, "policy_loss": -0.0016110727848298867, "vf_loss": 115.55329895019531, "vf_explained_var": 0.24566069841384888, "kl": 0.005271274623857636, "entropy": 3.1228042602539063, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 920000, "num_agent_steps_sampled": 1840000, "num_steps_trained": 920000, "num_agent_steps_trained": 1840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 91, "training_iteration": 46, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-52-54", "timestamp": 1704689574, "time_this_iter_s": 174.62144374847412, "time_total_s": 8412.756307125092, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A63A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8412.756307125092, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 17.798387096774192, "ram_util_percent": 49.44032258064515}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.6236559139785, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.31182795698925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2421644083488344, "mean_inference_ms": 1.1342551261966558, "mean_action_processing_ms": 0.05899027209239332, "mean_env_wait_ms": 7.6359348402815135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 940000, "timesteps_this_iter": 0, "agent_timesteps_total": 1880000, "timers": {"sample_time_ms": 173447.177, "sample_throughput": 115.309, "load_time_ms": 0.296, "load_throughput": 67459654.202, "learn_time_ms": 4549.246, "learn_throughput": 4396.333, "update_time_ms": 1.794}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 0.0005, "total_loss": 163.56964721679688, "policy_loss": -0.0010102360105514574, "vf_loss": 163.60199584960938, "vf_explained_var": 0.19352003335952758, "kl": 0.0027690856564920097, "entropy": 3.1335760593414306, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 940000, "num_agent_steps_sampled": 1880000, "num_steps_trained": 940000, "num_agent_steps_trained": 1880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 93, "training_iteration": 47, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-55-47", "timestamp": 1704689747, "time_this_iter_s": 173.65399265289307, "time_total_s": 8586.410299777985, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8586.410299777985, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 17.937804878048777, "ram_util_percent": 49.6788617886179}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -492.63157894736844, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.31578947368422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24199920392982746, "mean_inference_ms": 1.133296505532652, "mean_action_processing_ms": 0.05895562730383133, "mean_env_wait_ms": 7.632739288818426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 960000, "timesteps_this_iter": 0, "agent_timesteps_total": 1920000, "timers": {"sample_time_ms": 173601.263, "sample_throughput": 115.207, "load_time_ms": 0.396, "load_throughput": 50469935.624, "learn_time_ms": 4551.313, "learn_throughput": 4394.337, "update_time_ms": 1.694}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 0.0005, "total_loss": 120.11302490234375, "policy_loss": -0.0019261916952952873, "vf_loss": 120.14647064208984, "vf_explained_var": 0.2501432657241821, "kl": 0.0024549629903586555, "entropy": 3.1513806343078614, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 960000, "num_agent_steps_sampled": 1920000, "num_steps_trained": 960000, "num_agent_steps_trained": 1920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 95, "training_iteration": 48, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_12-58-43", "timestamp": 1704689923, "time_this_iter_s": 175.27688574790955, "time_total_s": 8761.687185525894, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8761.687185525894, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 17.807258064516123, "ram_util_percent": 49.606048387096784}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.8453608247423, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.42268041237114}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24183544489145967, "mean_inference_ms": 1.132341525075002, "mean_action_processing_ms": 0.05892142935006893, "mean_env_wait_ms": 7.629598912853382, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 980000, "timesteps_this_iter": 0, "agent_timesteps_total": 1960000, "timers": {"sample_time_ms": 173867.928, "sample_throughput": 115.03, "load_time_ms": 0.396, "load_throughput": 50469935.624, "learn_time_ms": 4554.704, "learn_throughput": 4391.065, "update_time_ms": 1.693}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 0.0005, "total_loss": 113.62562561035156, "policy_loss": -0.0014155174041632357, "vf_loss": 113.65851593017578, "vf_explained_var": 0.3023108601570129, "kl": 0.0021282497953818537, "entropy": 3.1477428913116454, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 980000, "num_agent_steps_sampled": 1960000, "num_steps_trained": 980000, "num_agent_steps_trained": 1960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 97, "training_iteration": 49, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-01-39", "timestamp": 1704690099, "time_this_iter_s": 176.5708794593811, "time_total_s": 8938.258064985275, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8938.258064985275, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 18.1736, "ram_util_percent": 49.1656}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.949494949495, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.4747474747475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24167264841635788, "mean_inference_ms": 1.1313898263778688, "mean_action_processing_ms": 0.058887491636248325, "mean_env_wait_ms": 7.626479613182426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1000000, "timesteps_this_iter": 0, "agent_timesteps_total": 2000000, "timers": {"sample_time_ms": 174072.44, "sample_throughput": 114.895, "load_time_ms": 0.396, "load_throughput": 50469935.624, "learn_time_ms": 4557.565, "learn_throughput": 4388.308, "update_time_ms": 1.69}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 0.0005, "total_loss": 112.87319946289062, "policy_loss": -0.0018289494891837288, "vf_loss": 112.90645294189453, "vf_explained_var": 0.27146615982055666, "kl": 0.004233651196074817, "entropy": 3.142046308517456, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1000000, "num_agent_steps_sampled": 2000000, "num_steps_trained": 1000000, "num_agent_steps_trained": 2000000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -250.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2079024742413222, "mean_inference_ms": 1.05871186696624, "mean_action_processing_ms": 0.05676806181050309, "mean_env_wait_ms": 7.286286466347741, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 99, "training_iteration": 50, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-18-56", "timestamp": 1704691136, "time_this_iter_s": 1036.267287492752, "time_total_s": 9974.525352478027, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301638E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9974.525352478027, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 17.81082368958475, "ram_util_percent": 49.22995234853642}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24206333568342678, "mean_inference_ms": 1.1317216136002761, "mean_action_processing_ms": 0.05890592335700329, "mean_env_wait_ms": 7.625904226304184, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1020000, "timesteps_this_iter": 0, "agent_timesteps_total": 2040000, "timers": {"sample_time_ms": 260496.626, "sample_throughput": 76.776, "load_time_ms": 0.396, "load_throughput": 50469935.624, "learn_time_ms": 4561.992, "learn_throughput": 4384.05, "update_time_ms": 1.787}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.552713678800501e-16, "cur_lr": 0.0005, "total_loss": 64.10378570556641, "policy_loss": -0.0017391278086043905, "vf_loss": 64.1369415283203, "vf_explained_var": 0.33969587087631226, "kl": 0.004088369266986902, "entropy": 3.1415779113769533, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1020000, "num_agent_steps_sampled": 2040000, "num_steps_trained": 1020000, "num_agent_steps_trained": 2040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 101, "training_iteration": 51, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-21-52", "timestamp": 1704691312, "time_this_iter_s": 175.98643827438354, "time_total_s": 10150.51179075241, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10150.51179075241, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 17.865461847389557, "ram_util_percent": 47.85983935742971}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -490.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -245.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24254649620980903, "mean_inference_ms": 1.13220644730082, "mean_action_processing_ms": 0.05894993202219998, "mean_env_wait_ms": 7.625421621599603, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1040000, "timesteps_this_iter": 0, "agent_timesteps_total": 2080000, "timers": {"sample_time_ms": 260581.223, "sample_throughput": 76.752, "load_time_ms": 0.396, "load_throughput": 50469935.624, "learn_time_ms": 4568.189, "learn_throughput": 4378.103, "update_time_ms": 1.787}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 0.0005, "total_loss": 87.27531433105469, "policy_loss": -0.0026668880131094142, "vf_loss": 87.30919494628907, "vf_explained_var": 0.41330890655517577, "kl": 0.0044243537894887, "entropy": 3.1209213733673096, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1040000, "num_agent_steps_sampled": 2080000, "num_steps_trained": 1040000, "num_agent_steps_trained": 2080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 103, "training_iteration": 52, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-24-46", "timestamp": 1704691486, "time_this_iter_s": 173.89685153961182, "time_total_s": 10324.408642292023, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10324.408642292023, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 18.058130081300813, "ram_util_percent": 49.319512195121945}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -492.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -200.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24261405012230314, "mean_inference_ms": 1.1314197969079656, "mean_action_processing_ms": 0.058946686526322886, "mean_env_wait_ms": 7.6226509337211805, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1060000, "timesteps_this_iter": 0, "agent_timesteps_total": 2120000, "timers": {"sample_time_ms": 260868.54, "sample_throughput": 76.667, "load_time_ms": 0.296, "load_throughput": 67459654.202, "learn_time_ms": 4573.965, "learn_throughput": 4372.574, "update_time_ms": 1.89}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.881784197001253e-17, "cur_lr": 0.0005, "total_loss": 116.40495910644532, "policy_loss": -0.0010987831668555436, "vf_loss": 116.43707733154297, "vf_explained_var": 0.2945737600326538, "kl": 0.0030316881920261275, "entropy": 3.102214050292969, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1060000, "num_agent_steps_sampled": 2120000, "num_steps_trained": 1060000, "num_agent_steps_trained": 2120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 105, "training_iteration": 53, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-27-41", "timestamp": 1704691661, "time_this_iter_s": 175.8939652442932, "time_total_s": 10500.302607536316, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019898B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10500.302607536316, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 17.913199999999996, "ram_util_percent": 47.93999999999999}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24241288864002283, "mean_inference_ms": 1.1299860005132023, "mean_action_processing_ms": 0.05889426997263675, "mean_env_wait_ms": 7.618570423339938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1080000, "timesteps_this_iter": 0, "agent_timesteps_total": 2160000, "timers": {"sample_time_ms": 261242.186, "sample_throughput": 76.557, "load_time_ms": 0.296, "load_throughput": 67459654.202, "learn_time_ms": 4582.731, "learn_throughput": 4364.21, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 0.0005, "total_loss": 139.36763763427734, "policy_loss": -0.0014208956915886973, "vf_loss": 139.3998062133789, "vf_explained_var": 0.22099941968917847, "kl": 0.0018912492658610613, "entropy": 3.0748132705688476, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1080000, "num_agent_steps_sampled": 2160000, "num_steps_trained": 1080000, "num_agent_steps_trained": 2160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 107, "training_iteration": 54, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-30-38", "timestamp": 1704691838, "time_this_iter_s": 176.7773609161377, "time_total_s": 10677.079968452454, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10677.079968452454, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 17.974800000000002, "ram_util_percent": 47.92279999999999}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24214661408693094, "mean_inference_ms": 1.1284127604617877, "mean_action_processing_ms": 0.05883313834996404, "mean_env_wait_ms": 7.614386183255513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1100000, "timesteps_this_iter": 0, "agent_timesteps_total": 2200000, "timers": {"sample_time_ms": 261605.87, "sample_throughput": 76.451, "load_time_ms": 0.198, "load_throughput": 100921655.438, "learn_time_ms": 4586.85, "learn_throughput": 4360.29, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2204460492503132e-17, "cur_lr": 0.0005, "total_loss": 51.54718246459961, "policy_loss": -0.0013401156623661591, "vf_loss": 51.578827667236325, "vf_explained_var": 0.3862382769584656, "kl": 0.0022943123875077466, "entropy": 3.0306713581085205, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1100000, "num_agent_steps_sampled": 2200000, "num_steps_trained": 1100000, "num_agent_steps_trained": 2200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 109, "training_iteration": 55, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-33-35", "timestamp": 1704692015, "time_this_iter_s": 176.86996126174927, "time_total_s": 10853.949929714203, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F58B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10853.949929714203, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 18.096799999999998, "ram_util_percent": 46.46320000000001}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24189793565855802, "mean_inference_ms": 1.126864022471228, "mean_action_processing_ms": 0.058775111002905264, "mean_env_wait_ms": 7.610169700458906, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1120000, "timesteps_this_iter": 0, "agent_timesteps_total": 2240000, "timers": {"sample_time_ms": 261999.1, "sample_throughput": 76.336, "load_time_ms": 0.298, "load_throughput": 67194873.438, "learn_time_ms": 4594.39, "learn_throughput": 4353.135, "update_time_ms": 1.891}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1102230246251566e-17, "cur_lr": 0.0005, "total_loss": 119.28927612304688, "policy_loss": -0.002614096860550319, "vf_loss": 119.32270050048828, "vf_explained_var": 0.3536047339439392, "kl": 0.0028854101621701212, "entropy": 3.0809905529022217, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1120000, "num_agent_steps_sampled": 2240000, "num_steps_trained": 1120000, "num_agent_steps_trained": 2240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 111, "training_iteration": 56, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-36-34", "timestamp": 1704692194, "time_this_iter_s": 178.58765864372253, "time_total_s": 11032.537588357925, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017D1790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11032.537588357925, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 18.031496062992126, "ram_util_percent": 47.29763779527559}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24163257449678363, "mean_inference_ms": 1.1253487483802358, "mean_action_processing_ms": 0.05871689743912368, "mean_env_wait_ms": 7.605961636476661, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1140000, "timesteps_this_iter": 0, "agent_timesteps_total": 2280000, "timers": {"sample_time_ms": 262225.086, "sample_throughput": 76.27, "load_time_ms": 0.301, "load_throughput": 66355070.4, "learn_time_ms": 4601.082, "learn_throughput": 4346.803, "update_time_ms": 1.694}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 0.0005, "total_loss": 61.916053009033206, "policy_loss": -0.0007127229102188882, "vf_loss": 61.94798736572265, "vf_explained_var": 0.3190418481826782, "kl": 0.0026489260977858643, "entropy": 3.1220303058624266, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1140000, "num_agent_steps_sampled": 2280000, "num_steps_trained": 1140000, "num_agent_steps_trained": 2280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 113, "training_iteration": 57, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-39-30", "timestamp": 1704692370, "time_this_iter_s": 175.9064154624939, "time_total_s": 11208.44400382042, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11208.44400382042, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 17.895983935742972, "ram_util_percent": 47.328915662650594}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2413469368292141, "mean_inference_ms": 1.1238192263306783, "mean_action_processing_ms": 0.058660990451028336, "mean_env_wait_ms": 7.601540001165477, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1160000, "timesteps_this_iter": 0, "agent_timesteps_total": 2320000, "timers": {"sample_time_ms": 262403.191, "sample_throughput": 76.219, "load_time_ms": 0.304, "load_throughput": 65736290.259, "learn_time_ms": 4608.75, "learn_throughput": 4339.572, "update_time_ms": 1.691}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7755575615628915e-18, "cur_lr": 0.0005, "total_loss": 55.00333862304687, "policy_loss": -0.0011126087658293927, "vf_loss": 55.035545349121094, "vf_explained_var": 0.21063897609710694, "kl": 0.001799818750141391, "entropy": 3.109371376037598, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1160000, "num_agent_steps_sampled": 2320000, "num_steps_trained": 1160000, "num_agent_steps_trained": 2320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 115, "training_iteration": 58, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-42-27", "timestamp": 1704692547, "time_this_iter_s": 177.06765031814575, "time_total_s": 11385.511654138565, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11385.511654138565, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 17.9, "ram_util_percent": 47.31872509960159}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -492.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2410282393017151, "mean_inference_ms": 1.1221027336821516, "mean_action_processing_ms": 0.058592196384210274, "mean_env_wait_ms": 7.596266673987597, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1180000, "timesteps_this_iter": 0, "agent_timesteps_total": 2360000, "timers": {"sample_time_ms": 262230.369, "sample_throughput": 76.269, "load_time_ms": 0.405, "load_throughput": 49350558.889, "learn_time_ms": 4625.355, "learn_throughput": 4323.992, "update_time_ms": 1.789}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 0.0005, "total_loss": 52.693902587890626, "policy_loss": -0.0013087181615457411, "vf_loss": 52.726514434814455, "vf_explained_var": 0.23940119743347169, "kl": 0.0014941194373918165, "entropy": 3.1306663513183595, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1180000, "num_agent_steps_sampled": 2360000, "num_steps_trained": 1180000, "num_agent_steps_trained": 2360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 117, "training_iteration": 59, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-45-22", "timestamp": 1704692722, "time_this_iter_s": 174.93237853050232, "time_total_s": 11560.444032669067, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016B5670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11560.444032669067, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 18.120967741935484, "ram_util_percent": 47.33427419354838}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2406906717184127, "mean_inference_ms": 1.1203110770687552, "mean_action_processing_ms": 0.05852109859171417, "mean_env_wait_ms": 7.590783229667592, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1200000, "timesteps_this_iter": 0, "agent_timesteps_total": 2400000, "timers": {"sample_time_ms": 262204.321, "sample_throughput": 76.276, "load_time_ms": 0.405, "load_throughput": 49350558.889, "learn_time_ms": 4626.519, "learn_throughput": 4322.904, "update_time_ms": 1.789}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.938893903907229e-19, "cur_lr": 0.0005, "total_loss": 164.89539794921876, "policy_loss": -0.001590670895874524, "vf_loss": 164.9282257080078, "vf_explained_var": 0.17796157598495482, "kl": 0.0018251146048835487, "entropy": 3.1228178977966308, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1200000, "num_agent_steps_sampled": 2400000, "num_steps_trained": 1200000, "num_agent_steps_trained": 2400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 119, "training_iteration": 60, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-48-16", "timestamp": 1704692896, "time_this_iter_s": 174.37622356414795, "time_total_s": 11734.820256233215, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11734.820256233215, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 18.045748987854253, "ram_util_percent": 46.114574898785435}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24034276094997734, "mean_inference_ms": 1.1184719990084075, "mean_action_processing_ms": 0.05844557091126164, "mean_env_wait_ms": 7.585281138612265, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1220000, "timesteps_this_iter": 0, "agent_timesteps_total": 2440000, "timers": {"sample_time_ms": 175957.368, "sample_throughput": 113.664, "load_time_ms": 0.405, "load_throughput": 49350558.889, "learn_time_ms": 4627.682, "learn_throughput": 4321.818, "update_time_ms": 1.803}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4694469519536144e-19, "cur_lr": 0.0005, "total_loss": 47.27604370117187, "policy_loss": -0.0011552057116199332, "vf_loss": 47.30839920043945, "vf_explained_var": 0.28961710929870604, "kl": 0.0017866187988889947, "entropy": 3.120104503631592, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1220000, "num_agent_steps_sampled": 2440000, "num_steps_trained": 1220000, "num_agent_steps_trained": 2440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 121, "training_iteration": 61, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-51-11", "timestamp": 1704693071, "time_this_iter_s": 175.00004863739014, "time_total_s": 11909.820304870605, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11909.820304870605, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 17.84032258064516, "ram_util_percent": 47.26491935483871}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2399874301119249, "mean_inference_ms": 1.116629433660602, "mean_action_processing_ms": 0.058372574381243485, "mean_env_wait_ms": 7.579810969708477, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1240000, "timesteps_this_iter": 0, "agent_timesteps_total": 2480000, "timers": {"sample_time_ms": 176151.06, "sample_throughput": 113.539, "load_time_ms": 0.405, "load_throughput": 49350558.889, "learn_time_ms": 4629.366, "learn_throughput": 4320.246, "update_time_ms": 1.8}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7347234759768072e-19, "cur_lr": 0.0005, "total_loss": 77.94942474365234, "policy_loss": -0.0017640872890874349, "vf_loss": 77.98260955810547, "vf_explained_var": 0.22872480154037475, "kl": 0.002595664047312296, "entropy": 3.1420366287231447, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1240000, "num_agent_steps_sampled": 2480000, "num_steps_trained": 1240000, "num_agent_steps_trained": 2480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 123, "training_iteration": 62, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-54-07", "timestamp": 1704693247, "time_this_iter_s": 175.8426549434662, "time_total_s": 12085.662959814072, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019933A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12085.662959814072, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 17.981927710843372, "ram_util_percent": 47.3285140562249}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23966800139317626, "mean_inference_ms": 1.1149243788544922, "mean_action_processing_ms": 0.05830642574232102, "mean_env_wait_ms": 7.574873050775027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1260000, "timesteps_this_iter": 0, "agent_timesteps_total": 2520000, "timers": {"sample_time_ms": 175869.594, "sample_throughput": 113.721, "load_time_ms": 0.405, "load_throughput": 49350558.889, "learn_time_ms": 4634.258, "learn_throughput": 4315.685, "update_time_ms": 1.797}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.673617379884036e-20, "cur_lr": 0.0005, "total_loss": 48.583065032958984, "policy_loss": -0.0010750953623745118, "vf_loss": 48.61528396606445, "vf_explained_var": 0.33977320194244387, "kl": 0.002036263723218257, "entropy": 3.114624786376953, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1260000, "num_agent_steps_sampled": 2520000, "num_steps_trained": 1260000, "num_agent_steps_trained": 2520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 125, "training_iteration": 63, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-57-00", "timestamp": 1704693420, "time_this_iter_s": 173.11057662963867, "time_total_s": 12258.77353644371, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12258.77353644371, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 17.984959349593495, "ram_util_percent": 47.29634146341463}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23937809468933297, "mean_inference_ms": 1.1133881046451306, "mean_action_processing_ms": 0.058246345861924904, "mean_env_wait_ms": 7.570314432284687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1280000, "timesteps_this_iter": 0, "agent_timesteps_total": 2560000, "timers": {"sample_time_ms": 175659.771, "sample_throughput": 113.856, "load_time_ms": 0.505, "load_throughput": 39596922.351, "learn_time_ms": 4637.342, "learn_throughput": 4312.815, "update_time_ms": 1.894}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.336808689942018e-20, "cur_lr": 0.0005, "total_loss": 136.53236389160156, "policy_loss": -0.0015271891496330347, "vf_loss": 136.5651824951172, "vf_explained_var": 0.10848091840744019, "kl": 0.006419948182547019, "entropy": 3.1291129112243654, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1280000, "num_agent_steps_sampled": 2560000, "num_steps_trained": 1280000, "num_agent_steps_trained": 2560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 127, "training_iteration": 64, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_13-59-55", "timestamp": 1704693595, "time_this_iter_s": 174.6628303527832, "time_total_s": 12433.436366796494, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12433.436366796494, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 17.851417004048585, "ram_util_percent": 47.3157894736842}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23910214936391092, "mean_inference_ms": 1.1119679044223245, "mean_action_processing_ms": 0.05819346358044965, "mean_env_wait_ms": 7.566155186752698, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1300000, "timesteps_this_iter": 0, "agent_timesteps_total": 2600000, "timers": {"sample_time_ms": 175356.243, "sample_throughput": 114.054, "load_time_ms": 0.505, "load_throughput": 39596922.351, "learn_time_ms": 4639.631, "learn_throughput": 4310.688, "update_time_ms": 1.995}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.336808689942018e-20, "cur_lr": 0.0005, "total_loss": 41.24663772583008, "policy_loss": -0.0009999848349764972, "vf_loss": 41.27892837524414, "vf_explained_var": 0.5244121551513672, "kl": 0.0022770837185583704, "entropy": 3.1289416313171388, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1300000, "num_agent_steps_sampled": 2600000, "num_steps_trained": 1300000, "num_agent_steps_trained": 2600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 129, "training_iteration": 65, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-02-49", "timestamp": 1704693769, "time_this_iter_s": 173.82562398910522, "time_total_s": 12607.261990785599, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019ADDC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12607.261990785599, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 18.16260162601626, "ram_util_percent": 46.38455284552846}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2388445931599853, "mean_inference_ms": 1.1106195132838863, "mean_action_processing_ms": 0.05814136290800727, "mean_env_wait_ms": 7.562273323679571, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1320000, "timesteps_this_iter": 0, "agent_timesteps_total": 2640000, "timers": {"sample_time_ms": 174891.387, "sample_throughput": 114.357, "load_time_ms": 0.406, "load_throughput": 49307047.552, "learn_time_ms": 4640.347, "learn_throughput": 4310.023, "update_time_ms": 1.894}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.168404344971009e-20, "cur_lr": 0.0005, "total_loss": 170.81829528808595, "policy_loss": -0.0014170427993498657, "vf_loss": 170.8509063720703, "vf_explained_var": 0.23430761098861694, "kl": 0.001706978546276261, "entropy": 3.1197211265563967, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1320000, "num_agent_steps_sampled": 2640000, "num_steps_trained": 1320000, "num_agent_steps_trained": 2640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 131, "training_iteration": 66, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-05-43", "timestamp": 1704693943, "time_this_iter_s": 173.92158150672913, "time_total_s": 12781.183572292328, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12781.183572292328, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 18.029149797570852, "ram_util_percent": 47.23198380566802}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23857527467998071, "mean_inference_ms": 1.1093110852459538, "mean_action_processing_ms": 0.0580908170688037, "mean_env_wait_ms": 7.558372189991177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1340000, "timesteps_this_iter": 0, "agent_timesteps_total": 2680000, "timers": {"sample_time_ms": 174758.831, "sample_throughput": 114.443, "load_time_ms": 0.303, "load_throughput": 65901547.647, "learn_time_ms": 4641.704, "learn_throughput": 4308.763, "update_time_ms": 1.904}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0842021724855045e-20, "cur_lr": 0.0005, "total_loss": 96.64887237548828, "policy_loss": -0.0020204748177528485, "vf_loss": 96.68234710693359, "vf_explained_var": 0.38075861930847166, "kl": 0.004100562485262671, "entropy": 3.145628881454468, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1340000, "num_agent_steps_sampled": 2680000, "num_steps_trained": 1340000, "num_agent_steps_trained": 2680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 133, "training_iteration": 67, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-08-37", "timestamp": 1704694117, "time_this_iter_s": 174.585955619812, "time_total_s": 12955.76952791214, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301989E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12955.76952791214, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 17.835627530364373, "ram_util_percent": 47.365587044534394}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23831087571578405, "mean_inference_ms": 1.108030794261772, "mean_action_processing_ms": 0.05804048342975315, "mean_env_wait_ms": 7.554476795237762, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1360000, "timesteps_this_iter": 0, "agent_timesteps_total": 2720000, "timers": {"sample_time_ms": 174419.094, "sample_throughput": 114.666, "load_time_ms": 0.201, "load_throughput": 99579867.047, "learn_time_ms": 4642.705, "learn_throughput": 4307.833, "update_time_ms": 1.907}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.4210108624275225e-21, "cur_lr": 0.0005, "total_loss": 74.55187225341797, "policy_loss": -0.0013515912348963433, "vf_loss": 74.58429260253907, "vf_explained_var": 0.4416024923324585, "kl": 0.0051579859251663866, "entropy": 3.1065399169921877, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1360000, "num_agent_steps_sampled": 2720000, "num_steps_trained": 1360000, "num_agent_steps_trained": 2720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 135, "training_iteration": 68, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-11-31", "timestamp": 1704694291, "time_this_iter_s": 173.6681706905365, "time_total_s": 13129.437698602676, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13129.437698602676, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 17.954065040650406, "ram_util_percent": 47.3211382113821}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23806287568050066, "mean_inference_ms": 1.1067954640663396, "mean_action_processing_ms": 0.05799092622395077, "mean_env_wait_ms": 7.550686304621678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1380000, "timesteps_this_iter": 0, "agent_timesteps_total": 2760000, "timers": {"sample_time_ms": 174620.506, "sample_throughput": 114.534, "load_time_ms": 0.1, "load_throughput": 200348889.42, "learn_time_ms": 4638.418, "learn_throughput": 4311.815, "update_time_ms": 1.81}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.4210108624275225e-21, "cur_lr": 0.0005, "total_loss": 51.67792282104492, "policy_loss": -0.0018306105164811015, "vf_loss": 51.71087799072266, "vf_explained_var": 0.46270185708999634, "kl": 0.0023817914018483765, "entropy": 3.1123589992523195, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1380000, "num_agent_steps_sampled": 2760000, "num_steps_trained": 1380000, "num_agent_steps_trained": 2760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 137, "training_iteration": 69, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-14-28", "timestamp": 1704694468, "time_this_iter_s": 176.88667845726013, "time_total_s": 13306.324377059937, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301993AF0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13306.324377059937, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 17.941832669322707, "ram_util_percent": 47.423505976095605}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23773801447035375, "mean_inference_ms": 1.1051179794231958, "mean_action_processing_ms": 0.05792531045064473, "mean_env_wait_ms": 7.5455178573541035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1400000, "timesteps_this_iter": 0, "agent_timesteps_total": 2800000, "timers": {"sample_time_ms": 174557.662, "sample_throughput": 114.575, "load_time_ms": 0.1, "load_throughput": 200348889.42, "learn_time_ms": 4642.505, "learn_throughput": 4308.019, "update_time_ms": 1.711}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7105054312137612e-21, "cur_lr": 0.0005, "total_loss": 40.58847198486328, "policy_loss": -0.002242565931491558, "vf_loss": 40.621968841552736, "vf_explained_var": 0.44259822368621826, "kl": 0.003561249522159371, "entropy": 3.1255035400390625, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1400000, "num_agent_steps_sampled": 2800000, "num_steps_trained": 1400000, "num_agent_steps_trained": 2800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 139, "training_iteration": 70, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-17-22", "timestamp": 1704694642, "time_this_iter_s": 173.83115243911743, "time_total_s": 13480.155529499054, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019933A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13480.155529499054, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 17.974390243902437, "ram_util_percent": 46.756504065040644}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23719367261583393, "mean_inference_ms": 1.1024142770473984, "mean_action_processing_ms": 0.05782228642456614, "mean_env_wait_ms": 7.5372550264120335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1420000, "timesteps_this_iter": 0, "agent_timesteps_total": 2840000, "timers": {"sample_time_ms": 174376.69, "sample_throughput": 114.694, "load_time_ms": 0.1, "load_throughput": 200348889.42, "learn_time_ms": 4647.953, "learn_throughput": 4302.969, "update_time_ms": 1.698}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3552527156068806e-21, "cur_lr": 0.0005, "total_loss": 51.494824981689455, "policy_loss": -0.0014902786221168917, "vf_loss": 51.52748184204101, "vf_explained_var": 0.46788069009780886, "kl": 0.0022960763527422935, "entropy": 3.1166327953338624, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1420000, "num_agent_steps_sampled": 2840000, "num_steps_trained": 1420000, "num_agent_steps_trained": 2840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 141, "training_iteration": 71, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-20-15", "timestamp": 1704694815, "time_this_iter_s": 173.21720957756042, "time_total_s": 13653.372739076614, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DE310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13653.372739076614, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 18.064897959183675, "ram_util_percent": 47.23428571428571}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23664909232706385, "mean_inference_ms": 1.0997346217054487, "mean_action_processing_ms": 0.05771949428937125, "mean_env_wait_ms": 7.528967385907956, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1440000, "timesteps_this_iter": 0, "agent_timesteps_total": 2880000, "timers": {"sample_time_ms": 174064.246, "sample_throughput": 114.9, "load_time_ms": 0.1, "load_throughput": 200348889.42, "learn_time_ms": 4652.053, "learn_throughput": 4299.178, "update_time_ms": 1.698}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.776263578034403e-22, "cur_lr": 0.0005, "total_loss": 73.3753875732422, "policy_loss": -0.0018532296445220807, "vf_loss": 73.40794219970704, "vf_explained_var": 0.4384976029396057, "kl": 0.0024206606048931103, "entropy": 3.0702515125274656, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1440000, "num_agent_steps_sampled": 2880000, "num_steps_trained": 1440000, "num_agent_steps_trained": 2880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 143, "training_iteration": 72, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-23-08", "timestamp": 1704694988, "time_this_iter_s": 172.70256185531616, "time_total_s": 13826.07530093193, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD5E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13826.07530093193, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 17.870612244897956, "ram_util_percent": 47.32367346938775}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23612974627402822, "mean_inference_ms": 1.0972031853734503, "mean_action_processing_ms": 0.0576213389422789, "mean_env_wait_ms": 7.521046453983414, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1460000, "timesteps_this_iter": 0, "agent_timesteps_total": 2920000, "timers": {"sample_time_ms": 174254.71, "sample_throughput": 114.775, "load_time_ms": 0.1, "load_throughput": 200348889.42, "learn_time_ms": 4653.681, "learn_throughput": 4297.673, "update_time_ms": 1.599}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.3881317890172015e-22, "cur_lr": 0.0005, "total_loss": 31.07134590148926, "policy_loss": -0.001293734533321178, "vf_loss": 31.10381202697754, "vf_explained_var": 0.5857845425605774, "kl": 0.002021446937829552, "entropy": 3.1173353672027586, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1460000, "num_agent_steps_sampled": 2920000, "num_steps_trained": 1460000, "num_agent_steps_trained": 2920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 145, "training_iteration": 73, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-26-03", "timestamp": 1704695163, "time_this_iter_s": 174.9910409450531, "time_total_s": 14001.066341876984, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301739B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14001.066341876984, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 17.927419354838708, "ram_util_percent": 47.34677419354837}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23563980223866968, "mean_inference_ms": 1.0948084115548045, "mean_action_processing_ms": 0.05752690028718279, "mean_env_wait_ms": 7.513420474826387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1480000, "timesteps_this_iter": 0, "agent_timesteps_total": 2960000, "timers": {"sample_time_ms": 174122.989, "sample_throughput": 114.861, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4653.232, "learn_throughput": 4298.088, "update_time_ms": 1.501}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6940658945086008e-22, "cur_lr": 0.0005, "total_loss": 114.3909683227539, "policy_loss": -0.0019217148620262136, "vf_loss": 114.42416076660156, "vf_explained_var": 0.25034207105636597, "kl": 0.0037657168693268515, "entropy": 3.127069616317749, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1480000, "num_agent_steps_sampled": 2960000, "num_steps_trained": 1480000, "num_agent_steps_trained": 2960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 147, "training_iteration": 74, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-28-56", "timestamp": 1704695336, "time_this_iter_s": 173.32249426841736, "time_total_s": 14174.388836145401, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301638E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14174.388836145401, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 17.85487804878049, "ram_util_percent": 47.42886178861788}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23517393355443159, "mean_inference_ms": 1.0925375352523634, "mean_action_processing_ms": 0.05743947844270792, "mean_env_wait_ms": 7.506182221017585, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1500000, "timesteps_this_iter": 0, "agent_timesteps_total": 3000000, "timers": {"sample_time_ms": 174236.766, "sample_throughput": 114.786, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4654.714, "learn_throughput": 4296.72, "update_time_ms": 1.297}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.470329472543004e-23, "cur_lr": 0.0005, "total_loss": 131.52643432617188, "policy_loss": -0.001778826855774973, "vf_loss": 131.55948181152343, "vf_explained_var": 0.39190772771835325, "kl": 0.003305311367136804, "entropy": 3.1265267372131347, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1500000, "num_agent_steps_sampled": 3000000, "num_steps_trained": 1500000, "num_agent_steps_trained": 3000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 149, "training_iteration": 75, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-31-51", "timestamp": 1704695511, "time_this_iter_s": 174.9795060157776, "time_total_s": 14349.368342161179, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DECA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14349.368342161179, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 17.867206477732793, "ram_util_percent": 47.05222672064777}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.234734460865334, "mean_inference_ms": 1.0903807203577183, "mean_action_processing_ms": 0.0573552107069861, "mean_env_wait_ms": 7.499371664963004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1520000, "timesteps_this_iter": 0, "agent_timesteps_total": 3040000, "timers": {"sample_time_ms": 174518.562, "sample_throughput": 114.601, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4654.679, "learn_throughput": 4296.752, "update_time_ms": 1.298}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.235164736271502e-23, "cur_lr": 0.0005, "total_loss": 84.10134887695312, "policy_loss": -0.001704792522862597, "vf_loss": 84.13410186767578, "vf_explained_var": 0.24735876321792602, "kl": 0.003936781870756167, "entropy": 3.104756212234497, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1520000, "num_agent_steps_sampled": 3040000, "num_steps_trained": 1520000, "num_agent_steps_trained": 3040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 151, "training_iteration": 76, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-34-48", "timestamp": 1704695688, "time_this_iter_s": 176.72393250465393, "time_total_s": 14526.092274665833, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14526.092274665833, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 17.78844621513944, "ram_util_percent": 47.331474103585656}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2343138046246903, "mean_inference_ms": 1.0883285636721438, "mean_action_processing_ms": 0.05727555515102344, "mean_env_wait_ms": 7.492841437629745, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1540000, "timesteps_this_iter": 0, "agent_timesteps_total": 3080000, "timers": {"sample_time_ms": 174613.886, "sample_throughput": 114.538, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4656.269, "learn_throughput": 4295.284, "update_time_ms": 1.288}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.117582368135751e-23, "cur_lr": 0.0005, "total_loss": 46.36426696777344, "policy_loss": -0.0020272258724272517, "vf_loss": 46.397186279296875, "vf_explained_var": 0.4448991656303406, "kl": 0.0033787359633700833, "entropy": 3.0892220020294188, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1540000, "num_agent_steps_sampled": 3080000, "num_steps_trained": 1540000, "num_agent_steps_trained": 3080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 153, "training_iteration": 77, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-37-43", "timestamp": 1704695863, "time_this_iter_s": 175.5521047115326, "time_total_s": 14701.644379377365, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14701.644379377365, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 18.02409638554217, "ram_util_percent": 47.44859437751003}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23391344602836583, "mean_inference_ms": 1.0863713885580157, "mean_action_processing_ms": 0.057199978552994066, "mean_env_wait_ms": 7.486628361128677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1560000, "timesteps_this_iter": 0, "agent_timesteps_total": 3120000, "timers": {"sample_time_ms": 174888.101, "sample_throughput": 114.359, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4658.862, "learn_throughput": 4292.894, "update_time_ms": 1.285}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0587911840678755e-23, "cur_lr": 0.0005, "total_loss": 57.99226303100586, "policy_loss": -0.0017448437886312894, "vf_loss": 58.02438659667969, "vf_explained_var": 0.4840267539024353, "kl": 0.0018982659565244474, "entropy": 3.0378971099853516, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1560000, "num_agent_steps_sampled": 3120000, "num_steps_trained": 1560000, "num_agent_steps_trained": 3120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 155, "training_iteration": 78, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-40-40", "timestamp": 1704696040, "time_this_iter_s": 176.4198956489563, "time_total_s": 14878.064275026321, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301989790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14878.064275026321, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 17.8564, "ram_util_percent": 47.42559999999999}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24043839639884892, "mean_inference_ms": 1.0845081608144536, "mean_action_processing_ms": 0.05712893039932662, "mean_env_wait_ms": 7.480730605492002, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1580000, "timesteps_this_iter": 0, "agent_timesteps_total": 3160000, "timers": {"sample_time_ms": 229778.906, "sample_throughput": 87.04, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4659.026, "learn_throughput": 4292.743, "update_time_ms": 1.384}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.2939559203393774e-24, "cur_lr": 0.0005, "total_loss": 65.85390930175781, "policy_loss": -0.0017690349443443055, "vf_loss": 65.88597869873047, "vf_explained_var": 0.4430810809135437, "kl": 0.002226332459608926, "entropy": 3.030246114730835, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1580000, "num_agent_steps_sampled": 3160000, "num_steps_trained": 1580000, "num_agent_steps_trained": 3160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 157, "training_iteration": 79, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-52-46", "timestamp": 1704696766, "time_this_iter_s": 725.548201084137, "time_total_s": 15603.612476110458, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15603.612476110458, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 20.708627450980394, "ram_util_percent": 42.88313725490196}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24689835778528393, "mean_inference_ms": 1.0827515819562847, "mean_action_processing_ms": 0.05706182117877292, "mean_env_wait_ms": 7.475160749476953, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1600000, "timesteps_this_iter": 0, "agent_timesteps_total": 3200000, "timers": {"sample_time_ms": 230686.047, "sample_throughput": 86.698, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4698.986, "learn_throughput": 4256.237, "update_time_ms": 1.386}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.6469779601696887e-24, "cur_lr": 0.0005, "total_loss": 32.77003784179688, "policy_loss": -0.0020327842494472837, "vf_loss": 32.803116989135745, "vf_explained_var": 0.5852188110351563, "kl": 0.003939187484132134, "entropy": 3.1045523166656492, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1600000, "num_agent_steps_sampled": 3200000, "num_steps_trained": 1600000, "num_agent_steps_trained": 3200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 159, "training_iteration": 80, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-55-49", "timestamp": 1704696949, "time_this_iter_s": 183.30228757858276, "time_total_s": 15786.914763689041, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD4C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15786.914763689041, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 22.39305019305019, "ram_util_percent": 44.503861003861005}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2532938738768791, "mean_inference_ms": 1.0810978229322197, "mean_action_processing_ms": 0.05700056135978507, "mean_env_wait_ms": 7.469994315609954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1620000, "timesteps_this_iter": 0, "agent_timesteps_total": 3240000, "timers": {"sample_time_ms": 232081.695, "sample_throughput": 86.177, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4710.211, "learn_throughput": 4246.094, "update_time_ms": 1.386}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3234889800848444e-24, "cur_lr": 0.0005, "total_loss": 178.9412414550781, "policy_loss": -0.0018705814405532094, "vf_loss": 178.9738555908203, "vf_explained_var": 0.10676075220108032, "kl": 0.003650287866523394, "entropy": 3.07503719329834, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1620000, "num_agent_steps_sampled": 3240000, "num_steps_trained": 1620000, "num_agent_steps_trained": 3240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 161, "training_iteration": 81, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_14-58-56", "timestamp": 1704697136, "time_this_iter_s": 186.8714737892151, "time_total_s": 15973.786237478256, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15973.786237478256, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 21.733962264150943, "ram_util_percent": 45.83773584905661}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2596278113259347, "mean_inference_ms": 1.0795458629313228, "mean_action_processing_ms": 0.056944210794784136, "mean_env_wait_ms": 7.465130037966137, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1640000, "timesteps_this_iter": 0, "agent_timesteps_total": 3280000, "timers": {"sample_time_ms": 233405.693, "sample_throughput": 85.688, "load_time_ms": 0.1, "load_throughput": 200396751.075, "learn_time_ms": 4720.459, "learn_throughput": 4236.876, "update_time_ms": 1.388}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.617444900424222e-25, "cur_lr": 0.0005, "total_loss": 68.46029205322266, "policy_loss": -0.0020821559719741366, "vf_loss": 68.4936508178711, "vf_explained_var": 0.44648433923721315, "kl": 0.002359006110864126, "entropy": 3.127560758590698, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1640000, "num_agent_steps_sampled": 3280000, "num_steps_trained": 1640000, "num_agent_steps_trained": 3280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 163, "training_iteration": 82, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-02-02", "timestamp": 1704697322, "time_this_iter_s": 185.93248200416565, "time_total_s": 16159.718719482422, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019D98B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16159.718719482422, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 21.559315589353613, "ram_util_percent": 47.322433460076056}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.26590456902040616, "mean_inference_ms": 1.0780817650811443, "mean_action_processing_ms": 0.056889797821291326, "mean_env_wait_ms": 7.460595674570369, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1660000, "timesteps_this_iter": 0, "agent_timesteps_total": 3320000, "timers": {"sample_time_ms": 234327.846, "sample_throughput": 85.351, "load_time_ms": 0.2, "load_throughput": 100234293.225, "learn_time_ms": 4777.119, "learn_throughput": 4186.624, "update_time_ms": 1.485}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.308722450212111e-25, "cur_lr": 0.0005, "total_loss": 60.28751831054687, "policy_loss": -0.001720840753242392, "vf_loss": 60.32045211791992, "vf_explained_var": 0.4137676239013672, "kl": 0.003689862722763454, "entropy": 3.12084379196167, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1660000, "num_agent_steps_sampled": 3320000, "num_steps_trained": 1660000, "num_agent_steps_trained": 3320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 165, "training_iteration": 83, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-05-06", "timestamp": 1704697506, "time_this_iter_s": 184.67633962631226, "time_total_s": 16344.395059108734, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019D9310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16344.395059108734, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 21.660919540229884, "ram_util_percent": 46.436015325670496}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.272125631733832, "mean_inference_ms": 1.076708783189752, "mean_action_processing_ms": 0.056837779772106474, "mean_env_wait_ms": 7.456406514197166, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1680000, "timesteps_this_iter": 0, "agent_timesteps_total": 3360000, "timers": {"sample_time_ms": 235813.882, "sample_throughput": 84.813, "load_time_ms": 0.2, "load_throughput": 100234293.225, "learn_time_ms": 4799.744, "learn_throughput": 4166.888, "update_time_ms": 1.585}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6543612251060554e-25, "cur_lr": 0.0005, "total_loss": 81.5676513671875, "policy_loss": -0.0016391068243979845, "vf_loss": 81.60023345947266, "vf_explained_var": 0.27730890512466433, "kl": 0.002707469816136077, "entropy": 3.094186544418335, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1680000, "num_agent_steps_sampled": 3360000, "num_steps_trained": 1680000, "num_agent_steps_trained": 3360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 167, "training_iteration": 84, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-08-14", "timestamp": 1704697694, "time_this_iter_s": 187.8379828929901, "time_total_s": 16532.233042001724, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16532.233042001724, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 22.76804511278195, "ram_util_percent": 46.767293233082704}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27828333423974827, "mean_inference_ms": 1.0754170245546089, "mean_action_processing_ms": 0.05678992577519743, "mean_env_wait_ms": 7.452507336912131, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1700000, "timesteps_this_iter": 0, "agent_timesteps_total": 3400000, "timers": {"sample_time_ms": 236585.542, "sample_throughput": 84.536, "load_time_ms": 0.299, "load_throughput": 66846824.448, "learn_time_ms": 4820.456, "learn_throughput": 4148.985, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.271806125530277e-26, "cur_lr": 0.0005, "total_loss": 65.62860946655273, "policy_loss": -0.0018889379760063997, "vf_loss": 65.6611946105957, "vf_explained_var": 0.38650922775268554, "kl": 0.0029292302116925573, "entropy": 3.069669246673584, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1700000, "num_agent_steps_sampled": 3400000, "num_steps_trained": 1700000, "num_agent_steps_trained": 3400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 169, "training_iteration": 85, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-11-17", "timestamp": 1704697877, "time_this_iter_s": 182.68163895606995, "time_total_s": 16714.914680957794, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16714.914680957794, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 20.437209302325577, "ram_util_percent": 46.38682170542636}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.28438372488838964, "mean_inference_ms": 1.0741963598417872, "mean_action_processing_ms": 0.05674375198288182, "mean_env_wait_ms": 7.448861932380998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1720000, "timesteps_this_iter": 0, "agent_timesteps_total": 3440000, "timers": {"sample_time_ms": 237556.548, "sample_throughput": 84.19, "load_time_ms": 0.299, "load_throughput": 66846824.448, "learn_time_ms": 4833.623, "learn_throughput": 4137.683, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.1359030627651386e-26, "cur_lr": 0.0005, "total_loss": 79.25858154296876, "policy_loss": -0.0021482531543076, "vf_loss": 79.29161224365234, "vf_explained_var": 0.4785720109939575, "kl": 0.0031735936360920646, "entropy": 3.0886169910430907, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1720000, "num_agent_steps_sampled": 3440000, "num_steps_trained": 1720000, "num_agent_steps_trained": 3440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 171, "training_iteration": 86, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-14-23", "timestamp": 1704698063, "time_this_iter_s": 186.35835981369019, "time_total_s": 16901.273040771484, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301993040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16901.273040771484, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 19.65909090909091, "ram_util_percent": 46.29659090909091}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2904254671129563, "mean_inference_ms": 1.0730338513224218, "mean_action_processing_ms": 0.05669958784793398, "mean_env_wait_ms": 7.445429704509249, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1740000, "timesteps_this_iter": 0, "agent_timesteps_total": 3480000, "timers": {"sample_time_ms": 237867.99, "sample_throughput": 84.08, "load_time_ms": 0.299, "load_throughput": 66846824.448, "learn_time_ms": 4839.409, "learn_throughput": 4132.736, "update_time_ms": 1.686}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.0679515313825693e-26, "cur_lr": 0.0005, "total_loss": 42.06422729492188, "policy_loss": -0.0018797906829230548, "vf_loss": 42.09731597900391, "vf_explained_var": 0.5173032999038696, "kl": 0.0028163052453883176, "entropy": 3.1207855224609373, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1740000, "num_agent_steps_sampled": 3480000, "num_steps_trained": 1740000, "num_agent_steps_trained": 3480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 173, "training_iteration": 87, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-17-22", "timestamp": 1704698242, "time_this_iter_s": 178.59364366531372, "time_total_s": 17079.866684436798, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019D9D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17079.866684436798, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 18.46324110671937, "ram_util_percent": 45.37272727272727}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29640371827776657, "mean_inference_ms": 1.0719238849963268, "mean_action_processing_ms": 0.05665673005052522, "mean_env_wait_ms": 7.442210177739234, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1760000, "timesteps_this_iter": 0, "agent_timesteps_total": 3520000, "timers": {"sample_time_ms": 238101.18, "sample_throughput": 83.998, "load_time_ms": 0.299, "load_throughput": 66846824.448, "learn_time_ms": 4837.191, "learn_throughput": 4134.631, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0339757656912847e-26, "cur_lr": 0.0005, "total_loss": 82.6860855102539, "policy_loss": -0.0019266637772135553, "vf_loss": 82.7190933227539, "vf_explained_var": 0.40525861978530886, "kl": 0.0024568465524675174, "entropy": 3.1088977813720704, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1760000, "num_agent_steps_sampled": 3520000, "num_steps_trained": 1760000, "num_agent_steps_trained": 3520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 175, "training_iteration": 88, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-20-21", "timestamp": 1704698421, "time_this_iter_s": 178.66946458816528, "time_total_s": 17258.536149024963, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17258.536149024963, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 20.36837944664032, "ram_util_percent": 45.27312252964427}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3023248892772329, "mean_inference_ms": 1.0708738951028587, "mean_action_processing_ms": 0.05661662354021253, "mean_env_wait_ms": 7.439221865835626, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1780000, "timesteps_this_iter": 0, "agent_timesteps_total": 3560000, "timers": {"sample_time_ms": 183838.702, "sample_throughput": 108.791, "load_time_ms": 0.399, "load_throughput": 50132122.154, "learn_time_ms": 4844.609, "learn_throughput": 4128.3, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.169878828456423e-27, "cur_lr": 0.0005, "total_loss": 83.5190658569336, "policy_loss": -0.0022959332942962263, "vf_loss": 83.55270843505859, "vf_explained_var": 0.36057056188583375, "kl": 0.0024973482916201386, "entropy": 3.134994649887085, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1780000, "num_agent_steps_sampled": 3560000, "num_steps_trained": 1780000, "num_agent_steps_trained": 3560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 177, "training_iteration": 89, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-23-24", "timestamp": 1704698604, "time_this_iter_s": 183.2472927570343, "time_total_s": 17441.783441781998, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017D1790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17441.783441781998, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 20.566409266409266, "ram_util_percent": 46.91351351351351}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3081885497037995, "mean_inference_ms": 1.0698692875609306, "mean_action_processing_ms": 0.05657597520554179, "mean_env_wait_ms": 7.436442058976061, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1800000, "timesteps_this_iter": 0, "agent_timesteps_total": 3600000, "timers": {"sample_time_ms": 183354.223, "sample_throughput": 109.078, "load_time_ms": 0.501, "load_throughput": 39909643.656, "learn_time_ms": 4811.355, "learn_throughput": 4156.833, "update_time_ms": 1.688}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.5849394142282116e-27, "cur_lr": 0.0005, "total_loss": 30.559568405151367, "policy_loss": -0.002052300579473343, "vf_loss": 30.592947006225586, "vf_explained_var": 0.5329096198081971, "kl": 0.0015678230950058492, "entropy": 3.1325363159179687, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1800000, "num_agent_steps_sampled": 3600000, "num_steps_trained": 1800000, "num_agent_steps_trained": 3600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 179, "training_iteration": 90, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-26-22", "timestamp": 1704698782, "time_this_iter_s": 178.04641819000244, "time_total_s": 17619.829859972, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F58B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17619.829859972, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 18.11388888888889, "ram_util_percent": 46.71904761904762}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31400276351985457, "mean_inference_ms": 1.0689649529392213, "mean_action_processing_ms": 0.05653767578481681, "mean_env_wait_ms": 7.433987588934795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1820000, "timesteps_this_iter": 0, "agent_timesteps_total": 3640000, "timers": {"sample_time_ms": 184328.087, "sample_throughput": 108.502, "load_time_ms": 0.601, "load_throughput": 33264366.722, "learn_time_ms": 5032.29, "learn_throughput": 3974.334, "update_time_ms": 1.591}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.2924697071141058e-27, "cur_lr": 0.0005, "total_loss": 128.89511108398438, "policy_loss": -0.0017350903062335998, "vf_loss": 128.92787017822266, "vf_explained_var": 0.37940911054611204, "kl": 0.003408687714113512, "entropy": 3.1030863761901855, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1820000, "num_agent_steps_sampled": 3640000, "num_steps_trained": 1820000, "num_agent_steps_trained": 3640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 181, "training_iteration": 91, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-29-41", "timestamp": 1704698981, "time_this_iter_s": 199.16944885253906, "time_total_s": 17818.99930882454, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019E8160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17818.99930882454, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 26.767259786476867, "ram_util_percent": 47.256227758007114}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31979117751231273, "mean_inference_ms": 1.068238067613299, "mean_action_processing_ms": 0.056506553232562824, "mean_env_wait_ms": 7.432163325815057, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1840000, "timesteps_this_iter": 0, "agent_timesteps_total": 3680000, "timers": {"sample_time_ms": 189537.759, "sample_throughput": 105.52, "load_time_ms": 0.501, "load_throughput": 39884975.276, "learn_time_ms": 5221.721, "learn_throughput": 3830.155, "update_time_ms": 1.591}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.462348535570529e-28, "cur_lr": 0.0005, "total_loss": 83.94426879882812, "policy_loss": -0.001557323251981302, "vf_loss": 83.97712860107421, "vf_explained_var": 0.4193622589111328, "kl": 0.003119884025713349, "entropy": 3.130201005935669, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1840000, "num_agent_steps_sampled": 3680000, "num_steps_trained": 1840000, "num_agent_steps_trained": 3680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 183, "training_iteration": 92, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-33-39", "timestamp": 1704699219, "time_this_iter_s": 237.6987612247467, "time_total_s": 18056.698070049286, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18056.698070049286, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 37.13928571428571, "ram_util_percent": 47.38303571428572}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32554630235905235, "mean_inference_ms": 1.067665279087928, "mean_action_processing_ms": 0.05648108687364797, "mean_env_wait_ms": 7.430884178341394, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1860000, "timesteps_this_iter": 0, "agent_timesteps_total": 3720000, "timers": {"sample_time_ms": 193998.009, "sample_throughput": 103.094, "load_time_ms": 0.502, "load_throughput": 39830055.553, "learn_time_ms": 5193.335, "learn_throughput": 3851.09, "update_time_ms": 1.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.2311742677852645e-28, "cur_lr": 0.0005, "total_loss": 25.854634857177736, "policy_loss": -0.0015046842162869112, "vf_loss": 25.887382888793944, "vf_explained_var": 0.5348878860473633, "kl": 0.003422304580666946, "entropy": 3.124421501159668, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1860000, "num_agent_steps_sampled": 3720000, "num_steps_trained": 1860000, "num_agent_steps_trained": 3720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 185, "training_iteration": 93, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-37-26", "timestamp": 1704699446, "time_this_iter_s": 227.08182454109192, "time_total_s": 18283.779894590378, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18283.779894590378, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 34.854517133956385, "ram_util_percent": 47.34859813084112}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3312619977688879, "mean_inference_ms": 1.0671873488901906, "mean_action_processing_ms": 0.05645929616745592, "mean_env_wait_ms": 7.429946283961176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1880000, "timesteps_this_iter": 0, "agent_timesteps_total": 3760000, "timers": {"sample_time_ms": 195525.518, "sample_throughput": 102.288, "load_time_ms": 0.502, "load_throughput": 39830055.553, "learn_time_ms": 5192.463, "learn_throughput": 3851.737, "update_time_ms": 1.491}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.6155871338926323e-28, "cur_lr": 0.0005, "total_loss": 92.14252014160157, "policy_loss": -0.00179013219239188, "vf_loss": 92.17548828125, "vf_explained_var": 0.35677300691604613, "kl": 0.002201313594133314, "entropy": 3.118126630783081, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1880000, "num_agent_steps_sampled": 3760000, "num_steps_trained": 1880000, "num_agent_steps_trained": 3760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 187, "training_iteration": 94, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-40-50", "timestamp": 1704699650, "time_this_iter_s": 203.39160776138306, "time_total_s": 18487.17150235176, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301739B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18487.17150235176, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 28.45208333333333, "ram_util_percent": 47.47708333333333}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33693470464364955, "mean_inference_ms": 1.0668002236664444, "mean_action_processing_ms": 0.05644107926559847, "mean_env_wait_ms": 7.42929168795566, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1900000, "timesteps_this_iter": 0, "agent_timesteps_total": 3800000, "timers": {"sample_time_ms": 197151.293, "sample_throughput": 101.445, "load_time_ms": 0.505, "load_throughput": 39626850.583, "learn_time_ms": 5172.74, "learn_throughput": 3866.423, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.077935669463161e-29, "cur_lr": 0.0005, "total_loss": 91.15523681640624, "policy_loss": -0.0017965939126722396, "vf_loss": 91.18843383789063, "vf_explained_var": 0.3952008247375488, "kl": 0.0037209645653900393, "entropy": 3.140310764312744, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1900000, "num_agent_steps_sampled": 3800000, "num_steps_trained": 1900000, "num_agent_steps_trained": 3800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 189, "training_iteration": 95, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-44-08", "timestamp": 1704699848, "time_this_iter_s": 198.75196599960327, "time_total_s": 18685.923468351364, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18685.923468351364, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 27.823487544483985, "ram_util_percent": 47.38718861209964}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3425541110858675, "mean_inference_ms": 1.0664405923985092, "mean_action_processing_ms": 0.0564241032270373, "mean_env_wait_ms": 7.428736322578291, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1920000, "timesteps_this_iter": 0, "agent_timesteps_total": 3840000, "timers": {"sample_time_ms": 196273.599, "sample_throughput": 101.899, "load_time_ms": 0.604, "load_throughput": 33121206.617, "learn_time_ms": 5170.16, "learn_throughput": 3868.352, "update_time_ms": 1.688}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.0389678347315807e-29, "cur_lr": 0.0005, "total_loss": 97.01829528808594, "policy_loss": -0.0019437864748761413, "vf_loss": 97.05123596191406, "vf_explained_var": 0.3689038157463074, "kl": 0.002038343951492427, "entropy": 3.0999494075775145, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1920000, "num_agent_steps_sampled": 3840000, "num_steps_trained": 1920000, "num_agent_steps_trained": 3840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 191, "training_iteration": 96, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-47-06", "timestamp": 1704700026, "time_this_iter_s": 177.7535262107849, "time_total_s": 18863.67699456215, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019ADAF0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18863.67699456215, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 18.211111111111112, "ram_util_percent": 47.15793650793651}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.34812264386582326, "mean_inference_ms": 1.0661202213079692, "mean_action_processing_ms": 0.05640870645314016, "mean_env_wait_ms": 7.428316218468269, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1940000, "timesteps_this_iter": 0, "agent_timesteps_total": 3880000, "timers": {"sample_time_ms": 196523.833, "sample_throughput": 101.769, "load_time_ms": 0.604, "load_throughput": 33121206.617, "learn_time_ms": 5204.806, "learn_throughput": 3842.603, "update_time_ms": 1.688}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.0194839173657903e-29, "cur_lr": 0.0005, "total_loss": 89.65970764160156, "policy_loss": -0.001780434554070176, "vf_loss": 89.69212799072265, "vf_explained_var": 0.4180688261985779, "kl": 0.0030455495789758202, "entropy": 3.063837242126465, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1940000, "num_agent_steps_sampled": 3880000, "num_steps_trained": 1940000, "num_agent_steps_trained": 3880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 193, "training_iteration": 97, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-50-08", "timestamp": 1704700208, "time_this_iter_s": 181.46533465385437, "time_total_s": 19045.142329216003, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A61F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19045.142329216003, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 21.084374999999998, "ram_util_percent": 47.475390624999996}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3536423394901677, "mean_inference_ms": 1.0658537015111893, "mean_action_processing_ms": 0.05639469739968563, "mean_env_wait_ms": 7.428019119747604, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1960000, "timesteps_this_iter": 0, "agent_timesteps_total": 3920000, "timers": {"sample_time_ms": 197236.979, "sample_throughput": 101.401, "load_time_ms": 0.604, "load_throughput": 33121206.617, "learn_time_ms": 5226.314, "learn_throughput": 3826.789, "update_time_ms": 1.785}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 0.0005, "total_loss": 88.91327362060547, "policy_loss": -0.0012036375547572753, "vf_loss": 88.94544830322266, "vf_explained_var": 0.46057151556015014, "kl": 0.008695123696581143, "entropy": 3.0969720840454102, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1960000, "num_agent_steps_sampled": 3920000, "num_steps_trained": 1960000, "num_agent_steps_trained": 3920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 195, "training_iteration": 98, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-53-13", "timestamp": 1704700393, "time_this_iter_s": 185.67214059829712, "time_total_s": 19230.8144698143, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19230.8144698143, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 23.865399239543727, "ram_util_percent": 49.046007604562746}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -252.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3591127141043202, "mean_inference_ms": 1.065636002692576, "mean_action_processing_ms": 0.05638208514839786, "mean_env_wait_ms": 7.4278604369547825, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1980000, "timesteps_this_iter": 0, "agent_timesteps_total": 3960000, "timers": {"sample_time_ms": 197915.891, "sample_throughput": 101.053, "load_time_ms": 0.604, "load_throughput": 33112054.946, "learn_time_ms": 5227.747, "learn_throughput": 3825.74, "update_time_ms": 1.685}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 0.0005, "total_loss": 152.43126220703124, "policy_loss": -0.001574125921018421, "vf_loss": 152.46351623535156, "vf_explained_var": 0.2902250289916992, "kl": 0.005036193188629312, "entropy": 3.0677052974700927, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1980000, "num_agent_steps_sampled": 3960000, "num_steps_trained": 1980000, "num_agent_steps_trained": 3960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 197, "training_iteration": 99, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_15-56-23", "timestamp": 1704700583, "time_this_iter_s": 189.8311128616333, "time_total_s": 19420.645582675934, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301739B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 19420.645582675934, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 24.98587360594795, "ram_util_percent": 49.37434944237918}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3645375999992167, "mean_inference_ms": 1.0654756585363614, "mean_action_processing_ms": 0.05637197556933168, "mean_env_wait_ms": 7.427904027355221, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2000000, "timesteps_this_iter": 0, "agent_timesteps_total": 4000000, "timers": {"sample_time_ms": 199550.074, "sample_throughput": 100.225, "load_time_ms": 0.602, "load_throughput": 33244592.399, "learn_time_ms": 5254.067, "learn_throughput": 3806.575, "update_time_ms": 1.682}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 0.0005, "total_loss": 93.8282974243164, "policy_loss": -0.00276696491863575, "vf_loss": 93.86212615966797, "vf_explained_var": 0.48201550245285035, "kl": 0.006979408097072093, "entropy": 3.1068889617919924, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2000000, "num_agent_steps_sampled": 4000000, "num_steps_trained": 2000000, "num_agent_steps_trained": 4000000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -440.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -220.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21495734509766123, "mean_inference_ms": 1.093260239622929, "mean_action_processing_ms": 0.056248347310983514, "mean_env_wait_ms": 7.4474949285827305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 199, "training_iteration": 100, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-14-40", "timestamp": 1704701680, "time_this_iter_s": 1096.6408755779266, "time_total_s": 20517.28645825386, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20517.28645825386, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 21.691494845360822, "ram_util_percent": 46.87442010309279}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -508.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -254.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3699170927101102, "mean_inference_ms": 1.065363254879344, "mean_action_processing_ms": 0.05636495124100503, "mean_env_wait_ms": 7.428059379724923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2020000, "timesteps_this_iter": 0, "agent_timesteps_total": 4040000, "timers": {"sample_time_ms": 288828.239, "sample_throughput": 69.245, "load_time_ms": 0.601, "load_throughput": 33259091.27, "learn_time_ms": 5103.179, "learn_throughput": 3919.126, "update_time_ms": 1.682}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 0.0005, "total_loss": 64.3606948852539, "policy_loss": -0.0017765733429417451, "vf_loss": 64.3935157775879, "vf_explained_var": 0.4992346286773682, "kl": 0.003894671818792972, "entropy": 3.1045957088470457, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2020000, "num_agent_steps_sampled": 4040000, "num_steps_trained": 2020000, "num_agent_steps_trained": 4040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 201, "training_iteration": 101, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-17-48", "timestamp": 1704701868, "time_this_iter_s": 188.14861679077148, "time_total_s": 20705.435075044632, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3016F2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20705.435075044632, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 22.122097378277154, "ram_util_percent": 45.218352059925095}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -506.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -253.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3752525865380255, "mean_inference_ms": 1.065292263160865, "mean_action_processing_ms": 0.056359176562759, "mean_env_wait_ms": 7.4283490422014395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2040000, "timesteps_this_iter": 0, "agent_timesteps_total": 4080000, "timers": {"sample_time_ms": 283636.131, "sample_throughput": 70.513, "load_time_ms": 0.701, "load_throughput": 28528798.803, "learn_time_ms": 4923.442, "learn_throughput": 4062.198, "update_time_ms": 1.585}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.048709793414476e-30, "cur_lr": 0.0005, "total_loss": 95.11527709960937, "policy_loss": -0.001811994838975295, "vf_loss": 95.14828948974609, "vf_explained_var": 0.2715738773345947, "kl": 0.003054963487625062, "entropy": 3.1207759857177733, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2040000, "num_agent_steps_sampled": 4080000, "num_steps_trained": 2040000, "num_agent_steps_trained": 4080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 203, "training_iteration": 102, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-20-54", "timestamp": 1704702054, "time_this_iter_s": 185.50099778175354, "time_total_s": 20890.936072826385, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD3A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 20890.936072826385, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 20.965019011406845, "ram_util_percent": 46.70038022813688}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3805444937867307, "mean_inference_ms": 1.065255148568764, "mean_action_processing_ms": 0.05635429016369151, "mean_env_wait_ms": 7.428703251330318, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2060000, "timesteps_this_iter": 0, "agent_timesteps_total": 4120000, "timers": {"sample_time_ms": 278951.28, "sample_throughput": 71.697, "load_time_ms": 0.601, "load_throughput": 33298697.999, "learn_time_ms": 4915.383, "learn_throughput": 4068.859, "update_time_ms": 1.683}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.524354896707238e-30, "cur_lr": 0.0005, "total_loss": 97.1559051513672, "policy_loss": -0.0025681547848506623, "vf_loss": 97.1892303466797, "vf_explained_var": 0.4139719128608704, "kl": 0.0028881737595656707, "entropy": 3.0759695053100584, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2060000, "num_agent_steps_sampled": 4120000, "num_steps_trained": 2060000, "num_agent_steps_trained": 4120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 205, "training_iteration": 103, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-23-56", "timestamp": 1704702236, "time_this_iter_s": 181.9698281288147, "time_total_s": 21072.9059009552, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21072.9059009552, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 20.004651162790697, "ram_util_percent": 46.29418604651162}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3857925596838082, "mean_inference_ms": 1.0652534906468716, "mean_action_processing_ms": 0.05634948651343082, "mean_env_wait_ms": 7.429124711385275, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2080000, "timesteps_this_iter": 0, "agent_timesteps_total": 4160000, "timers": {"sample_time_ms": 277037.845, "sample_throughput": 72.192, "load_time_ms": 0.699, "load_throughput": 28605653.879, "learn_time_ms": 4915.04, "learn_throughput": 4069.143, "update_time_ms": 1.683}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.262177448353619e-30, "cur_lr": 0.0005, "total_loss": 54.55061340332031, "policy_loss": -0.0027162761224433394, "vf_loss": 54.58445358276367, "vf_explained_var": 0.509253203868866, "kl": 0.004795303416251989, "entropy": 3.1122554779052733, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2080000, "num_agent_steps_sampled": 4160000, "num_steps_trained": 2080000, "num_agent_steps_trained": 4160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 207, "training_iteration": 104, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-27-00", "timestamp": 1704702420, "time_this_iter_s": 184.33967566490173, "time_total_s": 21257.245576620102, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019933A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21257.245576620102, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 19.94367816091954, "ram_util_percent": 46.22643678160919}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.39099833492273617, "mean_inference_ms": 1.0652845857754836, "mean_action_processing_ms": 0.056344898743001456, "mean_env_wait_ms": 7.429606860797277, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2100000, "timesteps_this_iter": 0, "agent_timesteps_total": 4200000, "timers": {"sample_time_ms": 275537.871, "sample_throughput": 72.585, "load_time_ms": 0.597, "load_throughput": 33504844.83, "learn_time_ms": 4982.599, "learn_throughput": 4013.97, "update_time_ms": 1.69}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.310887241768095e-31, "cur_lr": 0.0005, "total_loss": 91.23295288085937, "policy_loss": -0.0011283821000811045, "vf_loss": 91.2651870727539, "vf_explained_var": 0.44896153211593626, "kl": 0.003289895075815519, "entropy": 3.1106419563293457, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2100000, "num_agent_steps_sampled": 4200000, "num_steps_trained": 2100000, "num_agent_steps_trained": 4200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 209, "training_iteration": 105, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-30-04", "timestamp": 1704702604, "time_this_iter_s": 184.43477940559387, "time_total_s": 21441.680356025696, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21441.680356025696, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 20.631417624521074, "ram_util_percent": 45.48965517241379}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3961637786895624, "mean_inference_ms": 1.06535722370747, "mean_action_processing_ms": 0.056342378097113406, "mean_env_wait_ms": 7.4301678036363725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2120000, "timesteps_this_iter": 0, "agent_timesteps_total": 4240000, "timers": {"sample_time_ms": 276886.066, "sample_throughput": 72.232, "load_time_ms": 0.498, "load_throughput": 40177249.868, "learn_time_ms": 5003.285, "learn_throughput": 3997.374, "update_time_ms": 1.689}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.1554436208840474e-31, "cur_lr": 0.0005, "total_loss": 124.76701354980469, "policy_loss": -0.002427859985865766, "vf_loss": 124.80041809082032, "vf_explained_var": 0.3936791896820068, "kl": 0.0045335549641807305, "entropy": 3.0974025249481203, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2120000, "num_agent_steps_sampled": 4240000, "num_steps_trained": 2120000, "num_agent_steps_trained": 4240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 211, "training_iteration": 106, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-33-15", "timestamp": 1704702795, "time_this_iter_s": 190.7397038936615, "time_total_s": 21632.420059919357, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017D1790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21632.420059919357, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 22.298148148148147, "ram_util_percent": 46.29555555555555}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40129216734880946, "mean_inference_ms": 1.065471509091831, "mean_action_processing_ms": 0.056342046098523155, "mean_env_wait_ms": 7.4308687612585285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2140000, "timesteps_this_iter": 0, "agent_timesteps_total": 4280000, "timers": {"sample_time_ms": 278066.715, "sample_throughput": 71.925, "load_time_ms": 0.498, "load_throughput": 40177249.868, "learn_time_ms": 4999.023, "learn_throughput": 4000.782, "update_time_ms": 1.692}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5777218104420237e-31, "cur_lr": 0.0005, "total_loss": 188.48928833007812, "policy_loss": -0.0019651132666506756, "vf_loss": 188.52212524414062, "vf_explained_var": 0.20225851535797118, "kl": 0.003547988327870355, "entropy": 3.0869373798370363, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2140000, "num_agent_steps_sampled": 4280000, "num_steps_trained": 2140000, "num_agent_steps_trained": 4280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 213, "training_iteration": 107, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-36-28", "timestamp": 1704702988, "time_this_iter_s": 193.0270392894745, "time_total_s": 21825.44709920883, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 21825.44709920883, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 23.34343065693431, "ram_util_percent": 46.66459854014598}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.40638211262310386, "mean_inference_ms": 1.065625889237292, "mean_action_processing_ms": 0.05634356094555317, "mean_env_wait_ms": 7.431639734893809, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2160000, "timesteps_this_iter": 0, "agent_timesteps_total": 4320000, "timers": {"sample_time_ms": 278244.708, "sample_throughput": 71.879, "load_time_ms": 0.498, "load_throughput": 40177249.868, "learn_time_ms": 4986.492, "learn_throughput": 4010.836, "update_time_ms": 1.692}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.888609052210118e-32, "cur_lr": 0.0005, "total_loss": 169.820947265625, "policy_loss": -0.0019359571423567701, "vf_loss": 169.85310974121094, "vf_explained_var": 0.26782981157302854, "kl": 0.006803390826989375, "entropy": 3.022411584854126, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2160000, "num_agent_steps_sampled": 4320000, "num_steps_trained": 2160000, "num_agent_steps_trained": 4320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 215, "training_iteration": 108, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-39-36", "timestamp": 1704703176, "time_this_iter_s": 187.36614966392517, "time_total_s": 22012.813248872757, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019933A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22012.813248872757, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 24.768301886792454, "ram_util_percent": 48.841509433962266}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -501.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4114285227638018, "mean_inference_ms": 1.0657987709213206, "mean_action_processing_ms": 0.05634645058507548, "mean_env_wait_ms": 7.432471590267826, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2180000, "timesteps_this_iter": 0, "agent_timesteps_total": 4360000, "timers": {"sample_time_ms": 277211.097, "sample_throughput": 72.147, "load_time_ms": 0.398, "load_throughput": 50267305.849, "learn_time_ms": 4988.4, "learn_throughput": 4009.301, "update_time_ms": 1.689}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.888609052210118e-32, "cur_lr": 0.0005, "total_loss": 41.827728271484375, "policy_loss": -0.0013748963120207235, "vf_loss": 41.85956573486328, "vf_explained_var": 0.434462571144104, "kl": 0.0030495241458439624, "entropy": 3.0465145111083984, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2180000, "num_agent_steps_sampled": 4360000, "num_steps_trained": 2180000, "num_agent_steps_trained": 4360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 217, "training_iteration": 109, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-42-35", "timestamp": 1704703355, "time_this_iter_s": 179.6422154903412, "time_total_s": 22192.455464363098, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22192.455464363098, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 18.915354330708663, "ram_util_percent": 48.41062992125984}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41643292089096634, "mean_inference_ms": 1.065987526237785, "mean_action_processing_ms": 0.0563503288593034, "mean_env_wait_ms": 7.4333428806348305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2200000, "timesteps_this_iter": 0, "agent_timesteps_total": 4400000, "timers": {"sample_time_ms": 275425.121, "sample_throughput": 72.615, "load_time_ms": 0.298, "load_throughput": 67092761.737, "learn_time_ms": 4970.741, "learn_throughput": 4023.545, "update_time_ms": 1.69}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.944304526105059e-32, "cur_lr": 0.0005, "total_loss": 85.06670989990235, "policy_loss": -0.002094307302422749, "vf_loss": 85.09952850341797, "vf_explained_var": 0.5222859025001526, "kl": 0.004131486464732603, "entropy": 3.0728493213653563, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2200000, "num_agent_steps_sampled": 4400000, "num_steps_trained": 2200000, "num_agent_steps_trained": 4400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 219, "training_iteration": 110, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-45-32", "timestamp": 1704703532, "time_this_iter_s": 176.58092761039734, "time_total_s": 22369.036391973495, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019BAD30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22369.036391973495, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 18.913654618473895, "ram_util_percent": 48.46546184738956}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42139544606864776, "mean_inference_ms": 1.0661966135029788, "mean_action_processing_ms": 0.05635572875756976, "mean_env_wait_ms": 7.434269370598213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2220000, "timesteps_this_iter": 0, "agent_timesteps_total": 4440000, "timers": {"sample_time_ms": 184484.711, "sample_throughput": 108.41, "load_time_ms": 0.198, "load_throughput": 100885243.536, "learn_time_ms": 4909.139, "learn_throughput": 4074.034, "update_time_ms": 1.693}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9721522630525296e-32, "cur_lr": 0.0005, "total_loss": 86.6401611328125, "policy_loss": -0.0019351953163370573, "vf_loss": 86.67269592285156, "vf_explained_var": 0.5189793586730957, "kl": 0.0031208075592055627, "entropy": 3.0600085735321043, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2220000, "num_agent_steps_sampled": 4440000, "num_steps_trained": 2220000, "num_agent_steps_trained": 4440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 221, "training_iteration": 111, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-48-32", "timestamp": 1704703712, "time_this_iter_s": 180.3306005001068, "time_total_s": 22549.366992473602, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC1F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22549.366992473602, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 19.580392156862747, "ram_util_percent": 48.47058823529411}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.42632393631832827, "mean_inference_ms": 1.0664399798914141, "mean_action_processing_ms": 0.056363073713408054, "mean_env_wait_ms": 7.435276497904175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2240000, "timesteps_this_iter": 0, "agent_timesteps_total": 4480000, "timers": {"sample_time_ms": 184615.141, "sample_throughput": 108.333, "load_time_ms": 0.099, "load_throughput": 202966561.82, "learn_time_ms": 4929.603, "learn_throughput": 4057.122, "update_time_ms": 2.188}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.860761315262648e-33, "cur_lr": 0.0005, "total_loss": 85.21494903564454, "policy_loss": -0.0022669874422252432, "vf_loss": 85.24772796630859, "vf_explained_var": 0.4921274304389954, "kl": 0.003141781434896318, "entropy": 3.0506259918212892, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2240000, "num_agent_steps_sampled": 4480000, "num_steps_trained": 2240000, "num_agent_steps_trained": 4480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 223, "training_iteration": 112, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-51-40", "timestamp": 1704703900, "time_this_iter_s": 187.63621163368225, "time_total_s": 22737.003204107285, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019AD280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22737.003204107285, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 25.944905660377362, "ram_util_percent": 48.487547169811315}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -501.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4312160538103491, "mean_inference_ms": 1.0667240413071304, "mean_action_processing_ms": 0.056372150253252366, "mean_env_wait_ms": 7.4364418403096035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2260000, "timesteps_this_iter": 0, "agent_timesteps_total": 4520000, "timers": {"sample_time_ms": 185627.782, "sample_throughput": 107.742, "load_time_ms": 0.099, "load_throughput": 202966561.82, "learn_time_ms": 4969.019, "learn_throughput": 4024.939, "update_time_ms": 2.187}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 0.0005, "total_loss": 226.83189697265624, "policy_loss": -0.0027366802649572363, "vf_loss": 226.86532897949218, "vf_explained_var": 0.23826690912246704, "kl": 0.0052788206301175086, "entropy": 3.069993257522583, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2260000, "num_agent_steps_sampled": 4520000, "num_steps_trained": 2260000, "num_agent_steps_trained": 4520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 225, "training_iteration": 113, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-54-52", "timestamp": 1704704092, "time_this_iter_s": 192.2764608860016, "time_total_s": 22929.279664993286, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019ADA60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 22929.279664993286, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 25.135294117647057, "ram_util_percent": 48.77058823529411}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -501.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43607114804899283, "mean_inference_ms": 1.067032139877107, "mean_action_processing_ms": 0.05638279793332174, "mean_env_wait_ms": 7.437660442284439, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2280000, "timesteps_this_iter": 0, "agent_timesteps_total": 4560000, "timers": {"sample_time_ms": 185358.415, "sample_throughput": 107.899, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4974.979, "learn_throughput": 4020.118, "update_time_ms": 2.091}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 0.0005, "total_loss": 57.080264282226565, "policy_loss": -0.0017227620069496298, "vf_loss": 57.112571716308594, "vf_explained_var": 0.5394472599029541, "kl": 0.00785410100252477, "entropy": 3.0581146240234376, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2280000, "num_agent_steps_sampled": 4560000, "num_steps_trained": 2280000, "num_agent_steps_trained": 4560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 227, "training_iteration": 114, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_16-57-54", "timestamp": 1704704274, "time_this_iter_s": 181.30659365653992, "time_total_s": 23110.586258649826, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23110.586258649826, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 21.1875, "ram_util_percent": 48.85390625000001}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -501.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4408943803387881, "mean_inference_ms": 1.0673765659260517, "mean_action_processing_ms": 0.056395051982517375, "mean_env_wait_ms": 7.439013798318981, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2300000, "timesteps_this_iter": 0, "agent_timesteps_total": 4600000, "timers": {"sample_time_ms": 186110.689, "sample_throughput": 107.463, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4941.918, "learn_throughput": 4047.011, "update_time_ms": 1.987}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 0.0005, "total_loss": 97.20565490722656, "policy_loss": -0.0020041747224703423, "vf_loss": 97.23816986083985, "vf_explained_var": 0.5144616603851319, "kl": 0.0037728597406360143, "entropy": 3.0510074138641357, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2300000, "num_agent_steps_sampled": 4600000, "num_steps_trained": 2300000, "num_agent_steps_trained": 4600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 229, "training_iteration": 115, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-01-05", "timestamp": 1704704465, "time_this_iter_s": 191.55601406097412, "time_total_s": 23302.1422727108, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017D1790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23302.1422727108, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 25.733948339483398, "ram_util_percent": 49.226199261992626}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4456793257491736, "mean_inference_ms": 1.0677363581117851, "mean_action_processing_ms": 0.056408313595358736, "mean_env_wait_ms": 7.440423132360547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2320000, "timesteps_this_iter": 0, "agent_timesteps_total": 4640000, "timers": {"sample_time_ms": 184974.028, "sample_throughput": 108.123, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4944.431, "learn_throughput": 4044.954, "update_time_ms": 1.887}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.465190328815662e-33, "cur_lr": 0.0005, "total_loss": 81.0974609375, "policy_loss": -0.0019299496515095243, "vf_loss": 81.12981719970703, "vf_explained_var": 0.46535714864730837, "kl": 0.00340561936790893, "entropy": 3.042715549468994, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2320000, "num_agent_steps_sampled": 4640000, "num_steps_trained": 2320000, "num_agent_steps_trained": 4640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 231, "training_iteration": 116, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-04-05", "timestamp": 1704704645, "time_this_iter_s": 179.75606274604797, "time_total_s": 23481.898335456848, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301634F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23481.898335456848, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 19.121653543307087, "ram_util_percent": 48.62204724409449}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.45042940115981184, "mean_inference_ms": 1.068119260334805, "mean_action_processing_ms": 0.05642221315810556, "mean_env_wait_ms": 7.441902321322184, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2340000, "timesteps_this_iter": 0, "agent_timesteps_total": 4680000, "timers": {"sample_time_ms": 184077.465, "sample_throughput": 108.65, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5022.808, "learn_throughput": 3981.836, "update_time_ms": 1.887}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.232595164407831e-33, "cur_lr": 0.0005, "total_loss": 87.54552307128907, "policy_loss": -0.0023147265704348773, "vf_loss": 87.57765045166016, "vf_explained_var": 0.4766197204589844, "kl": 0.002953355085799636, "entropy": 2.9814585208892823, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2340000, "num_agent_steps_sampled": 4680000, "num_steps_trained": 2340000, "num_agent_steps_trained": 4680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 233, "training_iteration": 117, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-07-10", "timestamp": 1704704830, "time_this_iter_s": 184.81601691246033, "time_total_s": 23666.71435236931, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC5E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23666.71435236931, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 21.89618320610687, "ram_util_percent": 48.94961832061069}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -200.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4551382371003361, "mean_inference_ms": 1.0685123857058676, "mean_action_processing_ms": 0.05643608250638664, "mean_env_wait_ms": 7.443420340631473, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2360000, "timesteps_this_iter": 0, "agent_timesteps_total": 4720000, "timers": {"sample_time_ms": 183062.91, "sample_throughput": 109.252, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5037.395, "learn_throughput": 3970.306, "update_time_ms": 1.791}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.162975822039155e-34, "cur_lr": 0.0005, "total_loss": 44.98639755249023, "policy_loss": -0.0017096302000805725, "vf_loss": 45.01749267578125, "vf_explained_var": 0.6408533692359925, "kl": 0.004122129587253376, "entropy": 2.9382842063903807, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2360000, "num_agent_steps_sampled": 4720000, "num_steps_trained": 2360000, "num_agent_steps_trained": 4720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 235, "training_iteration": 118, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-10-06", "timestamp": 1704705006, "time_this_iter_s": 176.5840756893158, "time_total_s": 23843.298428058624, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A6430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 23843.298428058624, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 19.334, "ram_util_percent": 48.9788}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -247.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.45981032902101676, "mean_inference_ms": 1.0689146508545733, "mean_action_processing_ms": 0.05645070954991756, "mean_env_wait_ms": 7.444947651180522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2380000, "timesteps_this_iter": 0, "agent_timesteps_total": 4760000, "timers": {"sample_time_ms": 183021.997, "sample_throughput": 109.276, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5052.897, "learn_throughput": 3958.126, "update_time_ms": 1.891}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0814879110195775e-34, "cur_lr": 0.0005, "total_loss": 76.05667724609376, "policy_loss": -0.0014935381650738489, "vf_loss": 76.08831481933593, "vf_explained_var": 0.5343523859977722, "kl": 0.00477960069884562, "entropy": 3.014566993713379, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2380000, "num_agent_steps_sampled": 4760000, "num_steps_trained": 2380000, "num_agent_steps_trained": 4760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 237, "training_iteration": 119, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-13-06", "timestamp": 1704705186, "time_this_iter_s": 179.2417438030243, "time_total_s": 24022.54017186165, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D301638E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24022.54017186165, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 19.238976377952756, "ram_util_percent": 48.889370078740164}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -248.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.46444835253009076, "mean_inference_ms": 1.0693360668786525, "mean_action_processing_ms": 0.05646486984576347, "mean_env_wait_ms": 7.446550349409327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2400000, "timesteps_this_iter": 0, "agent_timesteps_total": 4800000, "timers": {"sample_time_ms": 183706.822, "sample_throughput": 108.869, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5082.729, "learn_throughput": 3934.894, "update_time_ms": 1.794}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.5407439555097888e-34, "cur_lr": 0.0005, "total_loss": 65.73327331542968, "policy_loss": -0.0024039322022721523, "vf_loss": 65.76571044921874, "vf_explained_var": 0.6277292490005493, "kl": 0.002626480279180399, "entropy": 3.0035494804382323, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2400000, "num_agent_steps_sampled": 4800000, "num_steps_trained": 2400000, "num_agent_steps_trained": 4800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 239, "training_iteration": 120, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-16-09", "timestamp": 1704705369, "time_this_iter_s": 183.56916165351868, "time_total_s": 24206.109333515167, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017A61F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24206.109333515167, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 20.697307692307692, "ram_util_percent": 49.550769230769234}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -249.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4690511413902286, "mean_inference_ms": 1.0697712419295293, "mean_action_processing_ms": 0.056479777663938385, "mean_env_wait_ms": 7.448210900276776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2420000, "timesteps_this_iter": 0, "agent_timesteps_total": 4840000, "timers": {"sample_time_ms": 183678.02, "sample_throughput": 108.886, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5098.58, "learn_throughput": 3922.661, "update_time_ms": 1.888}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.703719777548944e-35, "cur_lr": 0.0005, "total_loss": 42.50461654663086, "policy_loss": -0.002409736740626389, "vf_loss": 42.53683166503906, "vf_explained_var": 0.6115929961204529, "kl": 0.0044425903983630775, "entropy": 2.9802486896514893, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2420000, "num_agent_steps_sampled": 4840000, "num_steps_trained": 2420000, "num_agent_steps_trained": 4840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 241, "training_iteration": 121, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-19-09", "timestamp": 1704705549, "time_this_iter_s": 179.90281200408936, "time_total_s": 24386.012145519257, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC0D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24386.012145519257, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 19.88346456692913, "ram_util_percent": 49.31496062992126}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4736220818143353, "mean_inference_ms": 1.0702237514353785, "mean_action_processing_ms": 0.05649556094051384, "mean_env_wait_ms": 7.449964817049169, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2440000, "timesteps_this_iter": 0, "agent_timesteps_total": 4880000, "timers": {"sample_time_ms": 183381.824, "sample_throughput": 109.062, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5120.82, "learn_throughput": 3905.624, "update_time_ms": 1.49}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 0.0005, "total_loss": 182.17888488769532, "policy_loss": -0.001829648843556697, "vf_loss": 182.21066284179688, "vf_explained_var": 0.1340782880783081, "kl": 0.006094860579389705, "entropy": 2.9948002338409423, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2440000, "num_agent_steps_sampled": 4880000, "num_steps_trained": 2440000, "num_agent_steps_trained": 4880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 243, "training_iteration": 122, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-22-14", "timestamp": 1704705734, "time_this_iter_s": 184.7201111316681, "time_total_s": 24570.732256650925, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24570.732256650925, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 20.71679389312977, "ram_util_percent": 49.20038167938932}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -501.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -250.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4781645400194948, "mean_inference_ms": 1.0707003299267008, "mean_action_processing_ms": 0.05651197321335486, "mean_env_wait_ms": 7.4517648573289295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2460000, "timesteps_this_iter": 0, "agent_timesteps_total": 4920000, "timers": {"sample_time_ms": 182598.667, "sample_throughput": 109.53, "load_time_ms": 0.1, "load_throughput": 200540473.344, "learn_time_ms": 5093.807, "learn_throughput": 3926.337, "update_time_ms": 1.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 0.0005, "total_loss": 129.922509765625, "policy_loss": -0.0025250621591508373, "vf_loss": 129.95491638183594, "vf_explained_var": 0.3869249224662781, "kl": 0.0108414600163661, "entropy": 2.9885090351104737, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2460000, "num_agent_steps_sampled": 4920000, "num_steps_trained": 2460000, "num_agent_steps_trained": 4920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 245, "training_iteration": 123, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-25-18", "timestamp": 1704705918, "time_this_iter_s": 183.96017813682556, "time_total_s": 24754.69243478775, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019DC1F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24754.69243478775, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 22.87846153846154, "ram_util_percent": 49.42192307692307}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4826741798230438, "mean_inference_ms": 1.0711861901324127, "mean_action_processing_ms": 0.05652983577971241, "mean_env_wait_ms": 7.453605059136768, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2480000, "timesteps_this_iter": 0, "agent_timesteps_total": 4960000, "timers": {"sample_time_ms": 182266.101, "sample_throughput": 109.73, "load_time_ms": 0.1, "load_throughput": 200540473.344, "learn_time_ms": 5098.373, "learn_throughput": 3922.82, "update_time_ms": 1.492}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 0.0005, "total_loss": 46.812931823730466, "policy_loss": -0.0017567878109030488, "vf_loss": 46.845341491699216, "vf_explained_var": 0.6545457005500793, "kl": 0.00710414827839716, "entropy": 3.0652563095092775, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2480000, "num_agent_steps_sampled": 4960000, "num_steps_trained": 2480000, "num_agent_steps_trained": 4960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 247, "training_iteration": 124, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-28-16", "timestamp": 1704706096, "time_this_iter_s": 178.29608631134033, "time_total_s": 24932.98852109909, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3019D7790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 24932.98852109909, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 19.193675889328063, "ram_util_percent": 48.3905138339921}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.48714975061154303, "mean_inference_ms": 1.0716758531060113, "mean_action_processing_ms": 0.05654819072779017, "mean_env_wait_ms": 7.45545193012586, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2500000, "timesteps_this_iter": 0, "agent_timesteps_total": 5000000, "timers": {"sample_time_ms": 180725.313, "sample_throughput": 110.665, "load_time_ms": 0.2, "load_throughput": 100222317.802, "learn_time_ms": 5087.514, "learn_throughput": 3931.193, "update_time_ms": 1.49}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 0.0005, "total_loss": 100.37879791259766, "policy_loss": -0.001524629110554232, "vf_loss": 100.41138153076172, "vf_explained_var": 0.42450268268585206, "kl": 0.0047715027810594805, "entropy": 3.1059032440185548, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2500000, "num_agent_steps_sampled": 5000000, "num_steps_trained": 2500000, "num_agent_steps_trained": 5000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 249, "training_iteration": 125, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-31-12", "timestamp": 1704706272, "time_this_iter_s": 175.99593043327332, "time_total_s": 25108.984451532364, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F50D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25108.984451532364, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 18.410400000000003, "ram_util_percent": 47.6192}}
{"episode_reward_max": -308.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.08, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -154.0}, "policy_reward_mean": {"shared_policy": -251.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -308.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -154.0, -154.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.491592353924619, "mean_inference_ms": 1.072170216893017, "mean_action_processing_ms": 0.05656746867935364, "mean_env_wait_ms": 7.457273253987467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2520000, "timesteps_this_iter": 0, "agent_timesteps_total": 5040000, "timers": {"sample_time_ms": 180264.346, "sample_throughput": 110.948, "load_time_ms": 0.299, "load_throughput": 66841498.008, "learn_time_ms": 5106.896, "learn_throughput": 3916.273, "update_time_ms": 1.587}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 0.0005, "total_loss": 39.545206451416014, "policy_loss": -0.001779142577108006, "vf_loss": 39.5779167175293, "vf_explained_var": 0.685260820388794, "kl": 0.0037577397458964158, "entropy": 3.092919111251831, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2520000, "num_agent_steps_sampled": 5040000, "num_steps_trained": 2520000, "num_agent_steps_trained": 5040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 251, "training_iteration": 126, "trial_id": "2de53_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-08_17-34-08", "timestamp": 1704706448, "time_this_iter_s": 175.4513018131256, "time_total_s": 25284.43575334549, "pid": 7232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001D3017F5EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 25284.43575334549, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 19.43185483870968, "ram_util_percent": 46.46129032258064}}

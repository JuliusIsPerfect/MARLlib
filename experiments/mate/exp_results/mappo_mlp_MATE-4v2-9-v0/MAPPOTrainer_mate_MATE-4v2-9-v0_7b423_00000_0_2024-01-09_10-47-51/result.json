{"episode_reward_max": -600.0, "episode_reward_min": -600.0, "episode_reward_mean": -600.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -300.0}, "policy_reward_mean": {"shared_policy": -300.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0], "episode_lengths": [10001], "policy_shared_policy_reward": [-300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18899629464251275, "mean_inference_ms": 1.0390668134439958, "mean_action_processing_ms": 0.05385490794353715, "mean_env_wait_ms": 7.557301323185336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2420000, "timesteps_this_iter": 0, "agent_timesteps_total": 4840000, "timers": {"sample_time_ms": 177274.577, "sample_throughput": 112.819, "load_time_ms": 1.027, "load_throughput": 19467644.465, "learn_time_ms": 4810.613, "learn_throughput": 4157.474, "update_time_ms": 1.997}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 1e-10, "total_loss": 75.5158462524414, "policy_loss": -0.004333658619597535, "vf_loss": 75.54928283691406, "vf_explained_var": 0.5933724761009216, "kl": 0.005410503755780028, "entropy": 3.018729734420776, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2420000, "num_agent_steps_sampled": 4840000, "num_steps_trained": 2420000, "num_agent_steps_trained": 4840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 240, "training_iteration": 121, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_10-50-59", "timestamp": 1704768659, "time_this_iter_s": 182.0253803730011, "time_total_s": 24388.13471388817, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 182.0253803730011, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 19.06756756756757, "ram_util_percent": 54.92084942084943}}
{"episode_reward_max": -600.0, "episode_reward_min": -600.0, "episode_reward_mean": -600.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -300.0}, "policy_reward_mean": {"shared_policy": -300.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20664580084116904, "mean_inference_ms": 1.0735972063913677, "mean_action_processing_ms": 0.05657835442958137, "mean_env_wait_ms": 7.627447555223026, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2440000, "timesteps_this_iter": 0, "agent_timesteps_total": 4880000, "timers": {"sample_time_ms": 183394.414, "sample_throughput": 109.055, "load_time_ms": 1.013, "load_throughput": 19747193.974, "learn_time_ms": 4912.14, "learn_throughput": 4071.545, "update_time_ms": 1.511}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 1e-10, "total_loss": 61.302153778076175, "policy_loss": -0.002225375028718268, "vf_loss": 61.33407745361328, "vf_explained_var": 0.5597761631011963, "kl": 0.0025423442425362543, "entropy": 3.020535945892334, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2440000, "num_agent_steps_sampled": 4880000, "num_steps_trained": 2440000, "num_agent_steps_trained": 4880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 242, "training_iteration": 122, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_10-54-09", "timestamp": 1704768849, "time_this_iter_s": 189.66938138008118, "time_total_s": 24577.80409526825, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 371.6947617530823, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 21.78694029850746, "ram_util_percent": 58.561940298507466}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -520.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -260.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21422769797222768, "mean_inference_ms": 1.091696038835815, "mean_action_processing_ms": 0.05750119314715603, "mean_env_wait_ms": 7.685413499687229, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2460000, "timesteps_this_iter": 0, "agent_timesteps_total": 4920000, "timers": {"sample_time_ms": 187233.138, "sample_throughput": 106.819, "load_time_ms": 0.675, "load_throughput": 29620790.96, "learn_time_ms": 4907.202, "learn_throughput": 4075.642, "update_time_ms": 1.672}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 1e-10, "total_loss": 46.98563461303711, "policy_loss": -0.0030084370182080987, "vf_loss": 47.01826095581055, "vf_explained_var": 0.6258609294891357, "kl": 0.002736621496458547, "entropy": 2.9891361713409426, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2460000, "num_agent_steps_sampled": 4920000, "num_steps_trained": 2460000, "num_agent_steps_trained": 4920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 244, "training_iteration": 123, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_10-57-24", "timestamp": 1704769044, "time_this_iter_s": 194.76021361351013, "time_total_s": 24772.56430888176, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 566.4549753665924, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 22.584420289855075, "ram_util_percent": 57.552173913043475}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -542.8571428571429, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -271.42857142857144}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2192896589697594, "mean_inference_ms": 1.1020070605815488, "mean_action_processing_ms": 0.05782961409913882, "mean_env_wait_ms": 7.714334216424289, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2480000, "timesteps_this_iter": 0, "agent_timesteps_total": 4960000, "timers": {"sample_time_ms": 188218.352, "sample_throughput": 106.26, "load_time_ms": 0.762, "load_throughput": 26243103.394, "learn_time_ms": 4961.474, "learn_throughput": 4031.06, "update_time_ms": 2.003}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 1e-10, "total_loss": 103.54175567626953, "policy_loss": -0.0026381624010950234, "vf_loss": 103.57489776611328, "vf_explained_var": 0.5617977499961853, "kl": 0.004851747289268893, "entropy": 3.0747960567474366, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2480000, "num_agent_steps_sampled": 4960000, "num_steps_trained": 2480000, "num_agent_steps_trained": 4960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 246, "training_iteration": 124, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-00-35", "timestamp": 1704769235, "time_this_iter_s": 191.37932062149048, "time_total_s": 24963.94362950325, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 757.8342959880829, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 22.811439114391142, "ram_util_percent": 56.035793357933585}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -533.3333333333334, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -266.6666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22270922581978234, "mean_inference_ms": 1.1085779389302484, "mean_action_processing_ms": 0.05794206350627092, "mean_env_wait_ms": 7.731214606274652, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2500000, "timesteps_this_iter": 0, "agent_timesteps_total": 5000000, "timers": {"sample_time_ms": 188701.956, "sample_throughput": 105.987, "load_time_ms": 0.623, "load_throughput": 32095990.205, "learn_time_ms": 4979.052, "learn_throughput": 4016.829, "update_time_ms": 2.001}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 1e-10, "total_loss": 72.39438171386719, "policy_loss": -0.0020384142357483537, "vf_loss": 72.42743530273438, "vf_explained_var": 0.6180365562438965, "kl": 0.0034629172687331788, "entropy": 3.1103031158447267, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2500000, "num_agent_steps_sampled": 5000000, "num_steps_trained": 2500000, "num_agent_steps_trained": 5000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 248, "training_iteration": 125, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-03-46", "timestamp": 1704769426, "time_this_iter_s": 190.52665424346924, "time_total_s": 25154.47028374672, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443DBC10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 948.3609502315521, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 23.094074074074076, "ram_util_percent": 55.19555555555555}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -545.4545454545455, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -272.72727272727275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22538812821749607, "mean_inference_ms": 1.1134129946430258, "mean_action_processing_ms": 0.058020286373832344, "mean_env_wait_ms": 7.741207434304095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2520000, "timesteps_this_iter": 0, "agent_timesteps_total": 5040000, "timers": {"sample_time_ms": 188927.127, "sample_throughput": 105.861, "load_time_ms": 0.519, "load_throughput": 38515188.246, "learn_time_ms": 5001.325, "learn_throughput": 3998.94, "update_time_ms": 1.996}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 1e-10, "total_loss": 58.70529479980469, "policy_loss": -0.002517444246895595, "vf_loss": 58.73826217651367, "vf_explained_var": 0.599661922454834, "kl": 0.003184648272196089, "entropy": 3.0489792346954347, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2520000, "num_agent_steps_sampled": 5040000, "num_steps_trained": 2520000, "num_agent_steps_trained": 5040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 250, "training_iteration": 126, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-06-56", "timestamp": 1704769616, "time_this_iter_s": 190.0817427635193, "time_total_s": 25344.55202651024, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B71F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1138.4426929950714, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 22.92267657992565, "ram_util_percent": 54.91263940520446}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -538.4615384615385, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -269.2307692307692}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22749883931167234, "mean_inference_ms": 1.116770956755592, "mean_action_processing_ms": 0.05805386410399138, "mean_env_wait_ms": 7.7462973406775655, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2540000, "timesteps_this_iter": 0, "agent_timesteps_total": 5080000, "timers": {"sample_time_ms": 188859.057, "sample_throughput": 105.899, "load_time_ms": 0.445, "load_throughput": 44934386.287, "learn_time_ms": 5003.175, "learn_throughput": 3997.462, "update_time_ms": 1.996}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 1e-10, "total_loss": 85.98949890136718, "policy_loss": -0.0014445497965440257, "vf_loss": 86.0212173461914, "vf_explained_var": 0.6280435919761658, "kl": 0.0038665245554980743, "entropy": 3.030070686340332, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2540000, "num_agent_steps_sampled": 5080000, "num_steps_trained": 2540000, "num_agent_steps_trained": 5080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 252, "training_iteration": 127, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-10-04", "timestamp": 1704769804, "time_this_iter_s": 188.33113837242126, "time_total_s": 25532.88316488266, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044329D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1326.7738313674927, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 23.016165413533834, "ram_util_percent": 53.283458646616545}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -533.3333333333334, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -266.6666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22894072966414222, "mean_inference_ms": 1.1187797412030245, "mean_action_processing_ms": 0.058084462314011584, "mean_env_wait_ms": 7.747829400404424, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2560000, "timesteps_this_iter": 0, "agent_timesteps_total": 5120000, "timers": {"sample_time_ms": 188535.093, "sample_throughput": 106.081, "load_time_ms": 0.389, "load_throughput": 51353584.328, "learn_time_ms": 5041.36, "learn_throughput": 3967.184, "update_time_ms": 1.996}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 1e-10, "total_loss": 29.387511825561525, "policy_loss": -0.001692320890072807, "vf_loss": 29.41989059448242, "vf_explained_var": 0.719339382648468, "kl": 0.0026200012396626615, "entropy": 3.069552707672119, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2560000, "num_agent_steps_sampled": 5120000, "num_steps_trained": 2560000, "num_agent_steps_trained": 5120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 254, "training_iteration": 128, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-13-11", "timestamp": 1704769991, "time_this_iter_s": 186.52693581581116, "time_total_s": 25719.41010069847, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04438CF70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1513.3007671833038, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 21.91547169811321, "ram_util_percent": 55.24679245283019}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -517.6470588235294, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -258.8235294117647}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23015768994338853, "mean_inference_ms": 1.120447229399752, "mean_action_processing_ms": 0.05807319385816562, "mean_env_wait_ms": 7.748779723956437, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2580000, "timesteps_this_iter": 0, "agent_timesteps_total": 5160000, "timers": {"sample_time_ms": 188635.099, "sample_throughput": 106.025, "load_time_ms": 0.346, "load_throughput": 57772782.369, "learn_time_ms": 5038.884, "learn_throughput": 3969.133, "update_time_ms": 1.996}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 1e-10, "total_loss": 46.89379196166992, "policy_loss": -0.0018081188835203487, "vf_loss": 46.9263671875, "vf_explained_var": 0.6292090058326721, "kl": 0.0042020407895320576, "entropy": 3.0777475357055666, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2580000, "num_agent_steps_sampled": 5160000, "num_steps_trained": 2580000, "num_agent_steps_trained": 5160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 256, "training_iteration": 129, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-16-20", "timestamp": 1704770180, "time_this_iter_s": 189.11811685562134, "time_total_s": 25908.528217554092, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1702.4188840389252, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 21.31161048689139, "ram_util_percent": 55.885393258426966}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -505.2631578947368, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -252.6315789473684}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2313050151103452, "mean_inference_ms": 1.1226314171709901, "mean_action_processing_ms": 0.058065142573898255, "mean_env_wait_ms": 7.752174266919282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2600000, "timesteps_this_iter": 0, "agent_timesteps_total": 5200000, "timers": {"sample_time_ms": 189392.093, "sample_throughput": 105.601, "load_time_ms": 0.312, "load_throughput": 64191980.41, "learn_time_ms": 5071.785, "learn_throughput": 3943.385, "update_time_ms": 1.896}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 1e-10, "total_loss": 39.40079803466797, "policy_loss": -0.0014946461003459977, "vf_loss": 39.43311996459961, "vf_explained_var": 0.6294402480125427, "kl": 0.003181881292743061, "entropy": 3.0830560684204102, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2600000, "num_agent_steps_sampled": 5200000, "num_steps_trained": 2600000, "num_agent_steps_trained": 5200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 258, "training_iteration": 130, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-19-37", "timestamp": 1704770377, "time_this_iter_s": 196.52614760398865, "time_total_s": 26105.05436515808, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D01F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1898.9450316429138, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 24.608273381294964, "ram_util_percent": 56.63237410071943}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -504.76190476190476, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -252.38095238095238}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2323190560982256, "mean_inference_ms": 1.124754058325329, "mean_action_processing_ms": 0.058090708392626755, "mean_env_wait_ms": 7.756463756836547, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2620000, "timesteps_this_iter": 0, "agent_timesteps_total": 5240000, "timers": {"sample_time_ms": 191147.782, "sample_throughput": 104.631, "load_time_ms": 0.209, "load_throughput": 95771298.093, "learn_time_ms": 5097.304, "learn_throughput": 3923.643, "update_time_ms": 1.893}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 1e-10, "total_loss": 71.06610565185547, "policy_loss": -0.0021036434436589426, "vf_loss": 71.09943542480468, "vf_explained_var": 0.5841976284980774, "kl": 0.003311958517554814, "entropy": 3.1229134082794188, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2620000, "num_agent_steps_sampled": 5240000, "num_steps_trained": 2620000, "num_agent_steps_trained": 5240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 260, "training_iteration": 131, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-22-51", "timestamp": 1704770571, "time_this_iter_s": 194.50273299217224, "time_total_s": 26299.557098150253, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044329D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2093.447764635086, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 24.25709090909091, "ram_util_percent": 54.69563636363636}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.6521739130435, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -247.82608695652175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23325999817945792, "mean_inference_ms": 1.126870256827205, "mean_action_processing_ms": 0.058135155616685134, "mean_env_wait_ms": 7.760518690430154, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2640000, "timesteps_this_iter": 0, "agent_timesteps_total": 5280000, "timers": {"sample_time_ms": 191509.661, "sample_throughput": 104.433, "load_time_ms": 0.109, "load_throughput": 183477865.267, "learn_time_ms": 5117.894, "learn_throughput": 3907.858, "update_time_ms": 1.988}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 1e-10, "total_loss": 40.00271072387695, "policy_loss": -0.0017023160164989725, "vf_loss": 40.03553085327148, "vf_explained_var": 0.5872048139572144, "kl": 0.0022676319351370377, "entropy": 3.1114924430847166, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2640000, "num_agent_steps_sampled": 5280000, "num_steps_trained": 2640000, "num_agent_steps_trained": 5280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 262, "training_iteration": 132, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-26-04", "timestamp": 1704770764, "time_this_iter_s": 193.25538063049316, "time_total_s": 26492.812478780746, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2286.703145265579, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 24.732116788321164, "ram_util_percent": 52.78284671532847}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -248.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23406890392339685, "mean_inference_ms": 1.129047419858693, "mean_action_processing_ms": 0.058189978626163034, "mean_env_wait_ms": 7.764973168348672, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2660000, "timesteps_this_iter": 0, "agent_timesteps_total": 5320000, "timers": {"sample_time_ms": 191574.688, "sample_throughput": 104.398, "load_time_ms": 0.109, "load_throughput": 183477865.267, "learn_time_ms": 5157.742, "learn_throughput": 3877.666, "update_time_ms": 1.885}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 1e-10, "total_loss": 40.967166900634766, "policy_loss": -0.0015218823472224585, "vf_loss": 40.999854278564456, "vf_explained_var": 0.7092597126960755, "kl": 0.001858510179050299, "entropy": 3.1164527416229246, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2660000, "num_agent_steps_sampled": 5320000, "num_steps_trained": 2660000, "num_agent_steps_trained": 5320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 264, "training_iteration": 133, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-29-20", "timestamp": 1704770960, "time_this_iter_s": 195.60726118087769, "time_total_s": 26688.419739961624, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B78B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2482.310406446457, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 26.856521739130432, "ram_util_percent": 53.233333333333334}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.2962962962963, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -248.14814814814815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23477373175770122, "mean_inference_ms": 1.1309692390490467, "mean_action_processing_ms": 0.05823542136686418, "mean_env_wait_ms": 7.768732255926337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2680000, "timesteps_this_iter": 0, "agent_timesteps_total": 5360000, "timers": {"sample_time_ms": 191593.163, "sample_throughput": 104.388, "load_time_ms": 0.007, "load_throughput": 2974683687.943, "learn_time_ms": 5145.69, "learn_throughput": 3886.748, "update_time_ms": 1.685}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 1e-10, "total_loss": 51.12765960693359, "policy_loss": -0.0016389427429623904, "vf_loss": 51.16047286987305, "vf_explained_var": 0.6635845899581909, "kl": 0.0021858105190570853, "entropy": 3.1173613548278807, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2680000, "num_agent_steps_sampled": 5360000, "num_steps_trained": 2680000, "num_agent_steps_trained": 5360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 266, "training_iteration": 134, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-32-31", "timestamp": 1704771151, "time_this_iter_s": 191.03692150115967, "time_total_s": 26879.456661462784, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044329D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2673.3473279476166, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 24.587407407407404, "ram_util_percent": 53.92333333333333}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.55172413793105, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -248.27586206896552}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2353504001766208, "mean_inference_ms": 1.1325701797994328, "mean_action_processing_ms": 0.05826648893111997, "mean_env_wait_ms": 7.771223694850321, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2700000, "timesteps_this_iter": 0, "agent_timesteps_total": 5400000, "timers": {"sample_time_ms": 191253.874, "sample_throughput": 104.573, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5113.813, "learn_throughput": 3910.976, "update_time_ms": 1.685}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 1e-10, "total_loss": 70.4139892578125, "policy_loss": -0.0015982297274469205, "vf_loss": 70.44649810791016, "vf_explained_var": 0.6064707279205322, "kl": 0.002250232831562915, "entropy": 3.091041612625122, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2700000, "num_agent_steps_sampled": 5400000, "num_steps_trained": 2700000, "num_agent_steps_trained": 5400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 268, "training_iteration": 135, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-35-38", "timestamp": 1704771338, "time_this_iter_s": 186.94618487358093, "time_total_s": 27066.402846336365, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2860.2935128211975, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 24.486363636363635, "ram_util_percent": 52.62954545454546}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.2258064516129, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -251.61290322580646}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23575324084686922, "mean_inference_ms": 1.1334407705153344, "mean_action_processing_ms": 0.05827280854112843, "mean_env_wait_ms": 7.771618270842623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2720000, "timesteps_this_iter": 0, "agent_timesteps_total": 5440000, "timers": {"sample_time_ms": 190082.623, "sample_throughput": 105.217, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5073.339, "learn_throughput": 3942.177, "update_time_ms": 1.587}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 1e-10, "total_loss": 40.17059326171875, "policy_loss": -0.0016783624367415761, "vf_loss": 40.2032470703125, "vf_explained_var": 0.7391804456710815, "kl": 0.0033117071674418686, "entropy": 3.0975704193115234, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2720000, "num_agent_steps_sampled": 5440000, "num_steps_trained": 2720000, "num_agent_steps_trained": 5440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 270, "training_iteration": 136, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-38-36", "timestamp": 1704771516, "time_this_iter_s": 178.28987574577332, "time_total_s": 27244.692722082138, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3038.583388566971, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 18.456916996047433, "ram_util_percent": 50.087351778656135}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -503.030303030303, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -251.5151515151515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23605154956792132, "mean_inference_ms": 1.133868502151757, "mean_action_processing_ms": 0.05826241014051061, "mean_env_wait_ms": 7.770744887359628, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2740000, "timesteps_this_iter": 0, "agent_timesteps_total": 5480000, "timers": {"sample_time_ms": 189282.878, "sample_throughput": 105.662, "load_time_ms": 0.098, "load_throughput": 203163187.212, "learn_time_ms": 5033.631, "learn_throughput": 3973.275, "update_time_ms": 1.586}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 1e-10, "total_loss": 60.702962493896486, "policy_loss": -0.0016468741823174038, "vf_loss": 60.73561401367188, "vf_explained_var": 0.5669080257415772, "kl": 0.004561974697661242, "entropy": 3.1000929832458497, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2740000, "num_agent_steps_sampled": 5480000, "num_steps_trained": 2740000, "num_agent_steps_trained": 5480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 272, "training_iteration": 137, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-41-37", "timestamp": 1704771697, "time_this_iter_s": 180.33934664726257, "time_total_s": 27425.0320687294, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044309B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3218.9227352142334, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 23.14156862745098, "ram_util_percent": 48.4686274509804}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -508.57142857142856, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -254.28571428571428}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23621653748534688, "mean_inference_ms": 1.1338240995907316, "mean_action_processing_ms": 0.05823940811217333, "mean_env_wait_ms": 7.768628028796288, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2760000, "timesteps_this_iter": 0, "agent_timesteps_total": 5520000, "timers": {"sample_time_ms": 188365.264, "sample_throughput": 106.177, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4962.226, "learn_throughput": 4030.449, "update_time_ms": 1.586}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 1e-10, "total_loss": 84.39970703125, "policy_loss": -0.00205253291711216, "vf_loss": 84.43237762451172, "vf_explained_var": 0.44956313371658324, "kl": 0.004196453968732338, "entropy": 3.062108373641968, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2760000, "num_agent_steps_sampled": 5520000, "num_steps_trained": 2760000, "num_agent_steps_trained": 5520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 274, "training_iteration": 138, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-44-34", "timestamp": 1704771874, "time_this_iter_s": 177.0429756641388, "time_total_s": 27602.07504439354, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B75E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3395.965710878372, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 18.109163346613546, "ram_util_percent": 49.085657370517936}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.7027027027027, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -251.35135135135135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23630535971613584, "mean_inference_ms": 1.1334342599234473, "mean_action_processing_ms": 0.05820007225036736, "mean_env_wait_ms": 7.765909383792761, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2780000, "timesteps_this_iter": 0, "agent_timesteps_total": 5560000, "timers": {"sample_time_ms": 187362.33, "sample_throughput": 106.745, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4925.499, "learn_throughput": 4060.502, "update_time_ms": 1.483}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 1e-10, "total_loss": 35.391011810302736, "policy_loss": -0.0018457404353283357, "vf_loss": 35.42396697998047, "vf_explained_var": 0.6870772838592529, "kl": 0.002820595284486027, "entropy": 3.1111427783966064, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2780000, "num_agent_steps_sampled": 5560000, "num_steps_trained": 2780000, "num_agent_steps_trained": 5560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 276, "training_iteration": 139, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-47-33", "timestamp": 1704772053, "time_this_iter_s": 179.435706615448, "time_total_s": 27781.510751008987, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3575.40141749382, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 17.92992125984252, "ram_util_percent": 48.86259842519685}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.56410256410254, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -251.28205128205127}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23632851052019319, "mean_inference_ms": 1.1327789577649152, "mean_action_processing_ms": 0.05815496532722886, "mean_env_wait_ms": 7.762644569165562, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2800000, "timesteps_this_iter": 0, "agent_timesteps_total": 5600000, "timers": {"sample_time_ms": 185592.733, "sample_throughput": 107.763, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4853.11, "learn_throughput": 4121.068, "update_time_ms": 1.581}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 1e-10, "total_loss": 59.121298217773436, "policy_loss": -0.00261860567964618, "vf_loss": 59.15499496459961, "vf_explained_var": 0.6871831297874451, "kl": 0.002907429465339195, "entropy": 3.107702112197876, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2800000, "num_agent_steps_sampled": 5600000, "num_steps_trained": 2800000, "num_agent_steps_trained": 5600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 278, "training_iteration": 140, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-50-32", "timestamp": 1704772232, "time_this_iter_s": 178.4784426689148, "time_total_s": 27959.989193677902, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3753.879860162735, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 17.939920948616603, "ram_util_percent": 48.47905138339921}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.4390243902439, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -251.21951219512195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23628694322963398, "mean_inference_ms": 1.131926548855491, "mean_action_processing_ms": 0.0581058678460389, "mean_env_wait_ms": 7.758887353539802, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2820000, "timesteps_this_iter": 0, "agent_timesteps_total": 5640000, "timers": {"sample_time_ms": 183865.671, "sample_throughput": 108.775, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4812.451, "learn_throughput": 4155.887, "update_time_ms": 1.483}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 1e-10, "total_loss": 42.34545745849609, "policy_loss": -0.001981612656712528, "vf_loss": 42.37826919555664, "vf_explained_var": 0.683044159412384, "kl": 0.002290222509400941, "entropy": 3.0827511310577393, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2820000, "num_agent_steps_sampled": 5640000, "num_steps_trained": 2820000, "num_agent_steps_trained": 5640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 280, "training_iteration": 141, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-53-29", "timestamp": 1704772409, "time_this_iter_s": 177.54169750213623, "time_total_s": 28137.53089118004, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044309B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3931.421557664871, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 18.04285714285714, "ram_util_percent": 48.39047619047618}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.0232558139535, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.51162790697674}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23621424721717416, "mean_inference_ms": 1.1309252199063535, "mean_action_processing_ms": 0.05804984312954992, "mean_env_wait_ms": 7.7549147192285846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2840000, "timesteps_this_iter": 0, "agent_timesteps_total": 5680000, "timers": {"sample_time_ms": 182450.747, "sample_throughput": 109.619, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4756.993, "learn_throughput": 4204.337, "update_time_ms": 1.485}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 1e-10, "total_loss": 126.64528350830078, "policy_loss": -0.0021702119990438364, "vf_loss": 126.67772827148437, "vf_explained_var": 0.42250288724899293, "kl": 0.0048006448436540335, "entropy": 3.0289002418518067, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2840000, "num_agent_steps_sampled": 5680000, "num_steps_trained": 2840000, "num_agent_steps_trained": 5680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 282, "training_iteration": 142, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-56-28", "timestamp": 1704772588, "time_this_iter_s": 178.96137714385986, "time_total_s": 28316.4922683239, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044361DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4110.382934808731, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 18.090513833992098, "ram_util_percent": 48.50118577075099}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.3333333333333, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.66666666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2361187590041889, "mean_inference_ms": 1.1298266225087472, "mean_action_processing_ms": 0.057990427470754835, "mean_env_wait_ms": 7.750859683112535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2860000, "timesteps_this_iter": 0, "agent_timesteps_total": 5720000, "timers": {"sample_time_ms": 180869.689, "sample_throughput": 110.577, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4695.377, "learn_throughput": 4259.509, "update_time_ms": 1.587}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 1e-10, "total_loss": 87.47704772949218, "policy_loss": -0.0017733238528855112, "vf_loss": 87.50927734375, "vf_explained_var": 0.540506899356842, "kl": 0.003032737041910494, "entropy": 3.0454397201538086, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2860000, "num_agent_steps_sampled": 5720000, "num_steps_trained": 2860000, "num_agent_steps_trained": 5720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 284, "training_iteration": 143, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_11-59-28", "timestamp": 1704772768, "time_this_iter_s": 179.73284769058228, "time_total_s": 28496.22511601448, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4290.115782499313, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 18.33607843137255, "ram_util_percent": 47.98235294117647}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -489.36170212765956, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.68085106382978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2360118084373193, "mean_inference_ms": 1.1286455166298863, "mean_action_processing_ms": 0.05792646485482278, "mean_env_wait_ms": 7.746557659113716, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2880000, "timesteps_this_iter": 0, "agent_timesteps_total": 5760000, "timers": {"sample_time_ms": 179465.774, "sample_throughput": 111.442, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4662.057, "learn_throughput": 4289.952, "update_time_ms": 1.585}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 1e-10, "total_loss": 101.17597808837891, "policy_loss": -0.0016988370972871535, "vf_loss": 101.20796051025391, "vf_explained_var": 0.5798053741455078, "kl": 0.005505438935561102, "entropy": 3.027806806564331, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2880000, "num_agent_steps_sampled": 5760000, "num_steps_trained": 2880000, "num_agent_steps_trained": 5760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 286, "training_iteration": 144, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-02-26", "timestamp": 1704772946, "time_this_iter_s": 177.2869439125061, "time_total_s": 28673.512059926987, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4467.4027264118195, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 17.994820717131475, "ram_util_percent": 48.31673306772908}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -489.7959183673469, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.89795918367346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2358827438826283, "mean_inference_ms": 1.1274024355830958, "mean_action_processing_ms": 0.057859235998912066, "mean_env_wait_ms": 7.742047993333976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2900000, "timesteps_this_iter": 0, "agent_timesteps_total": 5800000, "timers": {"sample_time_ms": 178405.705, "sample_throughput": 112.104, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4654.16, "learn_throughput": 4297.231, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 1e-10, "total_loss": 35.7725112915039, "policy_loss": -0.001469637771453769, "vf_loss": 35.804144287109374, "vf_explained_var": 0.729837167263031, "kl": 0.002439465104111438, "entropy": 3.016463375091553, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2900000, "num_agent_steps_sampled": 5800000, "num_steps_trained": 2900000, "num_agent_steps_trained": 5800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 288, "training_iteration": 145, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-05-22", "timestamp": 1704773122, "time_this_iter_s": 176.5976221561432, "time_total_s": 28850.10968208313, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04437C700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4644.000348567963, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 18.038400000000003, "ram_util_percent": 48.280800000000006}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.11764705882354, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.05882352941177}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23573568484948162, "mean_inference_ms": 1.1261316549865854, "mean_action_processing_ms": 0.05779277191921073, "mean_env_wait_ms": 7.737339081736134, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2920000, "timesteps_this_iter": 0, "agent_timesteps_total": 5840000, "timers": {"sample_time_ms": 178180.202, "sample_throughput": 112.246, "load_time_ms": 0.209, "load_throughput": 95607567.814, "learn_time_ms": 4651.806, "learn_throughput": 4299.405, "update_time_ms": 1.705}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 1e-10, "total_loss": 93.24317474365235, "policy_loss": -0.0017961816928908191, "vf_loss": 93.27557525634765, "vf_explained_var": 0.34674819707870486, "kl": 0.004450600214684508, "entropy": 3.060311698913574, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2920000, "num_agent_steps_sampled": 5840000, "num_steps_trained": 2920000, "num_agent_steps_trained": 5840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 290, "training_iteration": 146, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-08-18", "timestamp": 1704773298, "time_this_iter_s": 176.0957055091858, "time_total_s": 29026.205387592316, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044202F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4820.096054077148, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 18.029199999999996, "ram_util_percent": 48.416}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.33962264150944, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.16981132075472}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23558426559465026, "mean_inference_ms": 1.124827830478878, "mean_action_processing_ms": 0.057728796755603905, "mean_env_wait_ms": 7.732575756619889, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2940000, "timesteps_this_iter": 0, "agent_timesteps_total": 5880000, "timers": {"sample_time_ms": 177857.622, "sample_throughput": 112.449, "load_time_ms": 0.111, "load_throughput": 180594359.526, "learn_time_ms": 4654.533, "learn_throughput": 4296.886, "update_time_ms": 1.606}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 1e-10, "total_loss": 25.696343231201173, "policy_loss": -0.0024867316433787147, "vf_loss": 25.729917144775392, "vf_explained_var": 0.7731691360473633, "kl": 0.006214277711264859, "entropy": 3.108822059631348, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2940000, "num_agent_steps_sampled": 5880000, "num_steps_trained": 2940000, "num_agent_steps_trained": 5880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 292, "training_iteration": 147, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-11-15", "timestamp": 1704773475, "time_this_iter_s": 177.16055393218994, "time_total_s": 29203.365941524506, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044283CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4997.256608009338, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 17.768924302788843, "ram_util_percent": 48.26135458167331}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.54545454545456, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.27272727272728}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2354291473919242, "mean_inference_ms": 1.1235079948732973, "mean_action_processing_ms": 0.05766596360051719, "mean_env_wait_ms": 7.727983575611991, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2960000, "timesteps_this_iter": 0, "agent_timesteps_total": 5920000, "timers": {"sample_time_ms": 178164.939, "sample_throughput": 112.256, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4659.575, "learn_throughput": 4292.237, "update_time_ms": 1.507}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 1e-10, "total_loss": 81.62367401123046, "policy_loss": -0.001805486482381724, "vf_loss": 81.65652465820312, "vf_explained_var": 0.5293169736862182, "kl": 0.004394915265978838, "entropy": 3.1045012950897215, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2960000, "num_agent_steps_sampled": 5920000, "num_steps_trained": 2960000, "num_agent_steps_trained": 5920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 294, "training_iteration": 148, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-14-16", "timestamp": 1704773656, "time_this_iter_s": 180.13871240615845, "time_total_s": 29383.504653930664, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5177.395320415497, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 17.981960784313724, "ram_util_percent": 47.74901960784314}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.2456140350877, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.12280701754386}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2352601818649796, "mean_inference_ms": 1.1221816475325437, "mean_action_processing_ms": 0.057605369351824594, "mean_env_wait_ms": 7.723435580794863, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2980000, "timesteps_this_iter": 0, "agent_timesteps_total": 5960000, "timers": {"sample_time_ms": 178026.845, "sample_throughput": 112.343, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4663.475, "learn_throughput": 4288.648, "update_time_ms": 1.507}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 1e-10, "total_loss": 87.78665008544922, "policy_loss": -0.0014614390000887046, "vf_loss": 87.81914367675782, "vf_explained_var": 0.5888237595558167, "kl": 0.0030798811463190745, "entropy": 3.103285312652588, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2980000, "num_agent_steps_sampled": 5960000, "num_steps_trained": 2980000, "num_agent_steps_trained": 5960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 296, "training_iteration": 149, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-17-14", "timestamp": 1704773834, "time_this_iter_s": 178.04153847694397, "time_total_s": 29561.546192407608, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044361F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5355.436858892441, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 17.998809523809523, "ram_util_percent": 48.06190476190477}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.3050847457627, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.15254237288136}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23508890586859071, "mean_inference_ms": 1.1208619871697207, "mean_action_processing_ms": 0.05754482834461732, "mean_env_wait_ms": 7.719070668102836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3000000, "timesteps_this_iter": 0, "agent_timesteps_total": 6000000, "timers": {"sample_time_ms": 178225.335, "sample_throughput": 112.217, "load_time_ms": 0.1, "load_throughput": 200492543.021, "learn_time_ms": 4666.313, "learn_throughput": 4286.039, "update_time_ms": 1.409}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 1e-10, "total_loss": 149.07989807128905, "policy_loss": -0.0021361964838951834, "vf_loss": 149.11293029785156, "vf_explained_var": 0.12399967908859252, "kl": 0.003457924788802735, "entropy": 3.0891000270843505, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3000000, "num_agent_steps_sampled": 6000000, "num_steps_trained": 3000000, "num_agent_steps_trained": 6000000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -540.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -270.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21143916549321787, "mean_inference_ms": 1.0444350636963378, "mean_action_processing_ms": 0.05434753310482404, "mean_env_wait_ms": 7.413067387961928, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 298, "training_iteration": 150, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-34-47", "timestamp": 1704774887, "time_this_iter_s": 1053.3172945976257, "time_total_s": 30614.863487005234, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044375160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6408.7541534900665, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 17.928101945003352, "ram_util_percent": 48.032863849765256}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.4590163934426, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.2295081967213}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.234910189686124, "mean_inference_ms": 1.119550032259052, "mean_action_processing_ms": 0.057484042690931485, "mean_env_wait_ms": 7.71496702520267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3020000, "timesteps_this_iter": 0, "agent_timesteps_total": 6040000, "timers": {"sample_time_ms": 265953.798, "sample_throughput": 75.201, "load_time_ms": 0.1, "load_throughput": 200492543.021, "learn_time_ms": 4678.208, "learn_throughput": 4275.141, "update_time_ms": 1.409}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 1e-10, "total_loss": 147.3730682373047, "policy_loss": -0.0022856672061607242, "vf_loss": 147.40612182617187, "vf_explained_var": 0.31168192625045776, "kl": 0.004337449717861297, "entropy": 3.0771652698516845, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3020000, "num_agent_steps_sampled": 6040000, "num_steps_trained": 3020000, "num_agent_steps_trained": 6040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 300, "training_iteration": 151, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-37-49", "timestamp": 1704775069, "time_this_iter_s": 182.04553747177124, "time_total_s": 30796.909024477005, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04438CEE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6590.799690961838, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 17.86887159533074, "ram_util_percent": 47.28249027237355}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.57142857142856, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.28571428571428}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23472872049279428, "mean_inference_ms": 1.11824271889898, "mean_action_processing_ms": 0.05742638214374832, "mean_env_wait_ms": 7.7108942658528346, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3040000, "timesteps_this_iter": 0, "agent_timesteps_total": 6080000, "timers": {"sample_time_ms": 265842.894, "sample_throughput": 75.232, "load_time_ms": 0.1, "load_throughput": 200492543.021, "learn_time_ms": 4685.886, "learn_throughput": 4268.136, "update_time_ms": 1.306}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 1e-10, "total_loss": 65.79066314697266, "policy_loss": -0.0026700522559136354, "vf_loss": 65.82393188476563, "vf_explained_var": 0.4664649724960327, "kl": 0.003328243642005191, "entropy": 3.059794473648071, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3040000, "num_agent_steps_sampled": 6080000, "num_steps_trained": 3040000, "num_agent_steps_trained": 6080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 302, "training_iteration": 152, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-40-47", "timestamp": 1704775247, "time_this_iter_s": 177.8100826740265, "time_total_s": 30974.71910715103, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044578430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6768.609773635864, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 17.924206349206347, "ram_util_percent": 48.764682539682546}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.67692307692306, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.33846153846153}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23454486565716834, "mean_inference_ms": 1.116950593537706, "mean_action_processing_ms": 0.05737002092487875, "mean_env_wait_ms": 7.70680775215283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3060000, "timesteps_this_iter": 0, "agent_timesteps_total": 6120000, "timers": {"sample_time_ms": 265540.714, "sample_throughput": 75.318, "load_time_ms": 0.199, "load_throughput": 100258252.659, "learn_time_ms": 4687.317, "learn_throughput": 4266.833, "update_time_ms": 1.306}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 1e-10, "total_loss": 30.35424919128418, "policy_loss": -0.0021918152612820487, "vf_loss": 30.3864688873291, "vf_explained_var": 0.7165482878684998, "kl": 0.004314459517929037, "entropy": 3.0027259826660155, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3060000, "num_agent_steps_sampled": 6120000, "num_steps_trained": 3060000, "num_agent_steps_trained": 6120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 304, "training_iteration": 153, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-43-44", "timestamp": 1704775424, "time_this_iter_s": 176.65193247795105, "time_total_s": 31151.371039628983, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6945.261706113815, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 17.8532, "ram_util_percent": 48.61519999999999}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.7910447761194, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -246.8955223880597}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23435979542122332, "mean_inference_ms": 1.1156753746293535, "mean_action_processing_ms": 0.05731351988406423, "mean_env_wait_ms": 7.702728514859381, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3080000, "timesteps_this_iter": 0, "agent_timesteps_total": 6160000, "timers": {"sample_time_ms": 265483.828, "sample_throughput": 75.334, "load_time_ms": 0.199, "load_throughput": 100258252.659, "learn_time_ms": 4689.901, "learn_throughput": 4264.483, "update_time_ms": 1.41}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 1e-10, "total_loss": 46.938811492919925, "policy_loss": -0.0026244831173123373, "vf_loss": 46.971435546875, "vf_explained_var": 0.44092048406600953, "kl": 0.005991677744803525, "entropy": 3.0000181674957274, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3080000, "num_agent_steps_sampled": 6160000, "num_steps_trained": 3080000, "num_agent_steps_trained": 6160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 306, "training_iteration": 154, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-46-40", "timestamp": 1704775600, "time_this_iter_s": 176.73109817504883, "time_total_s": 31328.10213780403, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B74C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7121.992804288864, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 17.891235059760955, "ram_util_percent": 48.57609561752989}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.8695652173913, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.43478260869566}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2341713395841779, "mean_inference_ms": 1.1144179520016335, "mean_action_processing_ms": 0.057256040797040546, "mean_env_wait_ms": 7.698763908516583, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3100000, "timesteps_this_iter": 0, "agent_timesteps_total": 6200000, "timers": {"sample_time_ms": 265713.977, "sample_throughput": 75.269, "load_time_ms": 0.299, "load_throughput": 66825523.779, "learn_time_ms": 4698.737, "learn_throughput": 4256.463, "update_time_ms": 1.406}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 1e-10, "total_loss": 28.895793533325197, "policy_loss": -0.0015630927601084199, "vf_loss": 28.92735023498535, "vf_explained_var": 0.6972155809402466, "kl": 0.0030096357491989243, "entropy": 2.999397039413452, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3100000, "num_agent_steps_sampled": 6200000, "num_steps_trained": 3100000, "num_agent_steps_trained": 6200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 308, "training_iteration": 155, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-49-39", "timestamp": 1704775779, "time_this_iter_s": 178.94559860229492, "time_total_s": 31507.047736406326, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7300.938402891159, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 17.73399209486166, "ram_util_percent": 48.6201581027668}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.9577464788732, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.4788732394366}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23398656036466503, "mean_inference_ms": 1.1131783243391273, "mean_action_processing_ms": 0.05719987683959351, "mean_env_wait_ms": 7.694829305950638, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3120000, "timesteps_this_iter": 0, "agent_timesteps_total": 6240000, "timers": {"sample_time_ms": 265809.375, "sample_throughput": 75.242, "load_time_ms": 0.299, "load_throughput": 66825523.779, "learn_time_ms": 4705.647, "learn_throughput": 4250.212, "update_time_ms": 1.289}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 1e-10, "total_loss": 38.477490234375, "policy_loss": -0.0022452589750662443, "vf_loss": 38.51030578613281, "vf_explained_var": 0.6628233671188355, "kl": 0.003455497786316464, "entropy": 3.0572124481201173, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3120000, "num_agent_steps_sampled": 6240000, "num_steps_trained": 3120000, "num_agent_steps_trained": 6240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 310, "training_iteration": 156, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-52-36", "timestamp": 1704775956, "time_this_iter_s": 177.0241026878357, "time_total_s": 31684.071839094162, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445708B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7477.962505578995, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 17.941035856573706, "ram_util_percent": 48.62828685258965}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.041095890411, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.5205479452055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23380838251596836, "mean_inference_ms": 1.1119600230153726, "mean_action_processing_ms": 0.057145143948941136, "mean_env_wait_ms": 7.690930293484929, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3140000, "timesteps_this_iter": 0, "agent_timesteps_total": 6280000, "timers": {"sample_time_ms": 265800.567, "sample_throughput": 75.244, "load_time_ms": 0.299, "load_throughput": 66825523.779, "learn_time_ms": 4717.207, "learn_throughput": 4239.797, "update_time_ms": 1.389}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 1e-10, "total_loss": 62.73565139770508, "policy_loss": -0.0016187344885430833, "vf_loss": 62.76768035888672, "vf_explained_var": 0.27082052230834963, "kl": 0.003918048398729423, "entropy": 3.041373682022095, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3140000, "num_agent_steps_sampled": 6280000, "num_steps_trained": 3140000, "num_agent_steps_trained": 6280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 312, "training_iteration": 157, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-55-34", "timestamp": 1704776134, "time_this_iter_s": 177.1198787689209, "time_total_s": 31861.191717863083, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D03A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7655.082384347916, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 17.947410358565737, "ram_util_percent": 48.712749003984065}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.12, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23362602453684309, "mean_inference_ms": 1.1107671589379808, "mean_action_processing_ms": 0.05709150286649732, "mean_env_wait_ms": 7.687146493065675, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3160000, "timesteps_this_iter": 0, "agent_timesteps_total": 6320000, "timers": {"sample_time_ms": 265685.569, "sample_throughput": 75.277, "load_time_ms": 0.399, "load_throughput": 50123135.755, "learn_time_ms": 4722.793, "learn_throughput": 4234.782, "update_time_ms": 1.39}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 1e-10, "total_loss": 34.296390533447266, "policy_loss": -0.0026229652055725695, "vf_loss": 34.32933807373047, "vf_explained_var": 0.6427061796188355, "kl": 0.004466530485026076, "entropy": 3.0325714111328126, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3160000, "num_agent_steps_sampled": 6320000, "num_steps_trained": 3160000, "num_agent_steps_trained": 6320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 314, "training_iteration": 158, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_12-58-33", "timestamp": 1704776313, "time_this_iter_s": 178.92938661575317, "time_total_s": 32040.121104478836, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04438CF70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7834.011770963669, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 18.153359683794466, "ram_util_percent": 48.737154150197625}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.1948051948052, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.5974025974026}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2334437812457221, "mean_inference_ms": 1.1095951688958394, "mean_action_processing_ms": 0.05703946727919759, "mean_env_wait_ms": 7.683458350822887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3180000, "timesteps_this_iter": 0, "agent_timesteps_total": 6360000, "timers": {"sample_time_ms": 265732.901, "sample_throughput": 75.264, "load_time_ms": 0.499, "load_throughput": 40056384.299, "learn_time_ms": 4725.381, "learn_throughput": 4232.463, "update_time_ms": 1.392}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 1e-10, "total_loss": 53.03752746582031, "policy_loss": -0.0017602500549145027, "vf_loss": 53.06947555541992, "vf_explained_var": 0.6224572896957398, "kl": 0.002997537353344537, "entropy": 3.018483829498291, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3180000, "num_agent_steps_sampled": 6360000, "num_steps_trained": 3180000, "num_agent_steps_trained": 6360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 316, "training_iteration": 159, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-01-31", "timestamp": 1704776491, "time_this_iter_s": 178.48675847053528, "time_total_s": 32218.60786294937, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04437C700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8012.498529434204, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 17.96561264822134, "ram_util_percent": 48.59209486166008}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.26582278481015, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.63291139240508}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23326141725660823, "mean_inference_ms": 1.1084466729355529, "mean_action_processing_ms": 0.05698740632479828, "mean_env_wait_ms": 7.679855093757236, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3200000, "timesteps_this_iter": 0, "agent_timesteps_total": 6400000, "timers": {"sample_time_ms": 265507.253, "sample_throughput": 75.328, "load_time_ms": 0.4, "load_throughput": 50057333.811, "learn_time_ms": 4729.854, "learn_throughput": 4228.46, "update_time_ms": 1.489}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 1e-10, "total_loss": 23.929924392700194, "policy_loss": -0.0015717702412231915, "vf_loss": 23.961700439453125, "vf_explained_var": 0.6754790782928467, "kl": 0.0022157149378845276, "entropy": 3.0204660415649416, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3200000, "num_agent_steps_sampled": 6400000, "num_steps_trained": 3200000, "num_agent_steps_trained": 6400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 318, "training_iteration": 160, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-04-29", "timestamp": 1704776669, "time_this_iter_s": 178.2131633758545, "time_total_s": 32396.821026325226, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04438CF70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8190.711692810059, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 17.89802371541502, "ram_util_percent": 48.51857707509882}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.3333333333333, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.66666666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23308114934217583, "mean_inference_ms": 1.1073227437984727, "mean_action_processing_ms": 0.05693652431424401, "mean_env_wait_ms": 7.676320960882029, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3220000, "timesteps_this_iter": 0, "agent_timesteps_total": 6440000, "timers": {"sample_time_ms": 177812.678, "sample_throughput": 112.478, "load_time_ms": 0.4, "load_throughput": 50057333.811, "learn_time_ms": 4725.541, "learn_throughput": 4232.32, "update_time_ms": 1.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 1e-10, "total_loss": 55.12602615356445, "policy_loss": -0.0016815157592482421, "vf_loss": 55.15815658569336, "vf_explained_var": 0.5093088865280151, "kl": 0.003715315768124938, "entropy": 3.0447743415832518, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3220000, "num_agent_steps_sampled": 6440000, "num_steps_trained": 3220000, "num_agent_steps_trained": 6440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 320, "training_iteration": 161, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-07-27", "timestamp": 1704776847, "time_this_iter_s": 177.87698602676392, "time_total_s": 32574.69801235199, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04438CEE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8368.588678836823, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 18.099601593625497, "ram_util_percent": 48.66374501992032}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.3975903614458, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.6987951807229}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23290214346965238, "mean_inference_ms": 1.1062221786648883, "mean_action_processing_ms": 0.056887711254059975, "mean_env_wait_ms": 7.672929565379284, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3240000, "timesteps_this_iter": 0, "agent_timesteps_total": 6480000, "timers": {"sample_time_ms": 178067.614, "sample_throughput": 112.317, "load_time_ms": 0.4, "load_throughput": 50057333.811, "learn_time_ms": 4726.673, "learn_throughput": 4231.306, "update_time_ms": 1.593}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 1e-10, "total_loss": 30.773749542236327, "policy_loss": -0.001521756558436893, "vf_loss": 30.80626220703125, "vf_explained_var": 0.750700831413269, "kl": 0.0036318104230022795, "entropy": 3.099229669570923, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3240000, "num_agent_steps_sampled": 6480000, "num_steps_trained": 3240000, "num_agent_steps_trained": 6480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 322, "training_iteration": 162, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-10-28", "timestamp": 1704777028, "time_this_iter_s": 180.41895604133606, "time_total_s": 32755.116968393326, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8549.007634878159, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 17.993359375, "ram_util_percent": 48.748046875}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.81176470588235, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.90588235294118}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23272241224732254, "mean_inference_ms": 1.105145067663015, "mean_action_processing_ms": 0.05683856844897429, "mean_env_wait_ms": 7.669606797516333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3260000, "timesteps_this_iter": 0, "agent_timesteps_total": 6520000, "timers": {"sample_time_ms": 178186.684, "sample_throughput": 112.242, "load_time_ms": 0.3, "load_throughput": 66708612.326, "learn_time_ms": 4735.889, "learn_throughput": 4223.072, "update_time_ms": 1.592}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 1e-10, "total_loss": 34.16815071105957, "policy_loss": -0.0018628253004140838, "vf_loss": 34.20125312805176, "vf_explained_var": 0.7348695158958435, "kl": 0.004558746849271422, "entropy": 3.124013900756836, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3260000, "num_agent_steps_sampled": 6520000, "num_steps_trained": 3260000, "num_agent_steps_trained": 6520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 324, "training_iteration": 163, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-13-26", "timestamp": 1704777206, "time_this_iter_s": 177.92174911499023, "time_total_s": 32933.038717508316, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445ADD30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8726.929383993149, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 17.864682539682537, "ram_util_percent": 48.728571428571435}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.51724137931035, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.75862068965517}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23254768786765267, "mean_inference_ms": 1.1040899171468255, "mean_action_processing_ms": 0.05678887740111261, "mean_env_wait_ms": 7.666334466969888, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3280000, "timesteps_this_iter": 0, "agent_timesteps_total": 6560000, "timers": {"sample_time_ms": 178253.871, "sample_throughput": 112.2, "load_time_ms": 0.3, "load_throughput": 66708612.326, "learn_time_ms": 4736.364, "learn_throughput": 4222.648, "update_time_ms": 1.492}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 1e-10, "total_loss": 28.711093139648437, "policy_loss": -0.0022715119491889977, "vf_loss": 28.74425163269043, "vf_explained_var": 0.7168341994285583, "kl": 0.0029995198576932224, "entropy": 3.0887290954589846, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3280000, "num_agent_steps_sampled": 6560000, "num_steps_trained": 3280000, "num_agent_steps_trained": 6560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 326, "training_iteration": 164, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-16-23", "timestamp": 1704777383, "time_this_iter_s": 177.31233406066895, "time_total_s": 33110.351051568985, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445ADCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 8904.241718053818, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 17.847808764940236, "ram_util_percent": 47.124701195219124}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.5730337078652, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.7865168539326}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2323726795856661, "mean_inference_ms": 1.1030592896723828, "mean_action_processing_ms": 0.0567399560747842, "mean_env_wait_ms": 7.663106653695592, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3300000, "timesteps_this_iter": 0, "agent_timesteps_total": 6600000, "timers": {"sample_time_ms": 178061.592, "sample_throughput": 112.321, "load_time_ms": 0.2, "load_throughput": 99995327.214, "learn_time_ms": 4734.559, "learn_throughput": 4224.258, "update_time_ms": 1.392}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 1e-10, "total_loss": 60.82740478515625, "policy_loss": -0.002483381230421422, "vf_loss": 60.860924530029294, "vf_explained_var": 0.5173845052719116, "kl": 0.0026201600514821786, "entropy": 3.1034545421600344, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3300000, "num_agent_steps_sampled": 6600000, "num_steps_trained": 3300000, "num_agent_steps_trained": 6600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 328, "training_iteration": 165, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-19-20", "timestamp": 1704777560, "time_this_iter_s": 177.0131847858429, "time_total_s": 33287.36423635483, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044309B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9081.25490283966, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 17.939600000000002, "ram_util_percent": 48.598000000000006}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.8241758241758, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.9120879120879}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23219887580652057, "mean_inference_ms": 1.102051300933336, "mean_action_processing_ms": 0.05669043800377439, "mean_env_wait_ms": 7.6599280853660145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3320000, "timesteps_this_iter": 0, "agent_timesteps_total": 6640000, "timers": {"sample_time_ms": 178069.773, "sample_throughput": 112.316, "load_time_ms": 0.2, "load_throughput": 99995327.214, "learn_time_ms": 4731.691, "learn_throughput": 4226.819, "update_time_ms": 1.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 119.35193176269532, "policy_loss": -0.002049878317229492, "vf_loss": 119.38490142822266, "vf_explained_var": 0.4751593112945557, "kl": 0.005559120436343079, "entropy": 3.0911118507385256, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3320000, "num_agent_steps_sampled": 6640000, "num_steps_trained": 3320000, "num_agent_steps_trained": 6640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 330, "training_iteration": 166, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-22-17", "timestamp": 1704777737, "time_this_iter_s": 177.09928345680237, "time_total_s": 33464.46351981163, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044202F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9258.354186296463, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 17.719521912350597, "ram_util_percent": 48.65697211155379}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.8279569892473, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.91397849462365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23203174781080046, "mean_inference_ms": 1.1010632138674752, "mean_action_processing_ms": 0.05664276066156671, "mean_env_wait_ms": 7.656798883382091, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3340000, "timesteps_this_iter": 0, "agent_timesteps_total": 6680000, "timers": {"sample_time_ms": 178087.659, "sample_throughput": 112.304, "load_time_ms": 0.2, "load_throughput": 99995327.214, "learn_time_ms": 4729.799, "learn_throughput": 4228.51, "update_time_ms": 1.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 115.82108001708984, "policy_loss": -0.001730859519969652, "vf_loss": 115.85272216796875, "vf_explained_var": 0.43753159046173096, "kl": 0.005915948801988868, "entropy": 2.991519594192505, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3340000, "num_agent_steps_sampled": 6680000, "num_steps_trained": 3340000, "num_agent_steps_trained": 6680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 332, "training_iteration": 167, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-25-14", "timestamp": 1704777914, "time_this_iter_s": 177.3060700893402, "time_total_s": 33641.76958990097, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D00D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9435.660256385803, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 17.890079365079362, "ram_util_percent": 48.74007936507937}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -497.7263157894737, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.86315789473684}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23186653501462967, "mean_inference_ms": 1.1000937192259574, "mean_action_processing_ms": 0.056596555539969874, "mean_env_wait_ms": 7.653729221731403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3360000, "timesteps_this_iter": 0, "agent_timesteps_total": 6720000, "timers": {"sample_time_ms": 177938.039, "sample_throughput": 112.399, "load_time_ms": 0.1, "load_throughput": 199443842.13, "learn_time_ms": 4730.484, "learn_throughput": 4227.897, "update_time_ms": 1.592}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 50.25864028930664, "policy_loss": -0.002333884592242541, "vf_loss": 50.29163665771485, "vf_explained_var": 0.6691619515419006, "kl": 0.005859407629091295, "entropy": 3.0662238121032717, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3360000, "num_agent_steps_sampled": 6720000, "num_steps_trained": 3360000, "num_agent_steps_trained": 6720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 334, "training_iteration": 168, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-28-12", "timestamp": 1704778092, "time_this_iter_s": 177.46031713485718, "time_total_s": 33819.22990703583, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9613.12057352066, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 18.084860557768923, "ram_util_percent": 48.77490039840637}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.83505154639175, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.91752577319588}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2317069421893853, "mean_inference_ms": 1.0991444445213379, "mean_action_processing_ms": 0.05655207976324908, "mean_env_wait_ms": 7.650683247060373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3380000, "timesteps_this_iter": 0, "agent_timesteps_total": 6760000, "timers": {"sample_time_ms": 177699.288, "sample_throughput": 112.55, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4730.892, "learn_throughput": 4227.532, "update_time_ms": 1.69}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 135.3898956298828, "policy_loss": -0.001584610577523704, "vf_loss": 135.42149047851564, "vf_explained_var": 0.23463127613067628, "kl": 0.005416377770442743, "entropy": 2.9998537063598634, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3380000, "num_agent_steps_sampled": 6760000, "num_steps_trained": 3380000, "num_agent_steps_trained": 6760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 336, "training_iteration": 169, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-31-08", "timestamp": 1704778268, "time_this_iter_s": 176.0966441631317, "time_total_s": 33995.32655119896, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044202F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9789.217217683792, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 18.03052208835341, "ram_util_percent": 47.29076305220884}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.83838383838383, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.91919191919192}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23155380350604837, "mean_inference_ms": 1.0982138806130513, "mean_action_processing_ms": 0.056509441130487344, "mean_env_wait_ms": 7.64769288048918, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3400000, "timesteps_this_iter": 0, "agent_timesteps_total": 6800000, "timers": {"sample_time_ms": 177633.618, "sample_throughput": 112.591, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4731.895, "learn_throughput": 4226.636, "update_time_ms": 1.693}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 117.95446319580078, "policy_loss": -0.0019803991321474257, "vf_loss": 117.98653259277344, "vf_explained_var": 0.4174440145492554, "kl": 0.006746096106476784, "entropy": 3.009497356414795, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3400000, "num_agent_steps_sampled": 6800000, "num_steps_trained": 3400000, "num_agent_steps_trained": 6800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 338, "training_iteration": 170, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-34-06", "timestamp": 1704778446, "time_this_iter_s": 177.55746746063232, "time_total_s": 34172.88401865959, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 9966.774685144424, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 18.0515873015873, "ram_util_percent": 48.755952380952394}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23182904361552656, "mean_inference_ms": 1.0978863933861696, "mean_action_processing_ms": 0.05649448186055841, "mean_env_wait_ms": 7.645617319792185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3420000, "timesteps_this_iter": 0, "agent_timesteps_total": 6840000, "timers": {"sample_time_ms": 177529.16, "sample_throughput": 112.658, "load_time_ms": 0.1, "load_throughput": 200924742.515, "learn_time_ms": 4732.204, "learn_throughput": 4226.36, "update_time_ms": 1.788}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 59.04809494018555, "policy_loss": -0.0018139578984305515, "vf_loss": 59.07958908081055, "vf_explained_var": 0.3286839842796326, "kl": 0.0067044384271948585, "entropy": 2.968232822418213, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3420000, "num_agent_steps_sampled": 6840000, "num_steps_trained": 3420000, "num_agent_steps_trained": 6840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 340, "training_iteration": 171, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-37-02", "timestamp": 1704778622, "time_this_iter_s": 176.84095001220703, "time_total_s": 34349.7249686718, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B74C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10143.615635156631, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 17.9132, "ram_util_percent": 48.63279999999999}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23199714143925868, "mean_inference_ms": 1.0970991823728873, "mean_action_processing_ms": 0.0564226666152154, "mean_env_wait_ms": 7.642280019245881, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3440000, "timesteps_this_iter": 0, "agent_timesteps_total": 6880000, "timers": {"sample_time_ms": 177238.235, "sample_throughput": 112.842, "load_time_ms": 0.202, "load_throughput": 99156122.931, "learn_time_ms": 4732.754, "learn_throughput": 4225.87, "update_time_ms": 1.79}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 1e-10, "total_loss": 43.737937927246094, "policy_loss": -0.002212687732279228, "vf_loss": 43.77035064697266, "vf_explained_var": 0.6370404124259949, "kl": 0.004986561731637096, "entropy": 3.0199743270874024, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3440000, "num_agent_steps_sampled": 6880000, "num_steps_trained": 3440000, "num_agent_steps_trained": 6880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 342, "training_iteration": 172, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-40-00", "timestamp": 1704778800, "time_this_iter_s": 177.50491166114807, "time_total_s": 34527.22988033295, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10321.12054681778, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 18.025000000000002, "ram_util_percent": 48.357539682539674}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23195862249027957, "mean_inference_ms": 1.0957358773820511, "mean_action_processing_ms": 0.056331992873492644, "mean_env_wait_ms": 7.636722089123177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3460000, "timesteps_this_iter": 0, "agent_timesteps_total": 6920000, "timers": {"sample_time_ms": 177376.565, "sample_throughput": 112.754, "load_time_ms": 0.202, "load_throughput": 99156122.931, "learn_time_ms": 4728.07, "learn_throughput": 4230.056, "update_time_ms": 1.789}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 1e-10, "total_loss": 49.61916732788086, "policy_loss": -0.001665688456818515, "vf_loss": 49.651170349121095, "vf_explained_var": 0.5529966473579406, "kl": 0.007353432066737398, "entropy": 3.0336591720581056, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3460000, "num_agent_steps_sampled": 6920000, "num_steps_trained": 3460000, "num_agent_steps_trained": 6920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 344, "training_iteration": 173, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-42-59", "timestamp": 1704778979, "time_this_iter_s": 179.2567195892334, "time_total_s": 34706.48659992218, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10500.377266407013, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 17.83280632411067, "ram_util_percent": 48.300790513833995}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23179180905074406, "mean_inference_ms": 1.094175848871232, "mean_action_processing_ms": 0.056246189090898985, "mean_env_wait_ms": 7.630812108757186, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3480000, "timesteps_this_iter": 0, "agent_timesteps_total": 6960000, "timers": {"sample_time_ms": 177332.635, "sample_throughput": 112.782, "load_time_ms": 0.301, "load_throughput": 66370820.476, "learn_time_ms": 4732.42, "learn_throughput": 4226.168, "update_time_ms": 1.885}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 1e-10, "total_loss": 37.12812271118164, "policy_loss": -0.0018477122281119307, "vf_loss": 37.16023178100586, "vf_explained_var": 0.6474972367286682, "kl": 0.006156920641769359, "entropy": 3.02620906829834, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3480000, "num_agent_steps_sampled": 6960000, "num_steps_trained": 3480000, "num_agent_steps_trained": 6960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 346, "training_iteration": 174, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-45-56", "timestamp": 1704779156, "time_this_iter_s": 176.96449208259583, "time_total_s": 34883.451092004776, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10677.341758489609, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 17.998406374501993, "ram_util_percent": 46.658167330677294}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23156821060514893, "mean_inference_ms": 1.0925270764083468, "mean_action_processing_ms": 0.056166244621358226, "mean_env_wait_ms": 7.624822545659657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3500000, "timesteps_this_iter": 0, "agent_timesteps_total": 7000000, "timers": {"sample_time_ms": 177663.132, "sample_throughput": 112.573, "load_time_ms": 0.301, "load_throughput": 66370820.476, "learn_time_ms": 4730.312, "learn_throughput": 4228.051, "update_time_ms": 1.885}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 1e-10, "total_loss": 66.65597000122071, "policy_loss": -0.002292340571470497, "vf_loss": 66.6883544921875, "vf_explained_var": 0.6325680017471313, "kl": 0.006053072260637382, "entropy": 3.0092904567718506, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3500000, "num_agent_steps_sampled": 7000000, "num_steps_trained": 3500000, "num_agent_steps_trained": 7000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 348, "training_iteration": 175, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-48-57", "timestamp": 1704779337, "time_this_iter_s": 180.2503309249878, "time_total_s": 35063.701422929764, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044375160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 10857.592089414597, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 18.04, "ram_util_percent": 47.8549019607843}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23128537843343852, "mean_inference_ms": 1.0907908546912846, "mean_action_processing_ms": 0.05608539007582094, "mean_env_wait_ms": 7.618909323772361, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3520000, "timesteps_this_iter": 0, "agent_timesteps_total": 7040000, "timers": {"sample_time_ms": 177953.025, "sample_throughput": 112.389, "load_time_ms": 0.301, "load_throughput": 66370820.476, "learn_time_ms": 4731.042, "learn_throughput": 4227.399, "update_time_ms": 1.786}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 1e-10, "total_loss": 98.20032806396485, "policy_loss": -0.0020560697318986244, "vf_loss": 98.23285522460938, "vf_explained_var": 0.18756439685821533, "kl": 0.007895973175667526, "entropy": 3.047021913528442, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3520000, "num_agent_steps_sampled": 7040000, "num_steps_trained": 3520000, "num_agent_steps_trained": 7040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 350, "training_iteration": 176, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-51-57", "timestamp": 1704779517, "time_this_iter_s": 180.02670741081238, "time_total_s": 35243.728130340576, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044309B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11037.618796825409, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 17.949803921568627, "ram_util_percent": 48.0356862745098}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23096930602234714, "mean_inference_ms": 1.0890377785983791, "mean_action_processing_ms": 0.05600734434496662, "mean_env_wait_ms": 7.613211696474932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3540000, "timesteps_this_iter": 0, "agent_timesteps_total": 7080000, "timers": {"sample_time_ms": 178154.911, "sample_throughput": 112.262, "load_time_ms": 0.4, "load_throughput": 49991704.41, "learn_time_ms": 4732.691, "learn_throughput": 4225.925, "update_time_ms": 1.798}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 1e-10, "total_loss": 38.12486190795899, "policy_loss": -0.001636794769894312, "vf_loss": 38.15689926147461, "vf_explained_var": 0.6442898273468017, "kl": 0.004899941168450828, "entropy": 3.040158271789551, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3540000, "num_agent_steps_sampled": 7080000, "num_steps_trained": 3540000, "num_agent_steps_trained": 7080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 352, "training_iteration": 177, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-54-56", "timestamp": 1704779696, "time_this_iter_s": 179.33493947982788, "time_total_s": 35423.063069820404, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443299D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11216.953736305237, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 17.941338582677165, "ram_util_percent": 47.95472440944881}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -247.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2306680206934692, "mean_inference_ms": 1.0873389098569337, "mean_action_processing_ms": 0.05592816793431444, "mean_env_wait_ms": 7.6078181749691565, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3560000, "timesteps_this_iter": 0, "agent_timesteps_total": 7120000, "timers": {"sample_time_ms": 178309.596, "sample_throughput": 112.164, "load_time_ms": 0.4, "load_throughput": 49991704.41, "learn_time_ms": 4740.702, "learn_throughput": 4218.784, "update_time_ms": 1.798}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 1e-10, "total_loss": 73.48060760498046, "policy_loss": -0.0028134868358075773, "vf_loss": 73.5133285522461, "vf_explained_var": 0.34918458461761476, "kl": 0.005304075735388536, "entropy": 2.9910601139068604, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3560000, "num_agent_steps_sampled": 7120000, "num_steps_trained": 3560000, "num_agent_steps_trained": 7120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 354, "training_iteration": 178, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_13-57-55", "timestamp": 1704779875, "time_this_iter_s": 179.0674958229065, "time_total_s": 35602.13056564331, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11396.021232128143, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 17.98779527559055, "ram_util_percent": 47.94685039370078}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -248.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23034799983313575, "mean_inference_ms": 1.0856060767755105, "mean_action_processing_ms": 0.05585488192244007, "mean_env_wait_ms": 7.602502256286985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3580000, "timesteps_this_iter": 0, "agent_timesteps_total": 7160000, "timers": {"sample_time_ms": 179015.626, "sample_throughput": 111.722, "load_time_ms": 0.4, "load_throughput": 49991704.41, "learn_time_ms": 4737.628, "learn_throughput": 4221.522, "update_time_ms": 1.798}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 1e-10, "total_loss": 29.226333618164062, "policy_loss": -0.0011031503822654498, "vf_loss": 29.25726661682129, "vf_explained_var": 0.6800616264343262, "kl": 0.004039297555399363, "entropy": 2.9830862522125243, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3580000, "num_agent_steps_sampled": 7160000, "num_steps_trained": 3580000, "num_agent_steps_trained": 7160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 356, "training_iteration": 179, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-00-58", "timestamp": 1704780058, "time_this_iter_s": 183.04591989517212, "time_total_s": 35785.17648553848, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044361F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11579.067152023315, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 18.02200772200772, "ram_util_percent": 46.8015444015444}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22999042493046795, "mean_inference_ms": 1.0836957214271878, "mean_action_processing_ms": 0.05578109439914442, "mean_env_wait_ms": 7.596672633706544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3600000, "timesteps_this_iter": 0, "agent_timesteps_total": 7200000, "timers": {"sample_time_ms": 179235.532, "sample_throughput": 111.585, "load_time_ms": 0.4, "load_throughput": 49991704.41, "learn_time_ms": 4734.033, "learn_throughput": 4224.728, "update_time_ms": 1.796}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 1e-10, "total_loss": 75.0421371459961, "policy_loss": -0.0020361577774956814, "vf_loss": 75.07328796386719, "vf_explained_var": 0.5672564029693603, "kl": 0.007321336171378601, "entropy": 2.9121774673461913, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3600000, "num_agent_steps_sampled": 7200000, "num_steps_trained": 3600000, "num_agent_steps_trained": 7200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 358, "training_iteration": 180, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-03-58", "timestamp": 1704780238, "time_this_iter_s": 179.75429153442383, "time_total_s": 35964.93077707291, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044375160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11758.82144355774, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 18.041568627450975, "ram_util_percent": 47.96549019607842}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.84, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22961395861732162, "mean_inference_ms": 1.0817000415561064, "mean_action_processing_ms": 0.05570192828101752, "mean_env_wait_ms": 7.590528846410336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3620000, "timesteps_this_iter": 0, "agent_timesteps_total": 7240000, "timers": {"sample_time_ms": 179678.361, "sample_throughput": 111.31, "load_time_ms": 0.301, "load_throughput": 66549845.299, "learn_time_ms": 4734.263, "learn_throughput": 4224.523, "update_time_ms": 1.797}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 1e-10, "total_loss": 33.28908081054688, "policy_loss": -0.0018229969956353286, "vf_loss": 33.32095451354981, "vf_explained_var": 0.6217782139778137, "kl": 0.005983494512355442, "entropy": 3.00522141456604, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3620000, "num_agent_steps_sampled": 7240000, "num_steps_trained": 3620000, "num_agent_steps_trained": 7240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 360, "training_iteration": 181, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-06-59", "timestamp": 1704780419, "time_this_iter_s": 181.29449939727783, "time_total_s": 36146.225276470184, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044577AF0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 11940.115942955017, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 17.8984375, "ram_util_percent": 48.069921875000006}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -499.32, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2292127188638739, "mean_inference_ms": 1.0796101173485453, "mean_action_processing_ms": 0.05561796602350568, "mean_env_wait_ms": 7.584250006266164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3640000, "timesteps_this_iter": 0, "agent_timesteps_total": 7280000, "timers": {"sample_time_ms": 179887.629, "sample_throughput": 111.181, "load_time_ms": 0.198, "load_throughput": 100824615.385, "learn_time_ms": 4734.652, "learn_throughput": 4224.175, "update_time_ms": 1.697}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 1e-10, "total_loss": 37.509857177734375, "policy_loss": -0.0017258663578145316, "vf_loss": 37.54233627319336, "vf_explained_var": 0.5233435750007629, "kl": 0.004327359712082135, "entropy": 3.0751805305480957, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3640000, "num_agent_steps_sampled": 7280000, "num_steps_trained": 3640000, "num_agent_steps_trained": 7280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 362, "training_iteration": 182, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-09-59", "timestamp": 1704780599, "time_this_iter_s": 179.6015501022339, "time_total_s": 36325.82682657242, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044361F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12119.717493057251, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 17.980392156862745, "ram_util_percent": 48.27372549019608}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22880360043831707, "mean_inference_ms": 1.0774080630408482, "mean_action_processing_ms": 0.05552992241370899, "mean_env_wait_ms": 7.57770095810426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3660000, "timesteps_this_iter": 0, "agent_timesteps_total": 7320000, "timers": {"sample_time_ms": 179949.335, "sample_throughput": 111.142, "load_time_ms": 0.198, "load_throughput": 100824615.385, "learn_time_ms": 4739.625, "learn_throughput": 4219.743, "update_time_ms": 1.6}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 1e-10, "total_loss": 57.32730941772461, "policy_loss": -0.002388497727587824, "vf_loss": 57.35975723266601, "vf_explained_var": 0.6128181695938111, "kl": 0.0033624060197854676, "entropy": 3.0062321186065675, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3660000, "num_agent_steps_sampled": 7320000, "num_steps_trained": 3660000, "num_agent_steps_trained": 7320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 364, "training_iteration": 183, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-12-59", "timestamp": 1704780779, "time_this_iter_s": 179.91939163208008, "time_total_s": 36505.7462182045, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445B4040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12299.636884689331, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 17.972549019607843, "ram_util_percent": 48.234117647058824}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22838851215834297, "mean_inference_ms": 1.0751756758966478, "mean_action_processing_ms": 0.05544224885110063, "mean_env_wait_ms": 7.571158251135448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3680000, "timesteps_this_iter": 0, "agent_timesteps_total": 7360000, "timers": {"sample_time_ms": 180282.141, "sample_throughput": 110.937, "load_time_ms": 0.198, "load_throughput": 100764060.06, "learn_time_ms": 4731.794, "learn_throughput": 4226.727, "update_time_ms": 1.6}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 1e-10, "total_loss": 188.8709289550781, "policy_loss": -0.0018941078718007986, "vf_loss": 188.9032958984375, "vf_explained_var": 0.282500422000885, "kl": 0.006134585841296425, "entropy": 3.0468765258789063, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3680000, "num_agent_steps_sampled": 7360000, "num_steps_trained": 3680000, "num_agent_steps_trained": 7360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 366, "training_iteration": 184, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-15-59", "timestamp": 1704780959, "time_this_iter_s": 180.1624686717987, "time_total_s": 36685.9086868763, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12479.79935336113, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 17.975294117647056, "ram_util_percent": 46.917647058823526}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22798056995801708, "mean_inference_ms": 1.0729497631085032, "mean_action_processing_ms": 0.055356818685312295, "mean_env_wait_ms": 7.564832176535836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3700000, "timesteps_this_iter": 0, "agent_timesteps_total": 7400000, "timers": {"sample_time_ms": 180297.155, "sample_throughput": 110.928, "load_time_ms": 0.198, "load_throughput": 100764060.06, "learn_time_ms": 4731.483, "learn_throughput": 4227.004, "update_time_ms": 1.7}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 1e-10, "total_loss": 73.11488494873046, "policy_loss": -0.0021641941868513646, "vf_loss": 73.14744720458984, "vf_explained_var": 0.43597739934921265, "kl": 0.0038989730954822055, "entropy": 3.04003324508667, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3700000, "num_agent_steps_sampled": 7400000, "num_steps_trained": 3700000, "num_agent_steps_trained": 7400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 368, "training_iteration": 185, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-19-00", "timestamp": 1704781140, "time_this_iter_s": 180.48116779327393, "time_total_s": 36866.38985466957, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445B4C10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12660.280521154404, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 17.828235294117647, "ram_util_percent": 48.090980392156865}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -250.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22759986608012334, "mean_inference_ms": 1.0708752588838617, "mean_action_processing_ms": 0.055276966283068434, "mean_env_wait_ms": 7.559016676657977, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3720000, "timesteps_this_iter": 0, "agent_timesteps_total": 7440000, "timers": {"sample_time_ms": 180057.238, "sample_throughput": 111.076, "load_time_ms": 0.198, "load_throughput": 100764060.06, "learn_time_ms": 4730.922, "learn_throughput": 4227.506, "update_time_ms": 1.799}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 1e-10, "total_loss": 135.47613830566405, "policy_loss": -0.002099274517148686, "vf_loss": 135.50777282714844, "vf_explained_var": 0.3296614646911621, "kl": 0.007064244615606086, "entropy": 2.954212474822998, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3720000, "num_agent_steps_sampled": 7440000, "num_steps_trained": 3720000, "num_agent_steps_trained": 7440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 370, "training_iteration": 186, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-21-57", "timestamp": 1704781317, "time_this_iter_s": 177.62009739875793, "time_total_s": 37044.00995206833, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044361DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 12837.900618553162, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 17.898412698412695, "ram_util_percent": 48.13571428571429}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22723574893153128, "mean_inference_ms": 1.0689015837072275, "mean_action_processing_ms": 0.055201823645711696, "mean_env_wait_ms": 7.553571277300357, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3740000, "timesteps_this_iter": 0, "agent_timesteps_total": 7480000, "timers": {"sample_time_ms": 179944.471, "sample_throughput": 111.145, "load_time_ms": 0.202, "load_throughput": 99097554.637, "learn_time_ms": 4731.174, "learn_throughput": 4227.281, "update_time_ms": 1.687}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 1e-10, "total_loss": 78.56158447265625, "policy_loss": -0.0017806089241988233, "vf_loss": 78.59368743896485, "vf_explained_var": 0.5804577827453613, "kl": 0.0045095997151952, "entropy": 3.0323816299438477, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3740000, "num_agent_steps_sampled": 7480000, "num_steps_trained": 3740000, "num_agent_steps_trained": 7480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 372, "training_iteration": 187, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-24-55", "timestamp": 1704781495, "time_this_iter_s": 178.21532011032104, "time_total_s": 37222.22527217865, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044329D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13016.115938663483, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 17.907936507936505, "ram_util_percent": 48.17063492063492}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22690431145603718, "mean_inference_ms": 1.0670660793614462, "mean_action_processing_ms": 0.05513103601669592, "mean_env_wait_ms": 7.5485912925551135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3760000, "timesteps_this_iter": 0, "agent_timesteps_total": 7520000, "timers": {"sample_time_ms": 180045.707, "sample_throughput": 111.083, "load_time_ms": 0.202, "load_throughput": 99097554.637, "learn_time_ms": 4731.233, "learn_throughput": 4227.228, "update_time_ms": 1.684}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 1e-10, "total_loss": 39.94010467529297, "policy_loss": -0.001998493861556061, "vf_loss": 39.97202377319336, "vf_explained_var": 0.7048175811767579, "kl": 0.003417876189222291, "entropy": 2.992211627960205, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3760000, "num_agent_steps_sampled": 7520000, "num_steps_trained": 3760000, "num_agent_steps_trained": 7520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 374, "training_iteration": 188, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-27-56", "timestamp": 1704781676, "time_this_iter_s": 180.0812075138092, "time_total_s": 37402.30647969246, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B73A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13196.197146177292, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 18.1453125, "ram_util_percent": 48.195312500000014}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22659041042964298, "mean_inference_ms": 1.0653513413200246, "mean_action_processing_ms": 0.055066683340206736, "mean_env_wait_ms": 7.5439081856809524, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3780000, "timesteps_this_iter": 0, "agent_timesteps_total": 7560000, "timers": {"sample_time_ms": 179687.406, "sample_throughput": 111.304, "load_time_ms": 0.202, "load_throughput": 99097554.637, "learn_time_ms": 4731.454, "learn_throughput": 4227.031, "update_time_ms": 1.587}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.552713678800501e-16, "cur_lr": 1e-10, "total_loss": 68.56546096801758, "policy_loss": -0.0018568819367512646, "vf_loss": 68.59743194580078, "vf_explained_var": 0.5821156144142151, "kl": 0.003822580176959178, "entropy": 3.0117477893829347, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3780000, "num_agent_steps_sampled": 7560000, "num_steps_trained": 3780000, "num_agent_steps_trained": 7560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 376, "training_iteration": 189, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-30-55", "timestamp": 1704781855, "time_this_iter_s": 179.4628143310547, "time_total_s": 37581.769294023514, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570D30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13375.659960508347, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 17.88976377952756, "ram_util_percent": 46.98228346456692}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -249.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22629536553048715, "mean_inference_ms": 1.0637458749699433, "mean_action_processing_ms": 0.055006650940615624, "mean_env_wait_ms": 7.539509174467298, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3800000, "timesteps_this_iter": 0, "agent_timesteps_total": 7600000, "timers": {"sample_time_ms": 179469.25, "sample_throughput": 111.44, "load_time_ms": 0.202, "load_throughput": 99097554.637, "learn_time_ms": 4734.059, "learn_throughput": 4224.704, "update_time_ms": 1.686}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 1e-10, "total_loss": 37.29088592529297, "policy_loss": -0.0025145525839924687, "vf_loss": 37.323571014404294, "vf_explained_var": 0.6868967771530151, "kl": 0.005447294187721408, "entropy": 3.016984224319458, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3800000, "num_agent_steps_sampled": 7600000, "num_steps_trained": 3800000, "num_agent_steps_trained": 7600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 378, "training_iteration": 190, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-33-53", "timestamp": 1704782033, "time_this_iter_s": 177.59703707695007, "time_total_s": 37759.366331100464, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443299D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13553.256997585297, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 18.133864541832672, "ram_util_percent": 48.17609561752988}}
{"episode_reward_max": -176.0, "episode_reward_min": -600.0, "episode_reward_mean": -494.32, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -88.0}, "policy_reward_mean": {"shared_policy": -247.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -200.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22602456683318173, "mean_inference_ms": 1.062238604272626, "mean_action_processing_ms": 0.054949384951854224, "mean_env_wait_ms": 7.535447663355552, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3820000, "timesteps_this_iter": 0, "agent_timesteps_total": 7640000, "timers": {"sample_time_ms": 179409.665, "sample_throughput": 111.477, "load_time_ms": 0.202, "load_throughput": 99097554.637, "learn_time_ms": 4731.196, "learn_throughput": 4227.261, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 1e-10, "total_loss": 71.37329406738282, "policy_loss": -0.002455917230881788, "vf_loss": 71.40608215332031, "vf_explained_var": 0.4020102143287659, "kl": 0.004761516964051182, "entropy": 3.0331578254699707, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3820000, "num_agent_steps_sampled": 7640000, "num_steps_trained": 3820000, "num_agent_steps_trained": 7640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 380, "training_iteration": 191, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-36-53", "timestamp": 1704782213, "time_this_iter_s": 180.65026187896729, "time_total_s": 37940.01659297943, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044283CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13733.907259464264, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 18.141406250000003, "ram_util_percent": 48.264453125}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -246.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2257646880740802, "mean_inference_ms": 1.0608192307949684, "mean_action_processing_ms": 0.05489616599479692, "mean_env_wait_ms": 7.5315515543281775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3840000, "timesteps_this_iter": 0, "agent_timesteps_total": 7680000, "timers": {"sample_time_ms": 178888.771, "sample_throughput": 111.801, "load_time_ms": 0.305, "load_throughput": 65674532.216, "learn_time_ms": 4732.482, "learn_throughput": 4226.112, "update_time_ms": 1.588}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.881784197001253e-17, "cur_lr": 1e-10, "total_loss": 66.01164245605469, "policy_loss": -0.00220218658827247, "vf_loss": 66.04396591186523, "vf_explained_var": 0.34427101612091066, "kl": 0.005499405764890231, "entropy": 3.0118330001831053, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3840000, "num_agent_steps_sampled": 7680000, "num_steps_trained": 3840000, "num_agent_steps_trained": 7680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 382, "training_iteration": 192, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-39-48", "timestamp": 1704782388, "time_this_iter_s": 174.43409419059753, "time_total_s": 38114.45068717003, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445775E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 13908.341353654861, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 17.989473684210523, "ram_util_percent": 48.32510121457488}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -246.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22551706911904026, "mean_inference_ms": 1.0594746707768337, "mean_action_processing_ms": 0.054847762996116003, "mean_env_wait_ms": 7.527854579695766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3860000, "timesteps_this_iter": 0, "agent_timesteps_total": 7720000, "timers": {"sample_time_ms": 178959.69, "sample_throughput": 111.757, "load_time_ms": 0.305, "load_throughput": 65674532.216, "learn_time_ms": 4731.541, "learn_throughput": 4226.953, "update_time_ms": 1.585}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.881784197001253e-17, "cur_lr": 1e-10, "total_loss": 17.794287490844727, "policy_loss": -0.0012960258261114355, "vf_loss": 17.825593566894533, "vf_explained_var": 0.832529628276825, "kl": 0.0033590050708188768, "entropy": 3.0010529518127442, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3860000, "num_agent_steps_sampled": 7720000, "num_steps_trained": 3860000, "num_agent_steps_trained": 7720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 384, "training_iteration": 193, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-42-48", "timestamp": 1704782568, "time_this_iter_s": 180.60576128959656, "time_total_s": 38295.056448459625, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044577A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14088.947114944458, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 17.845703125, "ram_util_percent": 48.185546875}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -247.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.225281095554995, "mean_inference_ms": 1.0582263797638691, "mean_action_processing_ms": 0.05480437392579081, "mean_env_wait_ms": 7.52445874002007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3880000, "timesteps_this_iter": 0, "agent_timesteps_total": 7760000, "timers": {"sample_time_ms": 179327.941, "sample_throughput": 111.528, "load_time_ms": 0.307, "load_throughput": 65209950.249, "learn_time_ms": 4740.509, "learn_throughput": 4218.956, "update_time_ms": 1.586}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 1e-10, "total_loss": 88.30834655761718, "policy_loss": -0.0017253687673620898, "vf_loss": 88.3400894165039, "vf_explained_var": 0.49843927621841433, "kl": 0.007121914219769332, "entropy": 3.001671886444092, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3880000, "num_agent_steps_sampled": 7760000, "num_steps_trained": 3880000, "num_agent_steps_trained": 7760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 386, "training_iteration": 194, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-45-52", "timestamp": 1704782752, "time_this_iter_s": 183.9423224925995, "time_total_s": 38478.998770952225, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044361DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14272.889437437057, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 22.694615384615386, "ram_util_percent": 50.049615384615386}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -247.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22506220067657792, "mean_inference_ms": 1.0570689009259866, "mean_action_processing_ms": 0.054765330487494414, "mean_env_wait_ms": 7.521387348301276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3900000, "timesteps_this_iter": 0, "agent_timesteps_total": 7800000, "timers": {"sample_time_ms": 179884.21, "sample_throughput": 111.183, "load_time_ms": 0.307, "load_throughput": 65209950.249, "learn_time_ms": 4756.451, "learn_throughput": 4204.815, "update_time_ms": 1.489}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 1e-10, "total_loss": 139.91331176757814, "policy_loss": -0.0008572148812003632, "vf_loss": 139.94480895996094, "vf_explained_var": 0.1515470862388611, "kl": 0.005998285851012264, "entropy": 3.063292455673218, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3900000, "num_agent_steps_sampled": 7800000, "num_steps_trained": 3900000, "num_agent_steps_trained": 7800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 388, "training_iteration": 195, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-48-59", "timestamp": 1704782939, "time_this_iter_s": 186.11132311820984, "time_total_s": 38665.110094070435, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044202F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14459.000760555267, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 22.194318181818183, "ram_util_percent": 52.905303030303024}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -246.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22486213113985215, "mean_inference_ms": 1.0560054684752784, "mean_action_processing_ms": 0.054729838969578226, "mean_env_wait_ms": 7.518700649205584, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3920000, "timesteps_this_iter": 0, "agent_timesteps_total": 7840000, "timers": {"sample_time_ms": 181301.865, "sample_throughput": 110.313, "load_time_ms": 0.307, "load_throughput": 65209950.249, "learn_time_ms": 4769.768, "learn_throughput": 4193.076, "update_time_ms": 1.389}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 1e-10, "total_loss": 81.12479248046876, "policy_loss": -0.001821074074134188, "vf_loss": 81.15762481689453, "vf_explained_var": 0.5444589376449585, "kl": 0.00400655638129419, "entropy": 3.1010772705078127, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3920000, "num_agent_steps_sampled": 7840000, "num_steps_trained": 3920000, "num_agent_steps_trained": 7840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 390, "training_iteration": 196, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-52-10", "timestamp": 1704783130, "time_this_iter_s": 191.77168726921082, "time_total_s": 38856.881781339645, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044577F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14650.772447824478, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 23.813653136531364, "ram_util_percent": 55.39963099630996}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -246.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2246739982957636, "mean_inference_ms": 1.0550318505759133, "mean_action_processing_ms": 0.05469657408050102, "mean_env_wait_ms": 7.516317003798317, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3940000, "timesteps_this_iter": 0, "agent_timesteps_total": 7880000, "timers": {"sample_time_ms": 182483.171, "sample_throughput": 109.599, "load_time_ms": 0.205, "load_throughput": 97735150.88, "learn_time_ms": 4795.156, "learn_throughput": 4170.876, "update_time_ms": 1.489}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2204460492503132e-17, "cur_lr": 1e-10, "total_loss": 32.90230369567871, "policy_loss": -0.0017157221545837764, "vf_loss": 32.93496246337891, "vf_explained_var": 0.7205198645591736, "kl": 0.005459621079610688, "entropy": 3.094404697418213, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3940000, "num_agent_steps_sampled": 7880000, "num_steps_trained": 3940000, "num_agent_steps_trained": 7880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 392, "training_iteration": 197, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-55-21", "timestamp": 1704783321, "time_this_iter_s": 190.1489245891571, "time_total_s": 39047.0307059288, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044309B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 14840.921372413635, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 21.845925925925926, "ram_util_percent": 55.51074074074073}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -495.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -247.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22450045413515832, "mean_inference_ms": 1.0541451696967388, "mean_action_processing_ms": 0.05466702012081896, "mean_env_wait_ms": 7.51407092648062, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3960000, "timesteps_this_iter": 0, "agent_timesteps_total": 7920000, "timers": {"sample_time_ms": 183233.241, "sample_throughput": 109.151, "load_time_ms": 0.205, "load_throughput": 97735150.88, "learn_time_ms": 4825.625, "learn_throughput": 4144.541, "update_time_ms": 1.392}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.2204460492503132e-17, "cur_lr": 1e-10, "total_loss": 20.268957901000977, "policy_loss": -0.0028490901938453385, "vf_loss": 20.302654647827147, "vf_explained_var": 0.8526435971260071, "kl": 0.004546507414938827, "entropy": 3.0848357677459717, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3960000, "num_agent_steps_sampled": 7920000, "num_steps_trained": 3960000, "num_agent_steps_trained": 7920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 394, "training_iteration": 198, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_14-58-28", "timestamp": 1704783508, "time_this_iter_s": 187.60971021652222, "time_total_s": 39234.640416145325, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15028.531082630157, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 23.534210526315793, "ram_util_percent": 54.849624060150376}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -246.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22434755804424517, "mean_inference_ms": 1.0533505214673786, "mean_action_processing_ms": 0.054640282297315663, "mean_env_wait_ms": 7.512107973594753, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3980000, "timesteps_this_iter": 0, "agent_timesteps_total": 7960000, "timers": {"sample_time_ms": 184787.291, "sample_throughput": 108.233, "load_time_ms": 0.205, "load_throughput": 97735150.88, "learn_time_ms": 4864.325, "learn_throughput": 4111.568, "update_time_ms": 1.489}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1102230246251566e-17, "cur_lr": 1e-10, "total_loss": 31.645454788208006, "policy_loss": -0.0024422331383451732, "vf_loss": 31.67848358154297, "vf_explained_var": 0.7095075249671936, "kl": 0.004527152788981592, "entropy": 3.0588077545166015, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3980000, "num_agent_steps_sampled": 7960000, "num_steps_trained": 3980000, "num_agent_steps_trained": 7960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 396, "training_iteration": 199, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-01-43", "timestamp": 1704783703, "time_this_iter_s": 195.08505821228027, "time_total_s": 39429.725474357605, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F04438CEE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 15223.616140842438, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 25.70942028985507, "ram_util_percent": 55.43079710144928}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.56, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -246.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-284.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-142.0, -142.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22421096120038786, "mean_inference_ms": 1.0526426612605966, "mean_action_processing_ms": 0.054617692269894234, "mean_env_wait_ms": 7.5103467733473845, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4000000, "timesteps_this_iter": 0, "agent_timesteps_total": 8000000, "timers": {"sample_time_ms": 186626.907, "sample_throughput": 107.166, "load_time_ms": 0.205, "load_throughput": 97735150.88, "learn_time_ms": 4906.439, "learn_throughput": 4076.276, "update_time_ms": 1.292}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 1e-10, "total_loss": 22.402521896362305, "policy_loss": -0.002172800332792102, "vf_loss": 22.434751892089842, "vf_explained_var": 0.7562019228935242, "kl": 0.006400563143766469, "entropy": 3.0058021068573, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4000000, "num_agent_steps_sampled": 8000000, "num_steps_trained": 4000000, "num_agent_steps_trained": 8000000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -460.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -230.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2235516637368372, "mean_inference_ms": 1.1209050336530308, "mean_action_processing_ms": 0.05840976386734155, "mean_env_wait_ms": 7.621812348176951, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 398, "training_iteration": 200, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-20-33", "timestamp": 1704784833, "time_this_iter_s": 1129.2268207073212, "time_total_s": 40558.952295064926, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16352.842961549759, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 23.204135338345868, "ram_util_percent": 55.13270676691729}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -248.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22409110828917975, "mean_inference_ms": 1.0520131982547303, "mean_action_processing_ms": 0.054598546128821986, "mean_env_wait_ms": 7.508698268483972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4020000, "timesteps_this_iter": 0, "agent_timesteps_total": 8040000, "timers": {"sample_time_ms": 281188.499, "sample_throughput": 71.127, "load_time_ms": 0.205, "load_throughput": 97735150.88, "learn_time_ms": 4948.961, "learn_throughput": 4041.253, "update_time_ms": 1.389}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 1e-10, "total_loss": 47.36958618164063, "policy_loss": -0.002233991084154674, "vf_loss": 47.40211715698242, "vf_explained_var": 0.7538561701774598, "kl": 0.003902306591199256, "entropy": 3.0298055171966554, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4020000, "num_agent_steps_sampled": 8040000, "num_steps_trained": 4020000, "num_agent_steps_trained": 8040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 400, "training_iteration": 201, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-23-46", "timestamp": 1704785026, "time_this_iter_s": 193.04851603507996, "time_total_s": 40752.000811100006, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443D0EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16545.89147758484, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 23.405109489051096, "ram_util_percent": 54.465328467153284}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -496.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -248.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2239821738255187, "mean_inference_ms": 1.05144839796346, "mean_action_processing_ms": 0.0545803756596141, "mean_env_wait_ms": 7.5072618440622145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4040000, "timesteps_this_iter": 0, "agent_timesteps_total": 8080000, "timers": {"sample_time_ms": 282680.057, "sample_throughput": 70.751, "load_time_ms": 0.102, "load_throughput": 196224748.538, "learn_time_ms": 4952.514, "learn_throughput": 4038.353, "update_time_ms": 1.388}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.7755575615628915e-18, "cur_lr": 1e-10, "total_loss": 15.576702880859376, "policy_loss": -0.002271910410858702, "vf_loss": 15.60931224822998, "vf_explained_var": 0.8595111846923829, "kl": 0.003007807093248438, "entropy": 3.0336533069610594, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4040000, "num_agent_steps_sampled": 8080000, "num_steps_trained": 4040000, "num_agent_steps_trained": 8080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 402, "training_iteration": 202, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-26-55", "timestamp": 1704785215, "time_this_iter_s": 188.95928144454956, "time_total_s": 40940.960092544556, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16734.85075902939, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 20.52059925093633, "ram_util_percent": 55.0}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -249.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22388580346110057, "mean_inference_ms": 1.050949655714281, "mean_action_processing_ms": 0.05456537365483545, "mean_env_wait_ms": 7.506080086938498, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4060000, "timesteps_this_iter": 0, "agent_timesteps_total": 8120000, "timers": {"sample_time_ms": 283755.342, "sample_throughput": 70.483, "load_time_ms": 0.102, "load_throughput": 196224748.538, "learn_time_ms": 4983.155, "learn_throughput": 4013.522, "update_time_ms": 1.49}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 1e-10, "total_loss": 43.13226089477539, "policy_loss": -0.0014381238895095905, "vf_loss": 43.16415939331055, "vf_explained_var": 0.7027743339538575, "kl": 0.0051943357262771, "entropy": 3.0458088874816895, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4060000, "num_agent_steps_sampled": 8120000, "num_steps_trained": 4060000, "num_agent_steps_trained": 8120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 404, "training_iteration": 203, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-30-06", "timestamp": 1704785406, "time_this_iter_s": 191.63309001922607, "time_total_s": 41132.59318256378, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044589C10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16926.483849048615, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 23.136397058823526, "ram_util_percent": 54.654411764705884}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -250.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22380508015714362, "mean_inference_ms": 1.050527623952541, "mean_action_processing_ms": 0.05455417658240581, "mean_env_wait_ms": 7.505190031435384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4080000, "timesteps_this_iter": 0, "agent_timesteps_total": 8160000, "timers": {"sample_time_ms": 285105.963, "sample_throughput": 70.149, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5004.957, "learn_throughput": 3996.038, "update_time_ms": 1.495}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 1e-10, "total_loss": 60.837223815917966, "policy_loss": -0.0030141029429808343, "vf_loss": 60.870654296875, "vf_explained_var": 0.5847400307655335, "kl": 0.005180951844416359, "entropy": 3.0415446758270264, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4080000, "num_agent_steps_sampled": 8160000, "num_steps_trained": 4080000, "num_agent_steps_trained": 8160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 406, "training_iteration": 204, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-33-24", "timestamp": 1704785604, "time_this_iter_s": 197.3548927307129, "time_total_s": 41329.948075294495, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044589280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17123.838741779327, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 27.570967741935487, "ram_util_percent": 54.99677419354838}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -498.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -249.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22374031051651053, "mean_inference_ms": 1.0501800937460126, "mean_action_processing_ms": 0.054546876049017465, "mean_env_wait_ms": 7.50449971084074, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4100000, "timesteps_this_iter": 0, "agent_timesteps_total": 8200000, "timers": {"sample_time_ms": 286109.081, "sample_throughput": 69.903, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5012.703, "learn_throughput": 3989.863, "update_time_ms": 1.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 1e-10, "total_loss": 139.17339630126952, "policy_loss": -0.0018130618318913604, "vf_loss": 139.20526428222655, "vf_explained_var": 0.5749763488769531, "kl": 0.0048064666043568845, "entropy": 3.004988956451416, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4100000, "num_agent_steps_sampled": 8200000, "num_steps_trained": 4100000, "num_agent_steps_trained": 8200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 408, "training_iteration": 205, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-36-40", "timestamp": 1704785800, "time_this_iter_s": 195.99483823776245, "time_total_s": 41525.94291353226, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445B13A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17319.83358001709, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 27.272924187725632, "ram_util_percent": 55.31371841155235}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -250.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2236887630842874, "mean_inference_ms": 1.0499080430718575, "mean_action_processing_ms": 0.05454267636450678, "mean_env_wait_ms": 7.504072767581437, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4120000, "timesteps_this_iter": 0, "agent_timesteps_total": 8240000, "timers": {"sample_time_ms": 286694.846, "sample_throughput": 69.761, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5026.907, "learn_throughput": 3978.59, "update_time_ms": 1.593}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.938893903907229e-19, "cur_lr": 1e-10, "total_loss": 32.89585800170899, "policy_loss": -0.002302220394983889, "vf_loss": 32.92835388183594, "vf_explained_var": 0.7898866415023804, "kl": 0.004851934622951681, "entropy": 3.0194887638092043, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4120000, "num_agent_steps_sampled": 8240000, "num_steps_trained": 4120000, "num_agent_steps_trained": 8240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 410, "training_iteration": 206, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-39-57", "timestamp": 1704785997, "time_this_iter_s": 197.6961419582367, "time_total_s": 41723.639055490494, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17517.529721975327, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 29.494642857142857, "ram_util_percent": 56.31214285714285}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -502.72, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -251.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22363971094316626, "mean_inference_ms": 1.0496688187363221, "mean_action_processing_ms": 0.05453947348876102, "mean_env_wait_ms": 7.5037659491339515, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4140000, "timesteps_this_iter": 0, "agent_timesteps_total": 8280000, "timers": {"sample_time_ms": 285872.728, "sample_throughput": 69.961, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 5003.821, "learn_throughput": 3996.945, "update_time_ms": 1.591}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.4694469519536144e-19, "cur_lr": 1e-10, "total_loss": 79.46197204589843, "policy_loss": -0.003034363180734223, "vf_loss": 79.49522857666015, "vf_explained_var": 0.419180428981781, "kl": 0.004249631554837619, "entropy": 3.0222384929656982, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4140000, "num_agent_steps_sampled": 8280000, "num_steps_trained": 4140000, "num_agent_steps_trained": 8280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 412, "training_iteration": 207, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-42-59", "timestamp": 1704786179, "time_this_iter_s": 181.55365324020386, "time_total_s": 41905.1927087307, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0443B7670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17699.08337521553, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 19.200781250000002, "ram_util_percent": 54.531640624999994}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.96, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -250.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -424.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -212.0, -212.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22360132557110632, "mean_inference_ms": 1.0494630738472053, "mean_action_processing_ms": 0.0545381106534564, "mean_env_wait_ms": 7.503523075163225, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4160000, "timesteps_this_iter": 0, "agent_timesteps_total": 8320000, "timers": {"sample_time_ms": 285375.617, "sample_throughput": 70.083, "load_time_ms": 0.0, "load_throughput": 0.0, "learn_time_ms": 4991.314, "learn_throughput": 4006.961, "update_time_ms": 1.688}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7347234759768072e-19, "cur_lr": 1e-10, "total_loss": 74.13495788574218, "policy_loss": -0.0020937725130096064, "vf_loss": 74.16688842773438, "vf_explained_var": 0.46600199937820436, "kl": 0.00500485603811125, "entropy": 2.983352518081665, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4160000, "num_agent_steps_sampled": 8320000, "num_steps_trained": 4160000, "num_agent_steps_trained": 8320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 414, "training_iteration": 208, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-46-02", "timestamp": 1704786362, "time_this_iter_s": 182.76157975196838, "time_total_s": 42087.954288482666, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044570550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 17881.8449549675, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 20.758527131782948, "ram_util_percent": 52.37790697674417}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.96, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -250.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -424.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -212.0, -212.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.223573022378309, "mean_inference_ms": 1.0492984940962191, "mean_action_processing_ms": 0.054538573398025106, "mean_env_wait_ms": 7.503385895971055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4180000, "timesteps_this_iter": 0, "agent_timesteps_total": 8360000, "timers": {"sample_time_ms": 284522.572, "sample_throughput": 70.293, "load_time_ms": 0.107, "load_throughput": 187664608.501, "learn_time_ms": 4984.398, "learn_throughput": 4012.521, "update_time_ms": 1.688}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.7347234759768072e-19, "cur_lr": 1e-10, "total_loss": 61.74864044189453, "policy_loss": -0.0024118228540569537, "vf_loss": 61.781107330322264, "vf_explained_var": 0.45755730867385863, "kl": 0.003547201460581295, "entropy": 3.005639600753784, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4180000, "num_agent_steps_sampled": 8360000, "num_steps_trained": 4180000, "num_agent_steps_trained": 8360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 416, "training_iteration": 209, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-49-08", "timestamp": 1704786548, "time_this_iter_s": 186.6117467880249, "time_total_s": 42274.56603527069, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F044207E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18068.456701755524, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 21.105283018867926, "ram_util_percent": 53.98603773584905}}
{"episode_reward_max": -124.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.96, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -62.0}, "policy_reward_mean": {"shared_policy": -250.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -200.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -248.0, -524.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -400.0, -400.0, -176.0, -400.0, -124.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -600.0, -600.0, -600.0, -400.0, -424.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -100.0, -100.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -124.0, -124.0, -262.0, -262.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -88.0, -88.0, -200.0, -200.0, -62.0, -62.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -212.0, -212.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22355433928603122, "mean_inference_ms": 1.0491738696273725, "mean_action_processing_ms": 0.05454171596049539, "mean_env_wait_ms": 7.503342714277618, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4200000, "timesteps_this_iter": 0, "agent_timesteps_total": 8400000, "timers": {"sample_time_ms": 283469.336, "sample_throughput": 70.554, "load_time_ms": 0.107, "load_throughput": 187664608.501, "learn_time_ms": 5025.064, "learn_throughput": 3980.049, "update_time_ms": 1.785}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 8.673617379884036e-20, "cur_lr": 1e-10, "total_loss": 10.56346778869629, "policy_loss": -0.0022624017777666426, "vf_loss": 10.59521427154541, "vf_explained_var": 0.8743620991706849, "kl": 0.0038051450381807682, "entropy": 2.948370361328125, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4200000, "num_agent_steps_sampled": 8400000, "num_steps_trained": 4200000, "num_agent_steps_trained": 8400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 418, "training_iteration": 210, "trial_id": "7b423_00000", "experiment_id": "3d52f98b96684a08a77e9a23840c4aca", "date": "2024-01-09_15-52-14", "timestamp": 1704786734, "time_this_iter_s": 185.9655363559723, "time_total_s": 42460.53157162666, "pid": 2232, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\checkpoint_000120\\checkpoint-120", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_2de53_00000_0_2024-01-08_10-32-34\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "128-256"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x000001F0445A7C10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 18254.422238111496, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 21.136882129277566, "ram_util_percent": 54.103422053231945}}

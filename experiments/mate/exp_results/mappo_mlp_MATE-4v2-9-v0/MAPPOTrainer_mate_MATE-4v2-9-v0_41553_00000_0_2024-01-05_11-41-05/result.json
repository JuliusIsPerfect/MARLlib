{"episode_reward_max": -400.0, "episode_reward_min": -400.0, "episode_reward_mean": -400.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -200.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -200.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0], "episode_lengths": [10001], "policy_shared_policy_reward": [-200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.18283426925531776, "mean_inference_ms": 0.9646859504444517, "mean_action_processing_ms": 0.05375065271165763, "mean_env_wait_ms": 7.466835115237341, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 420000, "timesteps_this_iter": 0, "agent_timesteps_total": 840000, "timers": {"sample_time_ms": 173837.88, "sample_throughput": 115.05, "load_time_ms": 0.522, "load_throughput": 38304146.119, "learn_time_ms": 957.489, "learn_throughput": 20887.973, "update_time_ms": 1.459}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 1e-10, "total_loss": 206.60670166015626, "policy_loss": -0.0001190708540146801, "vf_loss": 206.63897705078125, "vf_explained_var": 0.00232086181640625, "kl": 2.064289381237261e-05, "entropy": 3.2176260471343996, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 420000, "num_agent_steps_sampled": 840000, "num_steps_trained": 420000, "num_agent_steps_trained": 840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 21, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_11-44-07", "timestamp": 1704426247, "time_this_iter_s": 174.74394059181213, "time_total_s": 4150.9038462638855, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE01B5E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 174.74394059181213, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.348790322580644, "ram_util_percent": 82.81290322580647}}
{"episode_reward_max": -400.0, "episode_reward_min": -400.0, "episode_reward_mean": -400.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -200.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -200.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.19632822822863702, "mean_inference_ms": 0.9796909460403485, "mean_action_processing_ms": 0.055110337545265176, "mean_env_wait_ms": 7.489596857399616, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 440000, "timesteps_this_iter": 0, "agent_timesteps_total": 880000, "timers": {"sample_time_ms": 175867.718, "sample_throughput": 113.722, "load_time_ms": 0.509, "load_throughput": 39290903.981, "learn_time_ms": 964.092, "learn_throughput": 20744.905, "update_time_ms": 1.461}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 1e-10, "total_loss": 75.0860107421875, "policy_loss": -5.374822579380378e-05, "vf_loss": 75.11824645996094, "vf_explained_var": 0.0030591607093811033, "kl": 1.1044564262951972e-05, "entropy": 3.2177320957183837, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 440000, "num_agent_steps_sampled": 880000, "num_steps_trained": 440000, "num_agent_steps_trained": 880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 42, "training_iteration": 22, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_11-47-04", "timestamp": 1704426424, "time_this_iter_s": 177.8866400718689, "time_total_s": 4328.790486335754, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE357700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 352.63058066368103, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 24.67649402390438, "ram_util_percent": 83.47649402390438}}
{"episode_reward_max": -400.0, "episode_reward_min": -400.0, "episode_reward_mean": -400.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -200.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -200.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1992395537372782, "mean_inference_ms": 0.9796472838288169, "mean_action_processing_ms": 0.055009304266885974, "mean_env_wait_ms": 7.474392045262704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 460000, "timesteps_this_iter": 0, "agent_timesteps_total": 920000, "timers": {"sample_time_ms": 174865.785, "sample_throughput": 114.373, "load_time_ms": 0.513, "load_throughput": 39016781.395, "learn_time_ms": 966.451, "learn_throughput": 20694.277, "update_time_ms": 1.462}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 1e-10, "total_loss": 153.23796997070312, "policy_loss": -4.006216075040925e-05, "vf_loss": 153.27018127441406, "vf_explained_var": 0.0028734445571899415, "kl": 1.0326679180039377e-05, "entropy": 3.21781587600708, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 460000, "num_agent_steps_sampled": 920000, "num_steps_trained": 460000, "num_agent_steps_trained": 920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 44, "training_iteration": 23, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_11-49-57", "timestamp": 1704426597, "time_this_iter_s": 172.83917260169983, "time_total_s": 4501.629658937454, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE4EBA60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 525.4697532653809, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 18.571428571428577, "ram_util_percent": 82.68530612244896}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -428.57142857142856, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -214.28571428571428}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2004045032321605, "mean_inference_ms": 0.9779689234753886, "mean_action_processing_ms": 0.05484619707162254, "mean_env_wait_ms": 7.464204237535957, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 480000, "timesteps_this_iter": 0, "agent_timesteps_total": 960000, "timers": {"sample_time_ms": 174550.668, "sample_throughput": 114.58, "load_time_ms": 0.384, "load_throughput": 52022375.194, "learn_time_ms": 971.356, "learn_throughput": 20589.775, "update_time_ms": 1.462}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 1e-10, "total_loss": 129.4934112548828, "policy_loss": -5.427035458271945e-05, "vf_loss": 129.52564086914063, "vf_explained_var": 0.005080687999725342, "kl": 1.085580264774677e-05, "entropy": 3.217630910873413, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 480000, "num_agent_steps_sampled": 960000, "num_steps_trained": 480000, "num_agent_steps_trained": 960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 46, "training_iteration": 24, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_11-52-51", "timestamp": 1704426771, "time_this_iter_s": 173.59414410591125, "time_total_s": 4675.2238030433655, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE357940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 699.0638973712921, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 18.09755102040816, "ram_util_percent": 82.08734693877551}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -444.44444444444446, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -222.22222222222223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20147096032435052, "mean_inference_ms": 0.9761479590381865, "mean_action_processing_ms": 0.05469186051060594, "mean_env_wait_ms": 7.455280859677703, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 500000, "timesteps_this_iter": 0, "agent_timesteps_total": 1000000, "timers": {"sample_time_ms": 174256.82, "sample_throughput": 114.773, "load_time_ms": 0.407, "load_throughput": 49165443.676, "learn_time_ms": 969.136, "learn_throughput": 20636.948, "update_time_ms": 1.468}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 1e-10, "total_loss": 136.5952606201172, "policy_loss": -5.0354441941014016e-05, "vf_loss": 136.62749633789062, "vf_explained_var": 0.002020096778869629, "kl": 6.004170126489017e-06, "entropy": 3.2177991390228273, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 500000, "num_agent_steps_sampled": 1000000, "num_steps_trained": 500000, "num_agent_steps_trained": 1000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 48, "training_iteration": 25, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_11-55-44", "timestamp": 1704426944, "time_this_iter_s": 173.03322672843933, "time_total_s": 4848.257029771805, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE29C9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 872.0971240997314, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 17.972244897959186, "ram_util_percent": 81.9469387755102}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -454.54545454545456, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -227.27272727272728}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2023149927731212, "mean_inference_ms": 0.9746085135907664, "mean_action_processing_ms": 0.05453615240021595, "mean_env_wait_ms": 7.4492021290401675, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 520000, "timesteps_this_iter": 0, "agent_timesteps_total": 1040000, "timers": {"sample_time_ms": 174212.084, "sample_throughput": 114.803, "load_time_ms": 0.339, "load_throughput": 58998532.411, "learn_time_ms": 972.706, "learn_throughput": 20561.196, "update_time_ms": 1.467}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 1e-10, "total_loss": 115.57015075683594, "policy_loss": -3.323162081745323e-05, "vf_loss": 115.60235290527343, "vf_explained_var": 0.00438157320022583, "kl": 8.089498060570576e-06, "entropy": 3.2177333354949953, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 520000, "num_agent_steps_sampled": 1040000, "num_steps_trained": 520000, "num_agent_steps_trained": 1040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 50, "training_iteration": 26, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_11-58-38", "timestamp": 1704427118, "time_this_iter_s": 173.99110436439514, "time_total_s": 5022.2481341362, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE01B1F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1046.0882284641266, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 18.13780487804878, "ram_util_percent": 81.91585365853656}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -446.15384615384613, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -223.07692307692307}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20293719080034645, "mean_inference_ms": 0.9733795476959279, "mean_action_processing_ms": 0.054435402656989804, "mean_env_wait_ms": 7.445275152792478, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 540000, "timesteps_this_iter": 0, "agent_timesteps_total": 1080000, "timers": {"sample_time_ms": 174254.918, "sample_throughput": 114.774, "load_time_ms": 0.291, "load_throughput": 68831621.146, "learn_time_ms": 971.285, "learn_throughput": 20591.276, "update_time_ms": 1.471}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 1e-10, "total_loss": 129.1532012939453, "policy_loss": -1.6614666313863324e-05, "vf_loss": 129.18539123535157, "vf_explained_var": 0.0028200149536132812, "kl": 5.915452396365595e-06, "entropy": 3.2175739765167237, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 540000, "num_agent_steps_sampled": 1080000, "num_steps_trained": 540000, "num_agent_steps_trained": 1080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 52, "training_iteration": 27, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-01-33", "timestamp": 1704427293, "time_this_iter_s": 174.46167635917664, "time_total_s": 5196.709810495377, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE502DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1220.5499048233032, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 18.276016260162603, "ram_util_percent": 81.52073170731707}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -453.3333333333333, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -226.66666666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2034440511152833, "mean_inference_ms": 0.9723497379583663, "mean_action_processing_ms": 0.05435771153676115, "mean_env_wait_ms": 7.441575069483842, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 560000, "timesteps_this_iter": 0, "agent_timesteps_total": 1120000, "timers": {"sample_time_ms": 174134.538, "sample_throughput": 114.854, "load_time_ms": 0.316, "load_throughput": 63238658.123, "learn_time_ms": 971.026, "learn_throughput": 20596.775, "update_time_ms": 1.471}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 1e-10, "total_loss": 72.8131820678711, "policy_loss": -1.2069368518119462e-05, "vf_loss": 72.84536743164062, "vf_explained_var": 0.004201161861419678, "kl": 4.555911841919169e-06, "entropy": 3.2175687313079835, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 560000, "num_agent_steps_sampled": 1120000, "num_steps_trained": 560000, "num_agent_steps_trained": 1120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 54, "training_iteration": 28, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-04-26", "timestamp": 1704427466, "time_this_iter_s": 173.2741575241089, "time_total_s": 5369.9839680194855, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE195CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1393.824062347412, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 18.01387755102041, "ram_util_percent": 81.33795918367348}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -447.05882352941177, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -223.52941176470588}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20383125167075167, "mean_inference_ms": 0.9714650995415485, "mean_action_processing_ms": 0.05429380775905225, "mean_env_wait_ms": 7.438305390685247, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 580000, "timesteps_this_iter": 0, "agent_timesteps_total": 1160000, "timers": {"sample_time_ms": 174054.358, "sample_throughput": 114.907, "load_time_ms": 0.281, "load_throughput": 71143490.388, "learn_time_ms": 970.931, "learn_throughput": 20598.783, "update_time_ms": 1.418}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 1e-10, "total_loss": 105.72361907958984, "policy_loss": -2.3815765782586595e-05, "vf_loss": 105.75581207275391, "vf_explained_var": 0.004183495044708252, "kl": 4.107841906986209e-06, "entropy": 3.2173781871795653, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 580000, "num_agent_steps_sampled": 1160000, "num_steps_trained": 580000, "num_agent_steps_trained": 1160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 56, "training_iteration": 29, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-07-19", "timestamp": 1704427639, "time_this_iter_s": 173.38740038871765, "time_total_s": 5543.371368408203, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE357670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1567.2114627361298, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 17.98617886178862, "ram_util_percent": 81.32479674796745}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -442.10526315789474, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -221.05263157894737}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20419009922983203, "mean_inference_ms": 0.97070656769893, "mean_action_processing_ms": 0.054246995918482845, "mean_env_wait_ms": 7.435217011386311, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 600000, "timesteps_this_iter": 0, "agent_timesteps_total": 1200000, "timers": {"sample_time_ms": 173967.464, "sample_throughput": 114.964, "load_time_ms": 0.305, "load_throughput": 65515526.398, "learn_time_ms": 970.756, "learn_throughput": 20602.496, "update_time_ms": 1.472}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 1e-10, "total_loss": 79.93008575439453, "policy_loss": -3.5010652200107016e-05, "vf_loss": 79.96229248046875, "vf_explained_var": 0.004876720905303955, "kl": 6.123856331896605e-06, "entropy": 3.21726770401001, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 600000, "num_agent_steps_sampled": 1200000, "num_steps_trained": 600000, "num_agent_steps_trained": 1200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 58, "training_iteration": 30, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-10-12", "timestamp": 1704427812, "time_this_iter_s": 173.1598675251007, "time_total_s": 5716.531235933304, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE502550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1740.3713302612305, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 18.029098360655738, "ram_util_percent": 81.3290983606557}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -447.6190476190476, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -223.8095238095238}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20453106634182983, "mean_inference_ms": 0.9700331321781235, "mean_action_processing_ms": 0.05421023258457181, "mean_env_wait_ms": 7.432597941845576, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 620000, "timesteps_this_iter": 0, "agent_timesteps_total": 1240000, "timers": {"sample_time_ms": 173959.161, "sample_throughput": 114.97, "load_time_ms": 0.305, "load_throughput": 65623155.754, "learn_time_ms": 970.636, "learn_throughput": 20605.051, "update_time_ms": 1.473}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 1e-10, "total_loss": 136.11100158691406, "policy_loss": -6.185615403517808e-05, "vf_loss": 136.1432342529297, "vf_explained_var": 0.006272792816162109, "kl": 7.589001737466107e-06, "entropy": 3.2167853832244875, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 620000, "num_agent_steps_sampled": 1240000, "num_steps_trained": 620000, "num_agent_steps_trained": 1240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 60, "training_iteration": 31, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-13-06", "timestamp": 1704427986, "time_this_iter_s": 173.71736574172974, "time_total_s": 5890.248601675034, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE29C9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1914.0886960029602, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 18.110569105691056, "ram_util_percent": 81.37195121951218}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -443.4782608695652, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -221.7391304347826}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20483027362310016, "mean_inference_ms": 0.9694411613747858, "mean_action_processing_ms": 0.05418016940003676, "mean_env_wait_ms": 7.430266501948862, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 640000, "timesteps_this_iter": 0, "agent_timesteps_total": 1280000, "timers": {"sample_time_ms": 173521.131, "sample_throughput": 115.26, "load_time_ms": 0.303, "load_throughput": 65911903.827, "learn_time_ms": 970.845, "learn_throughput": 20600.616, "update_time_ms": 1.473}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 1e-10, "total_loss": 91.93701171875, "policy_loss": -7.479299453612142e-05, "vf_loss": 91.96925811767578, "vf_explained_var": 0.003007042407989502, "kl": 1.6214524752625194e-05, "entropy": 3.2170575141906737, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 640000, "num_agent_steps_sampled": 1280000, "num_steps_trained": 640000, "num_agent_steps_trained": 1280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 62, "training_iteration": 32, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-16-00", "timestamp": 1704428160, "time_this_iter_s": 173.50851488113403, "time_total_s": 6063.757116556168, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE195CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2087.5972108840942, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 18.129795918367346, "ram_util_percent": 81.33102040816325}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -448.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -224.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20509648246018045, "mean_inference_ms": 0.9689048671967332, "mean_action_processing_ms": 0.05415453872600607, "mean_env_wait_ms": 7.428509887678376, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 660000, "timesteps_this_iter": 0, "agent_timesteps_total": 1320000, "timers": {"sample_time_ms": 173690.834, "sample_throughput": 115.147, "load_time_ms": 0.251, "load_throughput": 79535488.765, "learn_time_ms": 972.778, "learn_throughput": 20559.685, "update_time_ms": 1.475}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 1e-10, "total_loss": 117.64168701171874, "policy_loss": -5.956408355034526e-05, "vf_loss": 117.67391357421874, "vf_explained_var": 0.003915023803710937, "kl": 8.94261425798959e-06, "entropy": 3.2167469024658204, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 660000, "num_agent_steps_sampled": 1320000, "num_steps_trained": 660000, "num_agent_steps_trained": 1320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 64, "training_iteration": 33, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-18-54", "timestamp": 1704428334, "time_this_iter_s": 174.5517294406891, "time_total_s": 6238.308845996857, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE357EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2262.1489403247833, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 18.029149797570852, "ram_util_percent": 81.31700404858296}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -445.18518518518516, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -222.59259259259258}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2053402617904741, "mean_inference_ms": 0.9684205538319097, "mean_action_processing_ms": 0.054139032069065215, "mean_env_wait_ms": 7.426931757503166, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 680000, "timesteps_this_iter": 0, "agent_timesteps_total": 1360000, "timers": {"sample_time_ms": 173702.111, "sample_throughput": 115.14, "load_time_ms": 0.251, "load_throughput": 79535488.765, "learn_time_ms": 971.885, "learn_throughput": 20578.571, "update_time_ms": 1.476}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 1e-10, "total_loss": 125.83774108886719, "policy_loss": -0.00010618707710179365, "vf_loss": 125.87000732421875, "vf_explained_var": 0.006595683097839355, "kl": 1.6853374321357252e-05, "entropy": 3.2157845497131348, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 680000, "num_agent_steps_sampled": 1360000, "num_steps_trained": 680000, "num_agent_steps_trained": 1360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 66, "training_iteration": 34, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-21-48", "timestamp": 1704428508, "time_this_iter_s": 173.67923831939697, "time_total_s": 6411.988084316254, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE29C9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2435.8281786441803, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 18.074390243902435, "ram_util_percent": 81.35528455284552}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -448.9655172413793, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -224.48275862068965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20557984888110903, "mean_inference_ms": 0.9679719097884886, "mean_action_processing_ms": 0.05412568140184461, "mean_env_wait_ms": 7.425269092532999, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 700000, "timesteps_this_iter": 0, "agent_timesteps_total": 1400000, "timers": {"sample_time_ms": 173662.266, "sample_throughput": 115.166, "load_time_ms": 0.254, "load_throughput": 78766272.3, "learn_time_ms": 971.386, "learn_throughput": 20589.131, "update_time_ms": 1.426}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 1e-10, "total_loss": 136.78385314941406, "policy_loss": -1.8638305364726547e-05, "vf_loss": 136.8160400390625, "vf_explained_var": 0.007952475547790527, "kl": 1.369563609927571e-05, "entropy": 3.2162243366241454, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 700000, "num_agent_steps_sampled": 1400000, "num_steps_trained": 700000, "num_agent_steps_trained": 1400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 68, "training_iteration": 35, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-24-41", "timestamp": 1704428681, "time_this_iter_s": 172.6365406513214, "time_total_s": 6584.624624967575, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFC86E160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2608.4647192955017, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 18.001639344262294, "ram_util_percent": 81.41352459016392}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -458.7096774193548, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -229.3548387096774}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20578385640472077, "mean_inference_ms": 0.9675647368810437, "mean_action_processing_ms": 0.05410850777775064, "mean_env_wait_ms": 7.4236601982423975, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 720000, "timesteps_this_iter": 0, "agent_timesteps_total": 1440000, "timers": {"sample_time_ms": 173560.231, "sample_throughput": 115.234, "load_time_ms": 0.254, "load_throughput": 78766272.3, "learn_time_ms": 967.959, "learn_throughput": 20662.03, "update_time_ms": 1.429}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 1e-10, "total_loss": 123.63492889404297, "policy_loss": -4.6272601948338377e-05, "vf_loss": 123.66713409423828, "vf_explained_var": 0.006966197490692138, "kl": 7.5869437768716356e-06, "entropy": 3.216198539733887, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 720000, "num_agent_steps_sampled": 1440000, "num_steps_trained": 720000, "num_agent_steps_trained": 1440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 70, "training_iteration": 36, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-27-34", "timestamp": 1704428854, "time_this_iter_s": 172.9463860988617, "time_total_s": 6757.571011066437, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE4F0310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2781.4111053943634, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 18.098367346938776, "ram_util_percent": 81.39795918367346}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -461.2121212121212, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -230.6060606060606}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20598503953760763, "mean_inference_ms": 0.9672093995577654, "mean_action_processing_ms": 0.054094148461668316, "mean_env_wait_ms": 7.422031561770879, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 740000, "timesteps_this_iter": 0, "agent_timesteps_total": 1480000, "timers": {"sample_time_ms": 173387.392, "sample_throughput": 115.349, "load_time_ms": 0.303, "load_throughput": 65901547.647, "learn_time_ms": 971.23, "learn_throughput": 20592.441, "update_time_ms": 1.429}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 1e-10, "total_loss": 124.417724609375, "policy_loss": -6.01318076054902e-05, "vf_loss": 124.44995574951172, "vf_explained_var": 0.0042351484298706055, "kl": 2.168830539805988e-05, "entropy": 3.216164779663086, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 740000, "num_agent_steps_sampled": 1480000, "num_steps_trained": 740000, "num_agent_steps_trained": 1480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 72, "training_iteration": 37, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-30-26", "timestamp": 1704429026, "time_this_iter_s": 172.79711484909058, "time_total_s": 6930.368125915527, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE195CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2954.208220243454, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 18.271721311475407, "ram_util_percent": 81.72213114754099}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -469.14285714285717, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -234.57142857142858}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2061602647453887, "mean_inference_ms": 0.9668994776479916, "mean_action_processing_ms": 0.05408367858240501, "mean_env_wait_ms": 7.420798530773873, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 760000, "timesteps_this_iter": 0, "agent_timesteps_total": 1520000, "timers": {"sample_time_ms": 173573.539, "sample_throughput": 115.225, "load_time_ms": 0.254, "load_throughput": 78781066.867, "learn_time_ms": 972.666, "learn_throughput": 20562.049, "update_time_ms": 1.431}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 1e-10, "total_loss": 124.70213012695312, "policy_loss": -6.866171954307276e-05, "vf_loss": 124.73436279296875, "vf_explained_var": 0.002461659908294678, "kl": 7.833256184172632e-06, "entropy": 3.2167630195617676, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 760000, "num_agent_steps_sampled": 1520000, "num_steps_trained": 760000, "num_agent_steps_trained": 1520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 74, "training_iteration": 38, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-33-22", "timestamp": 1704429202, "time_this_iter_s": 175.11464047431946, "time_total_s": 7105.482766389847, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE3571F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3129.3228607177734, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 18.282258064516128, "ram_util_percent": 81.50282258064516}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -465.4054054054054, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -232.7027027027027}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20631750984742583, "mean_inference_ms": 0.9666077202686619, "mean_action_processing_ms": 0.05407295008590314, "mean_env_wait_ms": 7.4195790238261194, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 780000, "timesteps_this_iter": 0, "agent_timesteps_total": 1560000, "timers": {"sample_time_ms": 173525.037, "sample_throughput": 115.257, "load_time_ms": 0.302, "load_throughput": 66145781.422, "learn_time_ms": 974.305, "learn_throughput": 20527.451, "update_time_ms": 1.478}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 1e-10, "total_loss": 99.39892120361328, "policy_loss": -3.0231466714170097e-05, "vf_loss": 99.43110656738281, "vf_explained_var": 0.0025923490524291993, "kl": 1.264368691275275e-05, "entropy": 3.2153637409210205, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 780000, "num_agent_steps_sampled": 1560000, "num_steps_trained": 780000, "num_agent_steps_trained": 1560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 76, "training_iteration": 39, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-36-15", "timestamp": 1704429375, "time_this_iter_s": 172.90850138664246, "time_total_s": 7278.391267776489, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE01B1F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3302.231362104416, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 18.004508196721314, "ram_util_percent": 81.64385245901639}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -467.1794871794872, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -233.5897435897436}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20645921140276308, "mean_inference_ms": 0.9663305295834818, "mean_action_processing_ms": 0.0540649052171878, "mean_env_wait_ms": 7.418332225996232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 800000, "timesteps_this_iter": 0, "agent_timesteps_total": 1600000, "timers": {"sample_time_ms": 173462.504, "sample_throughput": 115.299, "load_time_ms": 0.301, "load_throughput": 66360319.595, "learn_time_ms": 973.856, "learn_throughput": 20536.91, "update_time_ms": 1.434}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 1e-10, "total_loss": 124.52605438232422, "policy_loss": -5.681707358105026e-05, "vf_loss": 124.55827026367187, "vf_explained_var": 0.010870718955993652, "kl": 8.542947620160391e-06, "entropy": 3.2161641120910645, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 800000, "num_agent_steps_sampled": 1600000, "num_steps_trained": 800000, "num_agent_steps_trained": 1600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 78, "training_iteration": 40, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-39-07", "timestamp": 1704429547, "time_this_iter_s": 172.51360034942627, "time_total_s": 7450.9048681259155, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE29C9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3474.744962453842, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 18.034016393442624, "ram_util_percent": 81.52950819672131}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -473.6585365853659, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -236.82926829268294}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20658712811084323, "mean_inference_ms": 0.9660757353998706, "mean_action_processing_ms": 0.05405474728036096, "mean_env_wait_ms": 7.417072167204906, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 820000, "timesteps_this_iter": 0, "agent_timesteps_total": 1640000, "timers": {"sample_time_ms": 173339.509, "sample_throughput": 115.381, "load_time_ms": 0.299, "load_throughput": 66836172.417, "learn_time_ms": 976.835, "learn_throughput": 20474.287, "update_time_ms": 1.435}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 1e-10, "total_loss": 91.51359710693359, "policy_loss": -4.489332235451116e-05, "vf_loss": 91.5457992553711, "vf_explained_var": 0.010050547122955323, "kl": 8.63412981964018e-06, "entropy": 3.215574789047241, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 820000, "num_agent_steps_sampled": 1640000, "num_steps_trained": 820000, "num_agent_steps_trained": 1640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 80, "training_iteration": 41, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-42-00", "timestamp": 1704429720, "time_this_iter_s": 172.51227712631226, "time_total_s": 7623.417145252228, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE357310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3647.2572395801544, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 18.12704918032787, "ram_util_percent": 81.5155737704918}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.8837209302326, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -237.4418604651163}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2067085682204029, "mean_inference_ms": 0.9658404295652502, "mean_action_processing_ms": 0.05404509602429973, "mean_env_wait_ms": 7.41591766214786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 840000, "timesteps_this_iter": 0, "agent_timesteps_total": 1680000, "timers": {"sample_time_ms": 173350.425, "sample_throughput": 115.373, "load_time_ms": 0.251, "load_throughput": 79686596.371, "learn_time_ms": 976.973, "learn_throughput": 20471.391, "update_time_ms": 1.385}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 1e-10, "total_loss": 111.73834381103515, "policy_loss": -3.1429910530000885e-05, "vf_loss": 111.77052764892578, "vf_explained_var": 0.007873296737670898, "kl": 8.041639015582414e-06, "entropy": 3.2153873443603516, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 840000, "num_agent_steps_sampled": 1680000, "num_steps_trained": 840000, "num_agent_steps_trained": 1680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 82, "training_iteration": 42, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-44-53", "timestamp": 1704429893, "time_this_iter_s": 173.58645129203796, "time_total_s": 7797.003596544266, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE501280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3820.8436908721924, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 18.05061224489796, "ram_util_percent": 81.53224489795917}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -476.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -238.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2068148135675583, "mean_inference_ms": 0.9656179488767266, "mean_action_processing_ms": 0.05403836350364917, "mean_env_wait_ms": 7.41470204456392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 860000, "timesteps_this_iter": 0, "agent_timesteps_total": 1720000, "timers": {"sample_time_ms": 173083.602, "sample_throughput": 115.551, "load_time_ms": 0.251, "load_throughput": 79686596.371, "learn_time_ms": 977.271, "learn_throughput": 20465.157, "update_time_ms": 1.435}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 1e-10, "total_loss": 96.1035873413086, "policy_loss": -5.0205468006225826e-05, "vf_loss": 96.13578033447266, "vf_explained_var": 0.007787775993347168, "kl": 2.2792941967311743e-05, "entropy": 3.2146250724792482, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 860000, "num_agent_steps_sampled": 1720000, "num_steps_trained": 860000, "num_agent_steps_trained": 1720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 84, "training_iteration": 43, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-47-45", "timestamp": 1704430065, "time_this_iter_s": 171.88732028007507, "time_total_s": 7968.890916824341, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE195CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3992.7310111522675, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 18.207407407407405, "ram_util_percent": 81.40905349794237}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -477.02127659574467, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -238.51063829787233}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20693682627539786, "mean_inference_ms": 0.9654094412450973, "mean_action_processing_ms": 0.05403215150217033, "mean_env_wait_ms": 7.413617400964081, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 880000, "timesteps_this_iter": 0, "agent_timesteps_total": 1760000, "timers": {"sample_time_ms": 173129.505, "sample_throughput": 115.52, "load_time_ms": 0.251, "load_throughput": 79686596.371, "learn_time_ms": 981.983, "learn_throughput": 20366.956, "update_time_ms": 1.435}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 1e-10, "total_loss": 169.55736389160157, "policy_loss": -1.6301622515335624e-05, "vf_loss": 169.5895263671875, "vf_explained_var": 0.007804858684539795, "kl": 1.6510807175507124e-05, "entropy": 3.2149684906005858, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 880000, "num_agent_steps_sampled": 1760000, "num_steps_trained": 880000, "num_agent_steps_trained": 1760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 86, "training_iteration": 44, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-50-39", "timestamp": 1704430239, "time_this_iter_s": 174.18026041984558, "time_total_s": 8143.071177244186, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE502AF0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4166.911271572113, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 18.001619433198382, "ram_util_percent": 81.51255060728745}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -477.9591836734694, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -238.9795918367347}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20703803559567294, "mean_inference_ms": 0.9652183371909621, "mean_action_processing_ms": 0.054028556873136346, "mean_env_wait_ms": 7.412595997404771, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 900000, "timesteps_this_iter": 0, "agent_timesteps_total": 1800000, "timers": {"sample_time_ms": 173188.816, "sample_throughput": 115.481, "load_time_ms": 0.249, "load_throughput": 80481703.924, "learn_time_ms": 989.576, "learn_throughput": 20210.667, "update_time_ms": 1.482}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 1e-10, "total_loss": 93.84000396728516, "policy_loss": -4.521964083323837e-05, "vf_loss": 93.87219848632813, "vf_explained_var": 0.017241466045379638, "kl": 1.4134252205622034e-05, "entropy": 3.2149266242980956, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 900000, "num_agent_steps_sampled": 1800000, "num_steps_trained": 900000, "num_agent_steps_trained": 1800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 88, "training_iteration": 45, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-53-33", "timestamp": 1704430413, "time_this_iter_s": 173.25777864456177, "time_total_s": 8316.328955888748, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE5014C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4340.169050216675, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 18.08326530612245, "ram_util_percent": 81.59265306122448}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -482.7450980392157, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -241.37254901960785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20713463109238775, "mean_inference_ms": 0.9650349725052048, "mean_action_processing_ms": 0.05402722716960882, "mean_env_wait_ms": 7.411658020625952, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 920000, "timesteps_this_iter": 0, "agent_timesteps_total": 1840000, "timers": {"sample_time_ms": 173261.501, "sample_throughput": 115.432, "load_time_ms": 0.301, "load_throughput": 66523457.573, "learn_time_ms": 995.479, "learn_throughput": 20090.834, "update_time_ms": 1.529}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 1e-10, "total_loss": 78.70746459960938, "policy_loss": -9.394722989650717e-05, "vf_loss": 78.73970184326171, "vf_explained_var": 0.015698325634002686, "kl": 1.528337627969556e-05, "entropy": 3.214333343505859, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 920000, "num_agent_steps_sampled": 1840000, "num_steps_trained": 920000, "num_agent_steps_trained": 1840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 90, "training_iteration": 46, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-56-26", "timestamp": 1704430586, "time_this_iter_s": 173.65436363220215, "time_total_s": 8489.98331952095, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE501550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4513.823413848877, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 18.03265306122449, "ram_util_percent": 81.5730612244898}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -479.62264150943395, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -239.81132075471697}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20722660042879565, "mean_inference_ms": 0.9648615287728679, "mean_action_processing_ms": 0.05402492061623104, "mean_env_wait_ms": 7.410721743164217, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 940000, "timesteps_this_iter": 0, "agent_timesteps_total": 1880000, "timers": {"sample_time_ms": 173247.414, "sample_throughput": 115.442, "load_time_ms": 0.303, "load_throughput": 65927444.2, "learn_time_ms": 998.504, "learn_throughput": 20029.959, "update_time_ms": 1.575}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 1e-10, "total_loss": 188.66949462890625, "policy_loss": -7.224786786483862e-05, "vf_loss": 188.7017059326172, "vf_explained_var": 0.009603989124298096, "kl": 1.81314868646254e-05, "entropy": 3.2145205974578857, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 940000, "num_agent_steps_sampled": 1880000, "num_steps_trained": 940000, "num_agent_steps_trained": 1880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 92, "training_iteration": 47, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_12-59-19", "timestamp": 1704430759, "time_this_iter_s": 172.63013529777527, "time_total_s": 8662.613454818726, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE5015E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4686.453549146652, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 18.158196721311477, "ram_util_percent": 81.54139344262296}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -476.72727272727275, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -238.36363636363637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20731070422426034, "mean_inference_ms": 0.9647012199226573, "mean_action_processing_ms": 0.05402313591151368, "mean_env_wait_ms": 7.409809558685194, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 960000, "timesteps_this_iter": 0, "agent_timesteps_total": 1920000, "timers": {"sample_time_ms": 173028.311, "sample_throughput": 115.588, "load_time_ms": 0.303, "load_throughput": 65927444.2, "learn_time_ms": 997.465, "learn_throughput": 20050.823, "update_time_ms": 1.575}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 1e-10, "total_loss": 82.06375427246094, "policy_loss": -8.272139402571987e-05, "vf_loss": 82.0959686279297, "vf_explained_var": 0.01686958074569702, "kl": 1.3540828847347085e-05, "entropy": 3.2131581783294676, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 960000, "num_agent_steps_sampled": 1920000, "num_steps_trained": 960000, "num_agent_steps_trained": 1920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 94, "training_iteration": 48, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_13-02-12", "timestamp": 1704430932, "time_this_iter_s": 172.88253021240234, "time_total_s": 8835.495985031128, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFC86E160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4859.336079359055, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 18.249387755102042, "ram_util_percent": 81.47551020408162}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.03508771929825, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -237.01754385964912}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2073914408547677, "mean_inference_ms": 0.9645523054370154, "mean_action_processing_ms": 0.0540190273373854, "mean_env_wait_ms": 7.408924386894502, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 980000, "timesteps_this_iter": 0, "agent_timesteps_total": 1960000, "timers": {"sample_time_ms": 173030.455, "sample_throughput": 115.587, "load_time_ms": 0.304, "load_throughput": 65684817.164, "learn_time_ms": 995.978, "learn_throughput": 20080.768, "update_time_ms": 1.577}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 1e-10, "total_loss": 163.7006408691406, "policy_loss": -0.00010248005008557381, "vf_loss": 163.73287963867188, "vf_explained_var": 0.012714016437530517, "kl": 1.773499878439111e-05, "entropy": 3.2128181934356688, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 980000, "num_agent_steps_sampled": 1960000, "num_steps_trained": 980000, "num_agent_steps_trained": 1960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 96, "training_iteration": 49, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_13-05-05", "timestamp": 1704431105, "time_this_iter_s": 172.92317247390747, "time_total_s": 9008.419157505035, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE307280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5032.259251832962, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 17.979098360655737, "ram_util_percent": 81.5327868852459}}
{"episode_reward_max": -220.0, "episode_reward_min": -600.0, "episode_reward_mean": -471.52542372881356, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -110.0}, "policy_reward_mean": {"shared_policy": -235.76271186440678}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -220.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -110.0, -110.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2074679686079211, "mean_inference_ms": 0.9644142846347946, "mean_action_processing_ms": 0.05401744577576725, "mean_env_wait_ms": 7.408073074565149, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1000000, "timesteps_this_iter": 0, "agent_timesteps_total": 2000000, "timers": {"sample_time_ms": 173089.598, "sample_throughput": 115.547, "load_time_ms": 0.253, "load_throughput": 78988775.895, "learn_time_ms": 997.518, "learn_throughput": 20049.766, "update_time_ms": 1.574}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 1e-10, "total_loss": 110.46492462158203, "policy_loss": -4.411182055008567e-05, "vf_loss": 110.49710998535156, "vf_explained_var": 0.01146928071975708, "kl": 2.4342058726745108e-05, "entropy": 3.2141862392425535, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1000000, "num_agent_steps_sampled": 2000000, "num_steps_trained": 1000000, "num_agent_steps_trained": 2000000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -500.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -250.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20718398113582387, "mean_inference_ms": 1.0050896330686767, "mean_action_processing_ms": 0.05607627103279381, "mean_env_wait_ms": 7.308873465038994, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": true, "episodes_total": 98, "training_iteration": 50, "trial_id": "41553_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_13-22-16", "timestamp": 1704432136, "time_this_iter_s": 1031.395749092102, "time_total_s": 10039.814906597137, "pid": 13592, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/checkpoint_000020/checkpoint-20", "params_path": "D:/projs/MARLlib/experiments/mate/exp_results/mappo_mlp_MATE-4v2-9-v0/MAPPOTrainer_mate_MATE-4v2-9-v0_45c19_00000_0_2024-01-05_09-32-22/params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000014CFE4F4CA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6063.655000925064, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 18.05976696367375, "ram_util_percent": 81.77758738862235}}

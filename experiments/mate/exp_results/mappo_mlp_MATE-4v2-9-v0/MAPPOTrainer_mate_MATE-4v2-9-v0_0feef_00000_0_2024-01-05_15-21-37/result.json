{"episode_reward_max": -400.0, "episode_reward_min": -400.0, "episode_reward_mean": -400.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -200.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -200.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0], "episode_lengths": [10001], "policy_shared_policy_reward": [-200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2009551660173339, "mean_inference_ms": 1.0684875421336661, "mean_action_processing_ms": 0.05847482369915318, "mean_env_wait_ms": 7.771173135488429, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1020000, "timesteps_this_iter": 0, "agent_timesteps_total": 2040000, "timers": {"sample_time_ms": 182484.841, "sample_throughput": 109.598, "load_time_ms": 0.992, "load_throughput": 20164923.077, "learn_time_ms": 1488.007, "learn_throughput": 13440.799, "update_time_ms": 2.475}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 1e-10, "total_loss": 251.33592224121094, "policy_loss": -0.00012169038896332473, "vf_loss": 251.36814880371094, "vf_explained_var": 0.011518371105194092, "kl": 6.173485284790558e-05, "entropy": 3.212654399871826, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1020000, "num_agent_steps_sampled": 2040000, "num_steps_trained": 1020000, "num_agent_steps_trained": 2040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 99, "training_iteration": 51, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-24-47", "timestamp": 1704439487, "time_this_iter_s": 183.9173243045807, "time_total_s": 10223.732230901718, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF226F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 183.9173243045807, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 22.302681992337163, "ram_util_percent": 78.54482758620688}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -466.6666666666667, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -233.33333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22814245310730227, "mean_inference_ms": 1.1134686465271992, "mean_action_processing_ms": 0.06070912051457569, "mean_env_wait_ms": 7.909546697551764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1040000, "timesteps_this_iter": 0, "agent_timesteps_total": 2080000, "timers": {"sample_time_ms": 189580.342, "sample_throughput": 105.496, "load_time_ms": 0.496, "load_throughput": 40329846.154, "learn_time_ms": 1246.947, "learn_throughput": 16039.178, "update_time_ms": 3.221}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 1e-10, "total_loss": 95.79944305419922, "policy_loss": -4.4396649262479215e-05, "vf_loss": 95.8316162109375, "vf_explained_var": 0.018495547771453857, "kl": 1.672784174389097e-05, "entropy": 3.213383340835571, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1040000, "num_agent_steps_sampled": 2080000, "num_steps_trained": 1040000, "num_agent_steps_trained": 2080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 101, "training_iteration": 52, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-28-03", "timestamp": 1704439683, "time_this_iter_s": 196.1626214981079, "time_total_s": 10419.894852399826, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF253550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 380.0799458026886, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 31.504332129963895, "ram_util_percent": 85.86101083032491}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -440.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -220.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23767530674835888, "mean_inference_ms": 1.1398983104375442, "mean_action_processing_ms": 0.06180650153412502, "mean_env_wait_ms": 8.017508788979216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1060000, "timesteps_this_iter": 0, "agent_timesteps_total": 2120000, "timers": {"sample_time_ms": 194791.538, "sample_throughput": 102.674, "load_time_ms": 0.331, "load_throughput": 60494769.231, "learn_time_ms": 1216.368, "learn_throughput": 16442.396, "update_time_ms": 2.634}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 1e-10, "total_loss": 124.59313049316407, "policy_loss": -3.88496736765942e-05, "vf_loss": 124.62531127929688, "vf_explained_var": 0.017391455173492432, "kl": 1.2392409665240578e-05, "entropy": 3.2142629623413086, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1060000, "num_agent_steps_sampled": 2120000, "num_steps_trained": 1060000, "num_agent_steps_trained": 2120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 103, "training_iteration": 53, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-31-29", "timestamp": 1704439889, "time_this_iter_s": 205.33189725875854, "time_total_s": 10625.226749658585, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF2464C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 585.4118430614471, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 31.742413793103445, "ram_util_percent": 90.73137931034482}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -457.14285714285717, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -228.57142857142858}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24362064838297726, "mean_inference_ms": 1.1549540668834748, "mean_action_processing_ms": 0.06239541721475197, "mean_env_wait_ms": 8.095009788565395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1080000, "timesteps_this_iter": 0, "agent_timesteps_total": 2160000, "timers": {"sample_time_ms": 197455.899, "sample_throughput": 101.288, "load_time_ms": 0.248, "load_throughput": 80659692.308, "learn_time_ms": 1203.675, "learn_throughput": 16615.777, "update_time_ms": 2.348}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 1e-10, "total_loss": 115.36582489013672, "policy_loss": -4.8417281947332744e-05, "vf_loss": 115.39801177978515, "vf_explained_var": 0.016087377071380617, "kl": 1.6610553525453485e-05, "entropy": 3.213990831375122, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1080000, "num_agent_steps_sampled": 2160000, "num_steps_trained": 1080000, "num_agent_steps_trained": 2160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 105, "training_iteration": 54, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-34-54", "timestamp": 1704440094, "time_this_iter_s": 205.42867040634155, "time_total_s": 10830.655420064926, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF2468B0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 790.8405134677887, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 28.73551724137931, "ram_util_percent": 91.42275862068965}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -466.6666666666667, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -233.33333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2533387336500924, "mean_inference_ms": 1.190349201945041, "mean_action_processing_ms": 0.06385844362199532, "mean_env_wait_ms": 8.311716558425369, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1100000, "timesteps_this_iter": 0, "agent_timesteps_total": 2200000, "timers": {"sample_time_ms": 216276.311, "sample_throughput": 92.474, "load_time_ms": 0.198, "load_throughput": 100824615.385, "learn_time_ms": 1188.129, "learn_throughput": 16833.183, "update_time_ms": 2.369}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 1e-10, "total_loss": 85.246875, "policy_loss": -4.3425379689754354e-05, "vf_loss": 85.27906951904296, "vf_explained_var": 0.012212467193603516, "kl": 1.235069096972019e-05, "entropy": 3.214911699295044, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1100000, "num_agent_steps_sampled": 2200000, "num_steps_trained": 1100000, "num_agent_steps_trained": 2200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 107, "training_iteration": 55, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-39-46", "timestamp": 1704440386, "time_this_iter_s": 291.49733543395996, "time_total_s": 11122.152755498886, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF251EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1082.3378489017487, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 56.03082524271844, "ram_util_percent": 90.40922330097087}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -472.72727272727275, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -236.36363636363637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2636235210649346, "mean_inference_ms": 1.2337506960452655, "mean_action_processing_ms": 0.06565459298471576, "mean_env_wait_ms": 8.572932418722333, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1120000, "timesteps_this_iter": 0, "agent_timesteps_total": 2240000, "timers": {"sample_time_ms": 232767.924, "sample_throughput": 85.922, "load_time_ms": 0.248, "load_throughput": 80646768.146, "learn_time_ms": 1279.689, "learn_throughput": 15628.8, "update_time_ms": 2.14}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 1e-10, "total_loss": 147.91101684570313, "policy_loss": -6.183067338541015e-05, "vf_loss": 147.943212890625, "vf_explained_var": 0.02028374671936035, "kl": 2.398754527357383e-05, "entropy": 3.2136003971099854, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1120000, "num_agent_steps_sampled": 2240000, "num_steps_trained": 1120000, "num_agent_steps_trained": 2240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 109, "training_iteration": 56, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-45-02", "timestamp": 1704440702, "time_this_iter_s": 315.80884861946106, "time_total_s": 11437.961604118347, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF246DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1398.1466975212097, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 60.5476404494382, "ram_util_percent": 89.50044943820225}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -461.53846153846155, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -230.76923076923077}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.27357569223118267, "mean_inference_ms": 1.2723086947206137, "mean_action_processing_ms": 0.06724643658711134, "mean_env_wait_ms": 8.807661879844902, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1140000, "timesteps_this_iter": 0, "agent_timesteps_total": 2280000, "timers": {"sample_time_ms": 241425.978, "sample_throughput": 82.841, "load_time_ms": 0.283, "load_throughput": 70568748.948, "learn_time_ms": 1266.083, "learn_throughput": 15796.757, "update_time_ms": 1.976}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 1e-10, "total_loss": 126.82533111572266, "policy_loss": -5.6492032395993874e-05, "vf_loss": 126.85751953125, "vf_explained_var": 0.018998754024505616, "kl": 2.2107809982485628e-05, "entropy": 3.213562774658203, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1140000, "num_agent_steps_sampled": 2280000, "num_steps_trained": 1140000, "num_agent_steps_trained": 2280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 111, "training_iteration": 57, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-49-54", "timestamp": 1704440994, "time_this_iter_s": 292.77872228622437, "time_total_s": 11730.740326404572, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3EE310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1690.925419807434, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 56.996852300242125, "ram_util_percent": 86.0956416464891}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -466.6666666666667, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -233.33333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2800635374561062, "mean_inference_ms": 1.296980993912346, "mean_action_processing_ms": 0.06831088212033729, "mean_env_wait_ms": 8.952565340028615, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1160000, "timesteps_this_iter": 0, "agent_timesteps_total": 2320000, "timers": {"sample_time_ms": 236661.286, "sample_throughput": 84.509, "load_time_ms": 0.248, "load_throughput": 80649998.798, "learn_time_ms": 1245.652, "learn_throughput": 16055.854, "update_time_ms": 2.036}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 1e-10, "total_loss": 82.08695526123047, "policy_loss": -1.2418537007885532e-05, "vf_loss": 82.11911163330078, "vf_explained_var": 0.01986898183822632, "kl": 1.3196390605374475e-05, "entropy": 3.214418077468872, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1160000, "num_agent_steps_sampled": 2320000, "num_steps_trained": 1160000, "num_agent_steps_trained": 2320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 113, "training_iteration": 58, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-53-18", "timestamp": 1704441198, "time_this_iter_s": 203.19556665420532, "time_total_s": 11933.935893058777, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF087E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1894.1209864616394, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 29.381533101045296, "ram_util_percent": 83.51498257839722}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -458.8235294117647, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -229.41176470588235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2844966142131886, "mean_inference_ms": 1.313372732316467, "mean_action_processing_ms": 0.06900447396965675, "mean_env_wait_ms": 9.04496298406959, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1180000, "timesteps_this_iter": 0, "agent_timesteps_total": 2360000, "timers": {"sample_time_ms": 232988.378, "sample_throughput": 85.841, "load_time_ms": 0.22, "load_throughput": 90731248.648, "learn_time_ms": 1223.368, "learn_throughput": 16348.312, "update_time_ms": 1.972}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 1e-10, "total_loss": 81.31721954345703, "policy_loss": -4.6013859820970283e-05, "vf_loss": 81.34940643310547, "vf_explained_var": 0.026862144470214844, "kl": 3.085601739751809e-05, "entropy": 3.2134053230285646, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1180000, "num_agent_steps_sampled": 2360000, "num_steps_trained": 1180000, "num_agent_steps_trained": 2360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 115, "training_iteration": 59, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_15-56-41", "timestamp": 1704441401, "time_this_iter_s": 203.5060212612152, "time_total_s": 12137.441914319992, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF0D2F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2097.6270077228546, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 30.527430555555554, "ram_util_percent": 82.2704861111111}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -452.63157894736844, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -226.31578947368422}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2875565148250271, "mean_inference_ms": 1.3245010142322877, "mean_action_processing_ms": 0.06950372252994623, "mean_env_wait_ms": 9.104149015708362, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1200000, "timesteps_this_iter": 0, "agent_timesteps_total": 2400000, "timers": {"sample_time_ms": 229921.812, "sample_throughput": 86.986, "load_time_ms": 0.198, "load_throughput": 100812498.498, "learn_time_ms": 1216.304, "learn_throughput": 16443.26, "update_time_ms": 1.921}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 1e-10, "total_loss": 100.32386627197266, "policy_loss": -5.418438070865505e-05, "vf_loss": 100.3560562133789, "vf_explained_var": 0.01420828104019165, "kl": 3.2834915771475305e-05, "entropy": 3.2134085178375242, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1200000, "num_agent_steps_sampled": 2400000, "num_steps_trained": 1200000, "num_agent_steps_trained": 2400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 117, "training_iteration": 60, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-00-04", "timestamp": 1704441604, "time_this_iter_s": 202.40761923789978, "time_total_s": 12339.849533557892, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF1AB9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2300.0346269607544, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 29.894755244755242, "ram_util_percent": 81.66503496503496}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -457.14285714285717, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -228.57142857142858}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2898626209528048, "mean_inference_ms": 1.332457078734563, "mean_action_processing_ms": 0.06988681427651293, "mean_env_wait_ms": 9.143237072289816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1220000, "timesteps_this_iter": 0, "agent_timesteps_total": 2440000, "timers": {"sample_time_ms": 232336.222, "sample_throughput": 86.082, "load_time_ms": 0.099, "load_throughput": 201600769.046, "learn_time_ms": 1173.947, "learn_throughput": 17036.542, "update_time_ms": 1.82}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 1e-10, "total_loss": 113.02960510253907, "policy_loss": -4.1963938884492793e-05, "vf_loss": 113.06176452636718, "vf_explained_var": 0.02166544198989868, "kl": 2.1183974498484305e-05, "entropy": 3.211836576461792, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1220000, "num_agent_steps_sampled": 2440000, "num_steps_trained": 1220000, "num_agent_steps_trained": 2440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 119, "training_iteration": 61, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-03-30", "timestamp": 1704441810, "time_this_iter_s": 206.4991431236267, "time_total_s": 12546.348676681519, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF087E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2506.533770084381, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.90479452054795, "ram_util_percent": 81.20616438356164}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -452.17391304347825, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -226.08695652173913}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29154093339545434, "mean_inference_ms": 1.3380669590956247, "mean_action_processing_ms": 0.07015389191521536, "mean_env_wait_ms": 9.1679931650149, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1240000, "timesteps_this_iter": 0, "agent_timesteps_total": 2480000, "timers": {"sample_time_ms": 233018.431, "sample_throughput": 85.83, "load_time_ms": 0.149, "load_throughput": 134411280.244, "learn_time_ms": 1214.074, "learn_throughput": 16473.466, "update_time_ms": 1.722}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 1e-10, "total_loss": 77.20339965820312, "policy_loss": -5.624132244506086e-05, "vf_loss": 77.23559112548828, "vf_explained_var": 0.02187901735305786, "kl": 2.4764703645407947e-05, "entropy": 3.2132487297058105, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1240000, "num_agent_steps_sampled": 2480000, "num_steps_trained": 1240000, "num_agent_steps_trained": 2480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 121, "training_iteration": 62, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-06-54", "timestamp": 1704442014, "time_this_iter_s": 203.8158221244812, "time_total_s": 12750.164498806, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF0FCB80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2710.3495922088623, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 30.68680555555555, "ram_util_percent": 80.94513888888889}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -456.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -228.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2927906758196919, "mean_inference_ms": 1.3422426637673768, "mean_action_processing_ms": 0.07036204512463633, "mean_env_wait_ms": 9.184092503439434, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1260000, "timesteps_this_iter": 0, "agent_timesteps_total": 2520000, "timers": {"sample_time_ms": 233344.315, "sample_throughput": 85.71, "load_time_ms": 0.198, "load_throughput": 100788273.459, "learn_time_ms": 1233.415, "learn_throughput": 16215.146, "update_time_ms": 1.725}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 1e-10, "total_loss": 153.968798828125, "policy_loss": -9.69797604379874e-05, "vf_loss": 154.0010192871094, "vf_explained_var": 0.018731749057769774, "kl": 1.85562115064819e-05, "entropy": 3.2119298934936524, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1260000, "num_agent_steps_sampled": 2520000, "num_steps_trained": 1260000, "num_agent_steps_trained": 2520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 123, "training_iteration": 63, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-10-22", "timestamp": 1704442222, "time_this_iter_s": 208.3695216178894, "time_total_s": 12958.53402042389, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3DB040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2918.7191138267517, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 32.56033898305085, "ram_util_percent": 81.88101694915254}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -459.25925925925924, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -229.62962962962962}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2937006705688105, "mean_inference_ms": 1.3451755347575802, "mean_action_processing_ms": 0.0705178753192559, "mean_env_wait_ms": 9.192929989076122, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1280000, "timesteps_this_iter": 0, "agent_timesteps_total": 2560000, "timers": {"sample_time_ms": 233113.735, "sample_throughput": 85.795, "load_time_ms": 0.251, "load_throughput": 79830681.386, "learn_time_ms": 1222.453, "learn_throughput": 16360.545, "update_time_ms": 1.675}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 1e-10, "total_loss": 149.73510131835937, "policy_loss": 3.646096236309404e-05, "vf_loss": 149.7671691894531, "vf_explained_var": 0.023130953311920166, "kl": 2.4168660712309276e-05, "entropy": 3.21083984375, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1280000, "num_agent_steps_sampled": 2560000, "num_steps_trained": 1280000, "num_agent_steps_trained": 2560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 125, "training_iteration": 64, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-13-45", "timestamp": 1704442425, "time_this_iter_s": 202.8140640258789, "time_total_s": 13161.348084449768, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF226F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3121.5331778526306, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 30.38257839721254, "ram_util_percent": 81.80348432055749}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -462.0689655172414, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -231.0344827586207}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2943676544557835, "mean_inference_ms": 1.3472933241403864, "mean_action_processing_ms": 0.07063371760268287, "mean_env_wait_ms": 9.197036008187675, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1300000, "timesteps_this_iter": 0, "agent_timesteps_total": 2600000, "timers": {"sample_time_ms": 224468.976, "sample_throughput": 89.099, "load_time_ms": 0.251, "load_throughput": 79830681.386, "learn_time_ms": 1217.295, "learn_throughput": 16429.877, "update_time_ms": 1.576}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 1e-10, "total_loss": 110.96609802246094, "policy_loss": -7.250711270607723e-05, "vf_loss": 110.9982925415039, "vf_explained_var": 0.028309667110443117, "kl": 1.2953103853358128e-05, "entropy": 3.2116530895233155, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1300000, "num_agent_steps_sampled": 2600000, "num_steps_trained": 1300000, "num_agent_steps_trained": 2600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 127, "training_iteration": 65, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-17-10", "timestamp": 1704442630, "time_this_iter_s": 205.0952866077423, "time_total_s": 13366.44337105751, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3EE670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3326.628464460373, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 30.950344827586207, "ram_util_percent": 82.25724137931034}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -470.96774193548384, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -235.48387096774192}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29480145799071494, "mean_inference_ms": 1.3485640636473102, "mean_action_processing_ms": 0.07069986791764044, "mean_env_wait_ms": 9.197095486578128, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1320000, "timesteps_this_iter": 0, "agent_timesteps_total": 2640000, "timers": {"sample_time_ms": 212986.904, "sample_throughput": 93.902, "load_time_ms": 0.201, "load_throughput": 99544416.756, "learn_time_ms": 1150.585, "learn_throughput": 17382.459, "update_time_ms": 1.625}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 1e-10, "total_loss": 201.01321411132812, "policy_loss": -5.35231982148332e-05, "vf_loss": 201.0453674316406, "vf_explained_var": 0.019029998779296876, "kl": 1.3059351920219342e-05, "entropy": 3.210862970352173, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1320000, "num_agent_steps_sampled": 2640000, "num_steps_trained": 1320000, "num_agent_steps_trained": 2640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 129, "training_iteration": 66, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-20-31", "timestamp": 1704442831, "time_this_iter_s": 200.37218356132507, "time_total_s": 13566.815554618835, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3FF040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3527.000648021698, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 28.348056537102472, "ram_util_percent": 82.59257950530035}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -466.6666666666667, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -233.33333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29508097727469956, "mean_inference_ms": 1.3492715151486157, "mean_action_processing_ms": 0.07073821036869292, "mean_env_wait_ms": 9.194734790547512, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1340000, "timesteps_this_iter": 0, "agent_timesteps_total": 2680000, "timers": {"sample_time_ms": 204027.963, "sample_throughput": 98.026, "load_time_ms": 0.198, "load_throughput": 100885243.536, "learn_time_ms": 1148.353, "learn_throughput": 17416.244, "update_time_ms": 1.724}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 1e-10, "total_loss": 111.36446838378906, "policy_loss": -5.975442994508029e-05, "vf_loss": 111.396630859375, "vf_explained_var": 0.020818769931793213, "kl": 1.7064045091297332e-05, "entropy": 3.2104013442993162, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1340000, "num_agent_steps_sampled": 2680000, "num_steps_trained": 1340000, "num_agent_steps_trained": 2680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 131, "training_iteration": 67, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-23-55", "timestamp": 1704443035, "time_this_iter_s": 203.84979486465454, "time_total_s": 13770.66534948349, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3FF1F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3730.8504428863525, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 29.984375, "ram_util_percent": 83.67812500000001}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.2857142857143, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -237.14285714285714}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2952617499758917, "mean_inference_ms": 1.349588735183837, "mean_action_processing_ms": 0.07076084089024559, "mean_env_wait_ms": 9.1907383302949, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1360000, "timesteps_this_iter": 0, "agent_timesteps_total": 2720000, "timers": {"sample_time_ms": 204191.216, "sample_throughput": 97.947, "load_time_ms": 0.248, "load_throughput": 80690727.203, "learn_time_ms": 1154.402, "learn_throughput": 17324.994, "update_time_ms": 1.628}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 1e-10, "total_loss": 122.25457305908203, "policy_loss": -4.6158861724521215e-05, "vf_loss": 122.28673095703125, "vf_explained_var": 0.01835343837738037, "kl": 9.41337927140573e-06, "entropy": 3.2111294746398924, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1360000, "num_agent_steps_sampled": 2720000, "num_steps_trained": 1360000, "num_agent_steps_trained": 2720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 133, "training_iteration": 68, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-27-20", "timestamp": 1704443240, "time_this_iter_s": 204.9076268672943, "time_total_s": 13975.572976350784, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3FF4C0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3935.758069753647, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 28.814827586206896, "ram_util_percent": 82.86689655172414}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -470.27027027027026, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -235.13513513513513}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29538869012941704, "mean_inference_ms": 1.349703398648064, "mean_action_processing_ms": 0.07077301819977723, "mean_env_wait_ms": 9.18564218789887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1380000, "timesteps_this_iter": 0, "agent_timesteps_total": 2760000, "timers": {"sample_time_ms": 204468.75, "sample_throughput": 97.814, "load_time_ms": 0.297, "load_throughput": 67248741.382, "learn_time_ms": 1182.524, "learn_throughput": 16912.969, "update_time_ms": 1.678}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 1e-10, "total_loss": 131.47925720214843, "policy_loss": -3.142362669628085e-05, "vf_loss": 131.5113983154297, "vf_explained_var": 0.020463621616363524, "kl": 8.64567290914664e-06, "entropy": 3.21022310256958, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1380000, "num_agent_steps_sampled": 2760000, "num_steps_trained": 1380000, "num_agent_steps_trained": 2760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 135, "training_iteration": 69, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-30-46", "timestamp": 1704443446, "time_this_iter_s": 206.5153570175171, "time_total_s": 14182.088333368301, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3EE790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4142.273426771164, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 32.18082191780822, "ram_util_percent": 81.56986301369864}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -471.79487179487177, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -235.89743589743588}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29544419919184717, "mean_inference_ms": 1.3495099740028713, "mean_action_processing_ms": 0.07076723649722105, "mean_env_wait_ms": 9.179105792065434, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1400000, "timesteps_this_iter": 0, "agent_timesteps_total": 2800000, "timers": {"sample_time_ms": 204226.667, "sample_throughput": 97.93, "load_time_ms": 0.297, "load_throughput": 67248741.382, "learn_time_ms": 1166.851, "learn_throughput": 17140.146, "update_time_ms": 1.677}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 1e-10, "total_loss": 174.53508911132812, "policy_loss": -2.803914963500631e-05, "vf_loss": 174.56722412109374, "vf_explained_var": 0.023741555213928223, "kl": 2.0097750663516933e-05, "entropy": 3.210139608383179, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1400000, "num_agent_steps_sampled": 2800000, "num_steps_trained": 1400000, "num_agent_steps_trained": 2800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 137, "training_iteration": 70, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-34-06", "timestamp": 1704443646, "time_this_iter_s": 199.53765606880188, "time_total_s": 14381.625989437103, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3FF040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4341.811082839966, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 28.369858156028368, "ram_util_percent": 81.70709219858156}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -473.1707317073171, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -236.58536585365854}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29543665251439316, "mean_inference_ms": 1.349113394780032, "mean_action_processing_ms": 0.0707538158580491, "mean_env_wait_ms": 9.171557019296543, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1420000, "timesteps_this_iter": 0, "agent_timesteps_total": 2840000, "timers": {"sample_time_ms": 203580.744, "sample_throughput": 98.241, "load_time_ms": 0.347, "load_throughput": 57637817.782, "learn_time_ms": 1202.613, "learn_throughput": 16630.459, "update_time_ms": 1.698}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 1e-10, "total_loss": 137.96507873535157, "policy_loss": -3.714183778411595e-05, "vf_loss": 137.99720153808593, "vf_explained_var": 0.023881816864013673, "kl": 1.1405580659129555e-05, "entropy": 3.208257722854614, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1420000, "num_agent_steps_sampled": 2840000, "num_steps_trained": 1420000, "num_agent_steps_trained": 2840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 139, "training_iteration": 71, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-37-26", "timestamp": 1704443846, "time_this_iter_s": 200.57474732398987, "time_total_s": 14582.200736761093, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3FF9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4542.385830163956, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 28.34401408450704, "ram_util_percent": 81.76619718309858}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -469.7674418604651, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -234.88372093023256}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29542837485079143, "mean_inference_ms": 1.3487342510459621, "mean_action_processing_ms": 0.07073935465924949, "mean_env_wait_ms": 9.163916871560017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1440000, "timesteps_this_iter": 0, "agent_timesteps_total": 2880000, "timers": {"sample_time_ms": 204108.7, "sample_throughput": 97.987, "load_time_ms": 0.297, "load_throughput": 67248741.382, "learn_time_ms": 1165.713, "learn_throughput": 17156.88, "update_time_ms": 1.545}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 1e-10, "total_loss": 127.11615905761718, "policy_loss": -2.9529390466365158e-05, "vf_loss": 127.14828491210938, "vf_explained_var": 0.02679520845413208, "kl": 7.024393264565276e-06, "entropy": 3.209376096725464, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1440000, "num_agent_steps_sampled": 2880000, "num_steps_trained": 1440000, "num_agent_steps_trained": 2880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 141, "training_iteration": 72, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-40-55", "timestamp": 1704444055, "time_this_iter_s": 208.35715222358704, "time_total_s": 14790.55788898468, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF087E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4750.742982387543, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 31.42959183673469, "ram_util_percent": 81.68095238095238}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -471.1111111111111, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -235.55555555555554}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29540324591618844, "mean_inference_ms": 1.3483804309386362, "mean_action_processing_ms": 0.07072517183738447, "mean_env_wait_ms": 9.156193732114339, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1460000, "timesteps_this_iter": 0, "agent_timesteps_total": 2920000, "timers": {"sample_time_ms": 204025.355, "sample_throughput": 98.027, "load_time_ms": 0.297, "load_throughput": 67270312.751, "learn_time_ms": 1157.532, "learn_throughput": 17278.144, "update_time_ms": 1.542}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 1e-10, "total_loss": 73.05527801513672, "policy_loss": -3.611153657434585e-05, "vf_loss": 73.08741302490235, "vf_explained_var": 0.040610861778259275, "kl": 5.589009728290684e-06, "entropy": 3.2098541259765625, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1460000, "num_agent_steps_sampled": 2920000, "num_steps_trained": 1460000, "num_agent_steps_trained": 2920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 143, "training_iteration": 73, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-44-23", "timestamp": 1704444263, "time_this_iter_s": 207.84123015403748, "time_total_s": 14998.399119138718, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF188B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4958.58421254158, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 32.31292517006803, "ram_util_percent": 81.55918367346939}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -472.3404255319149, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -236.17021276595744}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2953713277868971, "mean_inference_ms": 1.3480484886432247, "mean_action_processing_ms": 0.07071181330627375, "mean_env_wait_ms": 9.148332353858498, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1480000, "timesteps_this_iter": 0, "agent_timesteps_total": 2960000, "timers": {"sample_time_ms": 204360.59, "sample_throughput": 97.866, "load_time_ms": 0.292, "load_throughput": 68428158.904, "learn_time_ms": 1154.209, "learn_throughput": 17327.891, "update_time_ms": 1.641}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 1e-10, "total_loss": 156.65996398925782, "policy_loss": -4.0877199248634534e-05, "vf_loss": 156.69210205078124, "vf_explained_var": 0.02691226005554199, "kl": 5.303226828745622e-06, "entropy": 3.209643077850342, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1480000, "num_agent_steps_sampled": 2960000, "num_steps_trained": 1480000, "num_agent_steps_trained": 2960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 145, "training_iteration": 74, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-47-49", "timestamp": 1704444469, "time_this_iter_s": 206.22138237953186, "time_total_s": 15204.62050151825, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF209790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5164.805594921112, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 31.926369863013704, "ram_util_percent": 81.26609589041097}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -473.46938775510205, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -236.73469387755102}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29531001362471254, "mean_inference_ms": 1.3476255731899696, "mean_action_processing_ms": 0.07069493761979237, "mean_env_wait_ms": 9.14029411828301, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1500000, "timesteps_this_iter": 0, "agent_timesteps_total": 3000000, "timers": {"sample_time_ms": 204159.792, "sample_throughput": 97.962, "load_time_ms": 0.34, "load_throughput": 58904627.484, "learn_time_ms": 1149.199, "learn_throughput": 17403.424, "update_time_ms": 1.591}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 1e-10, "total_loss": 107.73046264648437, "policy_loss": -1.976939212555706e-05, "vf_loss": 107.76258239746093, "vf_explained_var": 0.027283644676208495, "kl": 9.548621141108882e-06, "entropy": 3.20995979309082, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1500000, "num_agent_steps_sampled": 3000000, "num_steps_trained": 1500000, "num_agent_steps_trained": 3000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 147, "training_iteration": 75, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-51-12", "timestamp": 1704444672, "time_this_iter_s": 203.06824159622192, "time_total_s": 15407.688743114471, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBEF0A670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5367.873836517334, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 30.073867595818818, "ram_util_percent": 81.34494773519164}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -478.4313725490196, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -239.2156862745098}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29522836301073163, "mean_inference_ms": 1.3471397981920354, "mean_action_processing_ms": 0.07067604969885358, "mean_env_wait_ms": 9.132182693545767, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1520000, "timesteps_this_iter": 0, "agent_timesteps_total": 3040000, "timers": {"sample_time_ms": 204474.636, "sample_throughput": 97.812, "load_time_ms": 0.39, "load_throughput": 51240657.26, "learn_time_ms": 1148.605, "learn_throughput": 17412.433, "update_time_ms": 1.59}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 1e-10, "total_loss": 98.70709075927735, "policy_loss": -3.45955557286004e-05, "vf_loss": 98.73922271728516, "vf_explained_var": 0.03288899660110474, "kl": 1.070012114494645e-05, "entropy": 3.2098484516143797, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1520000, "num_agent_steps_sampled": 3040000, "num_steps_trained": 1520000, "num_agent_steps_trained": 3040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 149, "training_iteration": 76, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-54-36", "timestamp": 1704444876, "time_this_iter_s": 203.56548643112183, "time_total_s": 15611.254229545593, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3FF820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5571.439322948456, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 29.81354166666667, "ram_util_percent": 81.30034722222223}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -475.47169811320754, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -237.73584905660377}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.295118135968272, "mean_inference_ms": 1.3465587165579072, "mean_action_processing_ms": 0.07065190823909479, "mean_env_wait_ms": 9.123835156405171, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1540000, "timesteps_this_iter": 0, "agent_timesteps_total": 3080000, "timers": {"sample_time_ms": 204049.002, "sample_throughput": 98.016, "load_time_ms": 0.393, "load_throughput": 50892483.164, "learn_time_ms": 1133.182, "learn_throughput": 17649.421, "update_time_ms": 1.538}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 1e-10, "total_loss": 153.0387756347656, "policy_loss": -7.9228477101978e-05, "vf_loss": 153.07097473144532, "vf_explained_var": 0.02097907066345215, "kl": 6.439604423240653e-05, "entropy": 3.21102032661438, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1540000, "num_agent_steps_sampled": 3080000, "num_steps_trained": 1540000, "num_agent_steps_trained": 3080000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 151, "training_iteration": 77, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_16-57-55", "timestamp": 1704445075, "time_this_iter_s": 199.44252681732178, "time_total_s": 15810.696756362915, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF209790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5770.881849765778, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 28.566312056737583, "ram_util_percent": 81.21347517730497}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -472.72727272727275, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -236.36363636363637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2949525087877767, "mean_inference_ms": 1.3457440169093522, "mean_action_processing_ms": 0.0706182872250765, "mean_env_wait_ms": 9.114786510926242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1560000, "timesteps_this_iter": 0, "agent_timesteps_total": 3120000, "timers": {"sample_time_ms": 202351.764, "sample_throughput": 98.838, "load_time_ms": 0.343, "load_throughput": 58246132.482, "learn_time_ms": 1121.231, "learn_throughput": 17837.539, "update_time_ms": 1.535}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 1e-10, "total_loss": 80.49537658691406, "policy_loss": -4.335624836944163e-05, "vf_loss": 80.52750091552734, "vf_explained_var": 0.02978537082672119, "kl": 8.477331068390547e-06, "entropy": 3.207891511917114, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1560000, "num_agent_steps_sampled": 3120000, "num_steps_trained": 1560000, "num_agent_steps_trained": 3120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 153, "training_iteration": 78, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-01-03", "timestamp": 1704445263, "time_this_iter_s": 187.9753110408783, "time_total_s": 15998.672067403793, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF142430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 5958.857160806656, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 23.13233082706767, "ram_util_percent": 80.87781954887218}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -473.6842105263158, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -236.8421052631579}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2947477287286311, "mean_inference_ms": 1.3447369314271844, "mean_action_processing_ms": 0.07057512008468911, "mean_env_wait_ms": 9.105171288103794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1580000, "timesteps_this_iter": 0, "agent_timesteps_total": 3160000, "timers": {"sample_time_ms": 200476.276, "sample_throughput": 99.762, "load_time_ms": 0.346, "load_throughput": 57764825.782, "learn_time_ms": 1093.698, "learn_throughput": 18286.59, "update_time_ms": 1.488}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 1e-10, "total_loss": 238.8404510498047, "policy_loss": -6.309754015703107e-05, "vf_loss": 238.87258605957032, "vf_explained_var": 0.015434110164642334, "kl": 1.0991077130828587e-05, "entropy": 3.207470417022705, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1580000, "num_agent_steps_sampled": 3160000, "num_steps_trained": 1580000, "num_agent_steps_trained": 3160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 155, "training_iteration": 79, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-04-11", "timestamp": 1704445451, "time_this_iter_s": 187.60536456108093, "time_total_s": 16186.277431964874, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF246A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6146.462525367737, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 22.77169811320755, "ram_util_percent": 80.52867924528302}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.5762711864407, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -237.28813559322035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29454408419134265, "mean_inference_ms": 1.343743096154073, "mean_action_processing_ms": 0.07053248778746492, "mean_env_wait_ms": 9.095708496784388, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1600000, "timesteps_this_iter": 0, "agent_timesteps_total": 3200000, "timers": {"sample_time_ms": 200663.908, "sample_throughput": 99.669, "load_time_ms": 0.396, "load_throughput": 50521609.251, "learn_time_ms": 1107.288, "learn_throughput": 18062.154, "update_time_ms": 1.441}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 1e-10, "total_loss": 141.84146728515626, "policy_loss": -7.755136965421627e-05, "vf_loss": 141.87361755371094, "vf_explained_var": 0.025254952907562255, "kl": 2.1070123017352672e-05, "entropy": 3.2072454929351806, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1600000, "num_agent_steps_sampled": 3200000, "num_steps_trained": 1600000, "num_agent_steps_trained": 3200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 157, "training_iteration": 80, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-07-33", "timestamp": 1704445653, "time_this_iter_s": 201.83091807365417, "time_total_s": 16388.10835003853, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF251280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6348.293443441391, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 29.579298245614044, "ram_util_percent": 80.5821052631579}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -475.40983606557376, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -237.70491803278688}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29434886549103806, "mean_inference_ms": 1.3428170983088772, "mean_action_processing_ms": 0.07049318861239781, "mean_env_wait_ms": 9.086653262207678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1620000, "timesteps_this_iter": 0, "agent_timesteps_total": 3240000, "timers": {"sample_time_ms": 201401.508, "sample_throughput": 99.304, "load_time_ms": 0.346, "load_throughput": 57756871.385, "learn_time_ms": 1068.052, "learn_throughput": 18725.686, "update_time_ms": 1.374}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 1e-10, "total_loss": 76.30120239257812, "policy_loss": -3.6695318302193414e-05, "vf_loss": 76.33329162597656, "vf_explained_var": 0.04141614437103271, "kl": 1.1521877323861229e-05, "entropy": 3.205056381225586, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1620000, "num_agent_steps_sampled": 3240000, "num_steps_trained": 1620000, "num_agent_steps_trained": 3240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 159, "training_iteration": 81, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-11-00", "timestamp": 1704445860, "time_this_iter_s": 207.4087061882019, "time_total_s": 16595.51705622673, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF226F70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6555.702149629593, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 32.25442176870749, "ram_util_percent": 80.58605442176871}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -476.1904761904762, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -238.0952380952381}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29415860620229994, "mean_inference_ms": 1.3419329420905253, "mean_action_processing_ms": 0.07045714130550561, "mean_env_wait_ms": 9.077809095459148, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1640000, "timesteps_this_iter": 0, "agent_timesteps_total": 3280000, "timers": {"sample_time_ms": 200877.838, "sample_throughput": 99.563, "load_time_ms": 0.346, "load_throughput": 57756871.385, "learn_time_ms": 1085.506, "learn_throughput": 18424.595, "update_time_ms": 1.377}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 1e-10, "total_loss": 127.66329956054688, "policy_loss": -3.566532212730955e-05, "vf_loss": 127.6954132080078, "vf_explained_var": 0.015073585510253906, "kl": 1.2249582241263823e-05, "entropy": 3.2080954551696776, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1640000, "num_agent_steps_sampled": 3280000, "num_steps_trained": 1640000, "num_agent_steps_trained": 3280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 161, "training_iteration": 82, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-14-24", "timestamp": 1704446064, "time_this_iter_s": 203.69521737098694, "time_total_s": 16799.212273597717, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF104670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6759.39736700058, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 30.26909722222222, "ram_util_percent": 80.61631944444444}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -476.9230769230769, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -238.46153846153845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2939766596892245, "mean_inference_ms": 1.3410397366482603, "mean_action_processing_ms": 0.07041969218954434, "mean_env_wait_ms": 9.069121944629385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1660000, "timesteps_this_iter": 0, "agent_timesteps_total": 3320000, "timers": {"sample_time_ms": 200261.242, "sample_throughput": 99.87, "load_time_ms": 0.346, "load_throughput": 57760848.31, "learn_time_ms": 1091.355, "learn_throughput": 18325.844, "update_time_ms": 1.529}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 1e-10, "total_loss": 94.96694793701172, "policy_loss": -2.5946387893194255e-05, "vf_loss": 94.99904937744141, "vf_explained_var": 0.035204601287841794, "kl": 1.0850509619686477e-05, "entropy": 3.2074042320251466, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1660000, "num_agent_steps_sampled": 3320000, "num_steps_trained": 1660000, "num_agent_steps_trained": 3320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 163, "training_iteration": 83, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-17-45", "timestamp": 1704446265, "time_this_iter_s": 201.57324504852295, "time_total_s": 17000.78551864624, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF251160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 6960.970612049103, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 28.75508771929825, "ram_util_percent": 80.14035087719299}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.6268656716418, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -237.3134328358209}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2938005099471633, "mean_inference_ms": 1.3401835842185692, "mean_action_processing_ms": 0.0703849384304387, "mean_env_wait_ms": 9.060671314712271, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1680000, "timesteps_this_iter": 0, "agent_timesteps_total": 3360000, "timers": {"sample_time_ms": 200035.186, "sample_throughput": 99.982, "load_time_ms": 0.299, "load_throughput": 66846824.448, "learn_time_ms": 1098.398, "learn_throughput": 18208.335, "update_time_ms": 1.529}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 1e-10, "total_loss": 125.91689605712891, "policy_loss": -6.818461415534217e-05, "vf_loss": 125.94904174804688, "vf_explained_var": 0.02579120397567749, "kl": 6.065654997655656e-06, "entropy": 3.207388925552368, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1680000, "num_agent_steps_sampled": 3360000, "num_steps_trained": 1680000, "num_agent_steps_trained": 3360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 165, "training_iteration": 84, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-21-09", "timestamp": 1704446469, "time_this_iter_s": 203.94915103912354, "time_total_s": 17204.734669685364, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF0FCB80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7164.919763088226, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 30.558680555555554, "ram_util_percent": 79.59375}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -478.2608695652174, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -239.1304347826087}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29361257698153614, "mean_inference_ms": 1.3392499825681028, "mean_action_processing_ms": 0.07034785337306289, "mean_env_wait_ms": 9.052100573678993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1700000, "timesteps_this_iter": 0, "agent_timesteps_total": 3400000, "timers": {"sample_time_ms": 198943.171, "sample_throughput": 100.531, "load_time_ms": 0.302, "load_throughput": 66323592.663, "learn_time_ms": 1106.579, "learn_throughput": 18073.716, "update_time_ms": 1.631}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 1e-10, "total_loss": 96.95608825683594, "policy_loss": -3.0430764904032513e-05, "vf_loss": 96.98821868896485, "vf_explained_var": 0.03448153734207153, "kl": 1.3443590430095576e-05, "entropy": 3.2095062255859377, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1700000, "num_agent_steps_sampled": 3400000, "num_steps_trained": 1700000, "num_agent_steps_trained": 3400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 167, "training_iteration": 85, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-24-22", "timestamp": 1704446662, "time_this_iter_s": 192.16481637954712, "time_total_s": 17396.89948606491, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF246DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7357.084579467773, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 23.279411764705884, "ram_util_percent": 78.33713235294117}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -478.8732394366197, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -239.43661971830986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2934151460495942, "mean_inference_ms": 1.3382521525241267, "mean_action_processing_ms": 0.07030673086425879, "mean_env_wait_ms": 9.043408787991101, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1720000, "timesteps_this_iter": 0, "agent_timesteps_total": 3440000, "timers": {"sample_time_ms": 197691.019, "sample_throughput": 101.168, "load_time_ms": 0.251, "load_throughput": 79754782.278, "learn_time_ms": 1110.941, "learn_throughput": 18002.758, "update_time_ms": 1.632}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 1e-10, "total_loss": 137.01884765625, "policy_loss": -4.204998850809716e-05, "vf_loss": 137.0509490966797, "vf_explained_var": 0.03386965990066528, "kl": 9.269792526112042e-06, "entropy": 3.205603742599487, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1720000, "num_agent_steps_sampled": 3440000, "num_steps_trained": 1720000, "num_agent_steps_trained": 3440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 169, "training_iteration": 86, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-27-33", "timestamp": 1704446853, "time_this_iter_s": 191.0033438205719, "time_total_s": 17587.902829885483, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF3EE310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7548.087923288345, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 23.30925925925926, "ram_util_percent": 77.61148148148148}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -482.1917808219178, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -241.0958904109589}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -200.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.29320563750236084, "mean_inference_ms": 1.3372042942686977, "mean_action_processing_ms": 0.07026328679676427, "mean_env_wait_ms": 9.03469001375689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1740000, "timesteps_this_iter": 0, "agent_timesteps_total": 3480000, "timers": {"sample_time_ms": 196980.297, "sample_throughput": 101.533, "load_time_ms": 0.253, "load_throughput": 78907045.433, "learn_time_ms": 1118.081, "learn_throughput": 17887.797, "update_time_ms": 1.632}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 1e-10, "total_loss": 139.20319519042968, "policy_loss": -4.8281783355008655e-05, "vf_loss": 139.23531188964844, "vf_explained_var": 0.01679108142852783, "kl": 9.47558535799864e-06, "entropy": 3.207550811767578, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1740000, "num_agent_steps_sampled": 3480000, "num_steps_trained": 1740000, "num_agent_steps_trained": 3480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 171, "training_iteration": 87, "trial_id": "0feef_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_17-30-45", "timestamp": 1704447045, "time_this_iter_s": 192.36309480667114, "time_total_s": 17780.265924692154, "pid": 13632, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 1e-10, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 20, "checkpoint_end": true, "restore_path": {"model_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\checkpoint_000050\\checkpoint-50", "params_path": "D:\\projs\\MARLlib\\experiments\\mate\\exp_results\\mappo_mlp_MATE-4v2-9-v0\\MAPPOTrainer_mate_MATE-4v2-9-v0_41553_00000_0_2024-01-05_11-41-05\\params.json"}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x0000019EBF188B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 7740.4510180950165, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 23.435661764705884, "ram_util_percent": 77.7452205882353}}

{"episode_reward_max": -600.0, "episode_reward_min": -600.0, "episode_reward_mean": -600.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 1, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -300.0}, "policy_reward_mean": {"shared_policy": -300.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0], "episode_lengths": [10001], "policy_shared_policy_reward": [-300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1863516495767924, "mean_inference_ms": 0.9550538803778805, "mean_action_processing_ms": 0.055431169328984724, "mean_env_wait_ms": 7.356174850063344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20000, "timesteps_this_iter": 0, "agent_timesteps_total": 40000, "timers": {"sample_time_ms": 171497.739, "sample_throughput": 116.62, "load_time_ms": 1.022, "load_throughput": 19562985.075, "learn_time_ms": 942.343, "learn_throughput": 21223.7, "update_time_ms": 0.997}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.2, "cur_lr": 0.0005, "total_loss": 207.56344299316407, "policy_loss": -0.00010109146100933941, "vf_loss": 207.59571838378906, "vf_explained_var": 6.705522537231445e-05, "kl": 1.111296484110711e-05, "entropy": 3.2188528537750245, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 20000, "num_agent_steps_sampled": 40000, "num_steps_trained": 20000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 1, "training_iteration": 1, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-35-24", "timestamp": 1704418524, "time_this_iter_s": 172.40310049057007, "time_total_s": 172.40310049057007, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B97CB940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 172.40310049057007, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 26.766938775510205, "ram_util_percent": 43.65551020408163}}
{"episode_reward_max": -600.0, "episode_reward_min": -600.0, "episode_reward_mean": -600.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -300.0}, "policy_reward_mean": {"shared_policy": -300.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.20530708834231934, "mean_inference_ms": 1.0049844157362475, "mean_action_processing_ms": 0.057766077199297695, "mean_env_wait_ms": 7.537619322073028, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 40000, "timesteps_this_iter": 0, "agent_timesteps_total": 80000, "timers": {"sample_time_ms": 179539.719, "sample_throughput": 111.396, "load_time_ms": 0.775, "load_throughput": 25815073.088, "learn_time_ms": 1117.938, "learn_throughput": 17890.075, "update_time_ms": 1.243}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.1, "cur_lr": 0.0005, "total_loss": 124.11996307373047, "policy_loss": -4.419832203481633e-05, "vf_loss": 124.152197265625, "vf_explained_var": 0.00017145872116088867, "kl": 5.3850784167114306e-06, "entropy": 3.218807888031006, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 40000, "num_agent_steps_sampled": 80000, "num_steps_trained": 40000, "num_agent_steps_trained": 80000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3, "training_iteration": 2, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-38-32", "timestamp": 1704418712, "time_this_iter_s": 187.91228818893433, "time_total_s": 360.3153886795044, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9878040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 360.3153886795044, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 30.71842105263158, "ram_util_percent": 46.48233082706766}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -520.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -260.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.21581711362470682, "mean_inference_ms": 1.041753855024573, "mean_action_processing_ms": 0.05898225456633001, "mean_env_wait_ms": 7.649836671866204, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 60000, "timesteps_this_iter": 0, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 185332.99, "sample_throughput": 107.914, "load_time_ms": 0.683, "load_throughput": 29296651.921, "learn_time_ms": 1155.979, "learn_throughput": 17301.355, "update_time_ms": 1.324}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.05, "cur_lr": 0.0005, "total_loss": 149.20191345214843, "policy_loss": -3.502878158412326e-05, "vf_loss": 149.23414001464843, "vf_explained_var": 5.817413330078125e-05, "kl": 4.270144356932626e-06, "entropy": 3.218755674362183, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 120000, "num_steps_trained": 60000, "num_agent_steps_trained": 120000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 5, "training_iteration": 3, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-41-49", "timestamp": 1704418909, "time_this_iter_s": 196.8239870071411, "time_total_s": 557.1393756866455, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B99F2DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 557.1393756866455, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 38.26942446043165, "ram_util_percent": 70.75}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -514.2857142857143, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -257.14285714285717}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2252508171106735, "mean_inference_ms": 1.0777726718682048, "mean_action_processing_ms": 0.06051395908107816, "mean_env_wait_ms": 7.78099580344645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 80000, "timesteps_this_iter": 0, "agent_timesteps_total": 160000, "timers": {"sample_time_ms": 193113.873, "sample_throughput": 103.566, "load_time_ms": 0.642, "load_throughput": 31132336.24, "learn_time_ms": 1143.869, "learn_throughput": 17484.517, "update_time_ms": 1.365}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.025, "cur_lr": 0.0005, "total_loss": 153.6326141357422, "policy_loss": -5.924803685743996e-05, "vf_loss": 153.66484680175782, "vf_explained_var": 0.0003836870193481445, "kl": 4.581969524186658e-06, "entropy": 3.2187376022338867, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 80000, "num_agent_steps_sampled": 160000, "num_steps_trained": 80000, "num_agent_steps_trained": 160000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 7, "training_iteration": 4, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-45-25", "timestamp": 1704419125, "time_this_iter_s": 216.30402493476868, "time_total_s": 773.4434006214142, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B99F21F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 773.4434006214142, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 34.38333333333333, "ram_util_percent": 81.80718954248366}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -511.1111111111111, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -255.55555555555554}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23132688610889263, "mean_inference_ms": 1.0996649897563362, "mean_action_processing_ms": 0.06138822656481743, "mean_env_wait_ms": 7.859058575410431, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 100000, "timesteps_this_iter": 0, "agent_timesteps_total": 200000, "timers": {"sample_time_ms": 193875.762, "sample_throughput": 103.159, "load_time_ms": 0.514, "load_throughput": 38915420.301, "learn_time_ms": 1134.029, "learn_throughput": 17636.228, "update_time_ms": 1.291}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0125, "cur_lr": 0.0005, "total_loss": 82.95169830322266, "policy_loss": -3.2291459442390646e-05, "vf_loss": 82.98391418457031, "vf_explained_var": 0.00028839111328125, "kl": 3.588106429492158e-06, "entropy": 3.2186904430389403, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 100000, "num_agent_steps_sampled": 200000, "num_steps_trained": 100000, "num_agent_steps_trained": 200000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 9, "training_iteration": 5, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-48-42", "timestamp": 1704419322, "time_this_iter_s": 196.88317799568176, "time_total_s": 970.326578617096, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A03A60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 970.326578617096, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 27.893525179856113, "ram_util_percent": 80.48884892086332}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -509.09090909090907, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -254.54545454545453}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23626664732318375, "mean_inference_ms": 1.1174130062091867, "mean_action_processing_ms": 0.06211997889199769, "mean_env_wait_ms": 7.924205420656725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 120000, "timesteps_this_iter": 0, "agent_timesteps_total": 240000, "timers": {"sample_time_ms": 196172.855, "sample_throughput": 101.951, "load_time_ms": 0.511, "load_throughput": 39135096.804, "learn_time_ms": 1148.219, "learn_throughput": 17418.284, "update_time_ms": 1.323}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00625, "cur_lr": 0.0005, "total_loss": 103.65235595703125, "policy_loss": -6.408805841463667e-05, "vf_loss": 103.68460083007812, "vf_explained_var": 0.0007422924041748047, "kl": 5.2802826537079465e-06, "entropy": 3.2186371803283693, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 120000, "num_agent_steps_sampled": 240000, "num_steps_trained": 120000, "num_agent_steps_trained": 240000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 11, "training_iteration": 6, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-52-10", "timestamp": 1704419530, "time_this_iter_s": 207.75582075119019, "time_total_s": 1178.0823993682861, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B97AB940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1178.0823993682861, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 31.0656462585034, "ram_util_percent": 79.13707482993196}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -492.3076923076923, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -246.15384615384616}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24014649917238276, "mean_inference_ms": 1.1314157992930631, "mean_action_processing_ms": 0.06265452546221667, "mean_env_wait_ms": 7.9769319406857715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 140000, "timesteps_this_iter": 0, "agent_timesteps_total": 280000, "timers": {"sample_time_ms": 197488.498, "sample_throughput": 101.272, "load_time_ms": 0.438, "load_throughput": 45657612.938, "learn_time_ms": 1137.097, "learn_throughput": 17588.649, "update_time_ms": 1.489}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.003125, "cur_lr": 0.0005, "total_loss": 133.52969360351562, "policy_loss": -2.5114707675832902e-05, "vf_loss": 133.56190185546876, "vf_explained_var": 0.00038853883743286135, "kl": 6.272221933367739e-06, "entropy": 3.2185086250305175, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 140000, "num_agent_steps_sampled": 280000, "num_steps_trained": 140000, "num_agent_steps_trained": 280000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 13, "training_iteration": 7, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-55-35", "timestamp": 1704419735, "time_this_iter_s": 205.20811891555786, "time_total_s": 1383.290518283844, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B99FF9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1383.290518283844, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 30.070689655172412, "ram_util_percent": 78.66103448275864}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -493.3333333333333, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -246.66666666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24277046544493172, "mean_inference_ms": 1.1405429419928232, "mean_action_processing_ms": 0.06299097745793202, "mean_env_wait_ms": 8.011822265024124, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 160000, "timesteps_this_iter": 0, "agent_timesteps_total": 320000, "timers": {"sample_time_ms": 196715.015, "sample_throughput": 101.67, "load_time_ms": 0.445, "load_throughput": 44909900.288, "learn_time_ms": 1124.233, "learn_throughput": 17789.906, "update_time_ms": 1.423}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0015625, "cur_lr": 0.0005, "total_loss": 85.96575164794922, "policy_loss": -8.924026584811173e-06, "vf_loss": 85.9979476928711, "vf_explained_var": 0.0004493951797485352, "kl": 4.295225555495108e-06, "entropy": 3.218664836883545, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 160000, "num_agent_steps_sampled": 320000, "num_steps_trained": 160000, "num_agent_steps_trained": 320000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 15, "training_iteration": 8, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_09-58-46", "timestamp": 1704419926, "time_this_iter_s": 191.23507118225098, "time_total_s": 1574.525589466095, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A03310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1574.525589466095, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 23.684814814814814, "ram_util_percent": 77.55925925925926}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -482.3529411764706, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -241.1764705882353}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24482238727368244, "mean_inference_ms": 1.1480788594977278, "mean_action_processing_ms": 0.06325991698726097, "mean_env_wait_ms": 8.039402575882074, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 180000, "timesteps_this_iter": 0, "agent_timesteps_total": 360000, "timers": {"sample_time_ms": 196978.628, "sample_throughput": 101.534, "load_time_ms": 0.506, "load_throughput": 39512991.05, "learn_time_ms": 1152.751, "learn_throughput": 17349.801, "update_time_ms": 1.427}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.00078125, "cur_lr": 0.0005, "total_loss": 99.33707427978516, "policy_loss": -1.9164848526997958e-05, "vf_loss": 99.36927642822266, "vf_explained_var": 0.00046466588973999025, "kl": 4.661101625413888e-06, "entropy": 3.218553066253662, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 180000, "num_agent_steps_sampled": 360000, "num_steps_trained": 180000, "num_agent_steps_trained": 360000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 17, "training_iteration": 9, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-02-06", "timestamp": 1704420126, "time_this_iter_s": 199.41200423240662, "time_total_s": 1773.9375936985016, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B983D700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1773.9375936985016, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 28.106028368794327, "ram_util_percent": 76.30673758865248}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -473.6842105263158, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -236.8421052631579}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24662592138374578, "mean_inference_ms": 1.1543036999420666, "mean_action_processing_ms": 0.06348286937987345, "mean_env_wait_ms": 8.06144170734858, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 200000, "timesteps_this_iter": 0, "agent_timesteps_total": 400000, "timers": {"sample_time_ms": 197157.104, "sample_throughput": 101.442, "load_time_ms": 0.508, "load_throughput": 39377590.011, "learn_time_ms": 1148.23, "learn_throughput": 17418.118, "update_time_ms": 1.433}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.000390625, "cur_lr": 0.0005, "total_loss": 115.74707794189453, "policy_loss": -3.8134039921544624e-05, "vf_loss": 115.77930603027343, "vf_explained_var": 0.0002451658248901367, "kl": 4.463255726326956e-06, "entropy": 3.218463087081909, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 200000, "num_agent_steps_sampled": 400000, "num_steps_trained": 200000, "num_agent_steps_trained": 400000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 19, "training_iteration": 10, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-05-24", "timestamp": 1704420324, "time_this_iter_s": 198.4570541381836, "time_total_s": 1972.3946478366852, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B98635E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1972.3946478366852, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 26.923131672597865, "ram_util_percent": 75.77010676156584}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -476.1904761904762, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -238.0952380952381}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24815722339956847, "mean_inference_ms": 1.1597740352595256, "mean_action_processing_ms": 0.06368429604784984, "mean_env_wait_ms": 8.080865039985868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 220000, "timesteps_this_iter": 0, "agent_timesteps_total": 440000, "timers": {"sample_time_ms": 200219.007, "sample_throughput": 99.891, "load_time_ms": 0.406, "load_throughput": 49301251.837, "learn_time_ms": 1206.366, "learn_throughput": 16578.716, "update_time_ms": 1.681}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.0001953125, "cur_lr": 0.0005, "total_loss": 116.73458709716797, "policy_loss": -4.3857507664135655e-05, "vf_loss": 116.76681671142578, "vf_explained_var": 0.0010924816131591796, "kl": 3.523552584477896e-06, "entropy": 3.2184624671936035, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 220000, "num_agent_steps_sampled": 440000, "num_steps_trained": 220000, "num_agent_steps_trained": 440000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 21, "training_iteration": 11, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-08-47", "timestamp": 1704420527, "time_this_iter_s": 202.50970029830933, "time_total_s": 2174.9043481349945, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9863E50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2174.9043481349945, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 28.34335664335665, "ram_util_percent": 75.42412587412588}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -469.5652173913044, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -234.7826086956522}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24952514834170134, "mean_inference_ms": 1.164861357180739, "mean_action_processing_ms": 0.06389190191416236, "mean_env_wait_ms": 8.098384172956544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 240000, "timesteps_this_iter": 0, "agent_timesteps_total": 480000, "timers": {"sample_time_ms": 201876.249, "sample_throughput": 99.071, "load_time_ms": 0.402, "load_throughput": 49692601.149, "learn_time_ms": 1180.924, "learn_throughput": 16935.884, "update_time_ms": 1.631}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.765625e-05, "cur_lr": 0.0005, "total_loss": 88.08983764648437, "policy_loss": -1.4604940398932343e-05, "vf_loss": 88.12204284667969, "vf_explained_var": 0.000633072853088379, "kl": 3.7046385394444435e-06, "entropy": 3.2185752391815186, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 240000, "num_agent_steps_sampled": 480000, "num_steps_trained": 240000, "num_agent_steps_trained": 480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 23, "training_iteration": 12, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-12-11", "timestamp": 1704420731, "time_this_iter_s": 203.61762237548828, "time_total_s": 2378.521970510483, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9814040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2378.521970510483, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 30.84479166666667, "ram_util_percent": 75.03020833333333}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -472.0, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -236.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.250672849899859, "mean_inference_ms": 1.1692028556753977, "mean_action_processing_ms": 0.06407864863527067, "mean_env_wait_ms": 8.112936320317088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 260000, "timesteps_this_iter": 0, "agent_timesteps_total": 520000, "timers": {"sample_time_ms": 201965.749, "sample_throughput": 99.027, "load_time_ms": 0.402, "load_throughput": 49719108.582, "learn_time_ms": 1176.96, "learn_throughput": 16992.932, "update_time_ms": 1.727}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 0.0005, "total_loss": 111.87057189941406, "policy_loss": -2.6877509013283756e-05, "vf_loss": 111.90277709960938, "vf_explained_var": 0.001175236701965332, "kl": 3.4268369295986647e-06, "entropy": 3.218503999710083, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 260000, "num_agent_steps_sampled": 520000, "num_steps_trained": 260000, "num_agent_steps_trained": 520000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 25, "training_iteration": 13, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-15-28", "timestamp": 1704420928, "time_this_iter_s": 197.94809365272522, "time_total_s": 2576.470064163208, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A101F0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2576.470064163208, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 28.347142857142856, "ram_util_percent": 75.40357142857142}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -474.0740740740741, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -237.03703703703704}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.251723108829346, "mean_inference_ms": 1.1730696474657887, "mean_action_processing_ms": 0.06424643581716616, "mean_env_wait_ms": 8.125715000067412, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 280000, "timesteps_this_iter": 0, "agent_timesteps_total": 560000, "timers": {"sample_time_ms": 200381.494, "sample_throughput": 99.81, "load_time_ms": 0.35, "load_throughput": 57127540.18, "learn_time_ms": 1172.201, "learn_throughput": 17061.922, "update_time_ms": 1.727}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 0.0005, "total_loss": 119.13286437988282, "policy_loss": -2.75972083667142e-05, "vf_loss": 119.16507873535156, "vf_explained_var": 0.0007071375846862793, "kl": 3.4490751386728745e-06, "entropy": 3.2183087348937987, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 280000, "num_agent_steps_sampled": 560000, "num_steps_trained": 280000, "num_agent_steps_trained": 560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 27, "training_iteration": 14, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-18-49", "timestamp": 1704421129, "time_this_iter_s": 200.44588327407837, "time_total_s": 2776.9159474372864, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A0F9D0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2776.9159474372864, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 28.4362676056338, "ram_util_percent": 76.32077464788732}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -475.86206896551727, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -237.93103448275863}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2528038042773255, "mean_inference_ms": 1.1770987794074537, "mean_action_processing_ms": 0.0644100160518629, "mean_env_wait_ms": 8.138442958368802, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 300000, "timesteps_this_iter": 0, "agent_timesteps_total": 600000, "timers": {"sample_time_ms": 201651.23, "sample_throughput": 99.181, "load_time_ms": 0.4, "load_throughput": 50039417.8, "learn_time_ms": 1168.781, "learn_throughput": 17111.842, "update_time_ms": 1.774}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 0.0005, "total_loss": 115.02005767822266, "policy_loss": -4.915012312993739e-05, "vf_loss": 115.05228881835937, "vf_explained_var": 0.0019644498825073242, "kl": 4.553439744015009e-06, "entropy": 3.218251132965088, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 300000, "num_agent_steps_sampled": 600000, "num_steps_trained": 300000, "num_agent_steps_trained": 600000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 29, "training_iteration": 15, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-22-19", "timestamp": 1704421339, "time_this_iter_s": 209.59597897529602, "time_total_s": 2986.5119264125824, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A03310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 2986.5119264125824, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 32.88986486486487, "ram_util_percent": 76.54864864864865}}
{"episode_reward_max": -400.0, "episode_reward_min": -600.0, "episode_reward_mean": -483.8709677419355, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -200.0}, "policy_reward_mean": {"shared_policy": -241.93548387096774}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2537170880297236, "mean_inference_ms": 1.1805499607060566, "mean_action_processing_ms": 0.06454749756623497, "mean_env_wait_ms": 8.149090290479336, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 320000, "timesteps_this_iter": 0, "agent_timesteps_total": 640000, "timers": {"sample_time_ms": 200523.652, "sample_throughput": 99.739, "load_time_ms": 0.4, "load_throughput": 50045388.378, "learn_time_ms": 1150.928, "learn_throughput": 17377.28, "update_time_ms": 1.724}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 0.0005, "total_loss": 173.82366027832032, "policy_loss": -4.425500873761479e-05, "vf_loss": 173.8558776855469, "vf_explained_var": 0.00041501522064208985, "kl": 5.694199087180607e-06, "entropy": 3.2181907176971434, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 320000, "num_agent_steps_sampled": 640000, "num_steps_trained": 320000, "num_agent_steps_trained": 640000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 31, "training_iteration": 16, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-25-35", "timestamp": 1704421535, "time_this_iter_s": 196.33799576759338, "time_total_s": 3182.849922180176, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B96A7DC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3182.849922180176, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 27.05162454873646, "ram_util_percent": 76.30072202166065}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -478.7878787878788, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -239.3939393939394}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2545069320261473, "mean_inference_ms": 1.1836273471910599, "mean_action_processing_ms": 0.06466719825837557, "mean_env_wait_ms": 8.158291670664294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 340000, "timesteps_this_iter": 0, "agent_timesteps_total": 680000, "timers": {"sample_time_ms": 199800.904, "sample_throughput": 100.1, "load_time_ms": 0.4, "load_throughput": 50045388.378, "learn_time_ms": 1156.93, "learn_throughput": 17287.135, "update_time_ms": 1.575}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 0.0005, "total_loss": 155.67696533203124, "policy_loss": -3.967645745257542e-05, "vf_loss": 155.70918884277344, "vf_explained_var": 0.0008949756622314454, "kl": 6.718812463413215e-06, "entropy": 3.218251276016235, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 340000, "num_agent_steps_sampled": 680000, "num_steps_trained": 340000, "num_agent_steps_trained": 680000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 33, "training_iteration": 17, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-28-53", "timestamp": 1704421733, "time_this_iter_s": 198.21766710281372, "time_total_s": 3381.0675892829895, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B97623A0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3381.0675892829895, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 28.39786476868327, "ram_util_percent": 76.18505338078292}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -485.7142857142857, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -242.85714285714286}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25519582379523414, "mean_inference_ms": 1.1862805462545274, "mean_action_processing_ms": 0.06476579265644451, "mean_env_wait_ms": 8.166336195526858, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 360000, "timesteps_this_iter": 0, "agent_timesteps_total": 720000, "timers": {"sample_time_ms": 200435.204, "sample_throughput": 99.783, "load_time_ms": 0.4, "load_throughput": 50042402.911, "learn_time_ms": 1160.746, "learn_throughput": 17230.296, "update_time_ms": 1.627}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 0.0005, "total_loss": 107.87366027832032, "policy_loss": -6.30237954447388e-05, "vf_loss": 107.9059066772461, "vf_explained_var": 0.0009748339653015137, "kl": 8.118316983463103e-06, "entropy": 3.2182895660400392, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 360000, "num_agent_steps_sampled": 720000, "num_steps_trained": 360000, "num_agent_steps_trained": 720000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 35, "training_iteration": 18, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-32-11", "timestamp": 1704421931, "time_this_iter_s": 197.5560429096222, "time_total_s": 3578.6236321926117, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B97FFA60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3578.6236321926117, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 27.755913978494622, "ram_util_percent": 76.14802867383511}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -481.0810810810811, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -240.54054054054055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25584568015252607, "mean_inference_ms": 1.1887251391871112, "mean_action_processing_ms": 0.06485903810509132, "mean_env_wait_ms": 8.173796664638425, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 380000, "timesteps_this_iter": 0, "agent_timesteps_total": 760000, "timers": {"sample_time_ms": 200688.314, "sample_throughput": 99.657, "load_time_ms": 0.35, "load_throughput": 57150892.492, "learn_time_ms": 1128.305, "learn_throughput": 17725.71, "update_time_ms": 1.683}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 0.0005, "total_loss": 131.96209716796875, "policy_loss": -3.230991372169534e-05, "vf_loss": 131.9943115234375, "vf_explained_var": 0.0014638900756835938, "kl": 5.745891192704411e-06, "entropy": 3.21803994178772, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 380000, "num_agent_steps_sampled": 760000, "num_steps_trained": 380000, "num_agent_steps_trained": 760000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 37, "training_iteration": 19, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-35-32", "timestamp": 1704422132, "time_this_iter_s": 201.57181072235107, "time_total_s": 3780.1954429149628, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B97FFDC0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3780.1954429149628, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 29.11438596491228, "ram_util_percent": 76.74842105263158}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -482.05128205128204, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -241.02564102564102}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25639820777754313, "mean_inference_ms": 1.190788911524806, "mean_action_processing_ms": 0.06493335322813547, "mean_env_wait_ms": 8.180292420856773, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 400000, "timesteps_this_iter": 0, "agent_timesteps_total": 800000, "timers": {"sample_time_ms": 200412.717, "sample_throughput": 99.794, "load_time_ms": 0.347, "load_throughput": 57586380.174, "learn_time_ms": 1121.564, "learn_throughput": 17832.236, "update_time_ms": 1.681}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 0.0005, "total_loss": 110.49062957763672, "policy_loss": -2.528833428172561e-05, "vf_loss": 110.52283782958985, "vf_explained_var": 0.0018018841743469237, "kl": 7.073368243837308e-06, "entropy": 3.2181575298309326, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 400000, "num_agent_steps_sampled": 800000, "num_steps_trained": 400000, "num_agent_steps_trained": 800000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 39, "training_iteration": 20, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-38-48", "timestamp": 1704422328, "time_this_iter_s": 195.9644627571106, "time_total_s": 3976.1599056720734, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A0C5E0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 3976.1599056720734, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 25.912635379061374, "ram_util_percent": 76.73574007220216}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -487.8048780487805, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -243.90243902439025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25688486068637867, "mean_inference_ms": 1.1926456869530777, "mean_action_processing_ms": 0.06499858791044488, "mean_env_wait_ms": 8.186107666491948, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 420000, "timesteps_this_iter": 0, "agent_timesteps_total": 840000, "timers": {"sample_time_ms": 200017.981, "sample_throughput": 99.991, "load_time_ms": 0.347, "load_throughput": 57586380.174, "learn_time_ms": 1088.98, "learn_throughput": 18365.81, "update_time_ms": 1.479}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 0.0005, "total_loss": 98.00875091552734, "policy_loss": -3.901206032024263e-05, "vf_loss": 98.040966796875, "vf_explained_var": 0.0017111063003540038, "kl": 5.018375949550347e-06, "entropy": 3.218026638031006, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 420000, "num_agent_steps_sampled": 840000, "num_steps_trained": 420000, "num_agent_steps_trained": 840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 41, "training_iteration": 21, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-42-07", "timestamp": 1704422527, "time_this_iter_s": 198.28789591789246, "time_total_s": 4174.447801589966, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A03B80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4174.447801589966, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 27.53964285714286, "ram_util_percent": 76.47535714285713}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -488.3720930232558, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.1860465116279}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2573616889508234, "mean_inference_ms": 1.1945002895146473, "mean_action_processing_ms": 0.06506497881474789, "mean_env_wait_ms": 8.191782720870094, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 440000, "timesteps_this_iter": 0, "agent_timesteps_total": 880000, "timers": {"sample_time_ms": 200070.734, "sample_throughput": 99.965, "load_time_ms": 0.347, "load_throughput": 57566620.917, "learn_time_ms": 1124.645, "learn_throughput": 17783.391, "update_time_ms": 1.576}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 0.0005, "total_loss": 120.9737533569336, "policy_loss": -3.856773328765328e-05, "vf_loss": 121.00597229003907, "vf_explained_var": 0.0031258106231689454, "kl": 4.748605575222164e-06, "entropy": 3.217552995681763, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 440000, "num_agent_steps_sampled": 880000, "num_steps_trained": 440000, "num_agent_steps_trained": 880000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 43, "training_iteration": 22, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-45-32", "timestamp": 1704422732, "time_this_iter_s": 204.8536388874054, "time_total_s": 4379.301440477371, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B96F3EE0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4379.301440477371, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 31.00931034482759, "ram_util_percent": 76.64379310344827}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -488.8888888888889, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.44444444444446}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25780706223411, "mean_inference_ms": 1.1962303145060118, "mean_action_processing_ms": 0.0651270943600792, "mean_env_wait_ms": 8.197164625323925, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 460000, "timesteps_this_iter": 0, "agent_timesteps_total": 920000, "timers": {"sample_time_ms": 200494.701, "sample_throughput": 99.753, "load_time_ms": 0.347, "load_throughput": 57570571.683, "learn_time_ms": 1113.383, "learn_throughput": 17963.278, "update_time_ms": 1.48}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 0.0005, "total_loss": 95.22677307128906, "policy_loss": -6.880998701097596e-06, "vf_loss": 95.25895538330079, "vf_explained_var": 0.004039788246154785, "kl": 7.886399973727753e-06, "entropy": 3.2176601886749268, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 460000, "num_agent_steps_sampled": 920000, "num_steps_trained": 460000, "num_agent_steps_trained": 920000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 45, "training_iteration": 23, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-48-53", "timestamp": 1704422933, "time_this_iter_s": 201.71046805381775, "time_total_s": 4581.011908531189, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B952A430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4581.011908531189, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 29.687017543859646, "ram_util_percent": 76.85894736842106}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -489.36170212765956, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.68085106382978}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.25822454851531773, "mean_inference_ms": 1.1977819747258274, "mean_action_processing_ms": 0.06518351230661773, "mean_env_wait_ms": 8.201960976362903, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 480000, "timesteps_this_iter": 0, "agent_timesteps_total": 960000, "timers": {"sample_time_ms": 200177.478, "sample_throughput": 99.911, "load_time_ms": 0.397, "load_throughput": 50379004.264, "learn_time_ms": 1123.404, "learn_throughput": 17803.028, "update_time_ms": 1.527}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 0.0005, "total_loss": 149.14800109863282, "policy_loss": -2.6281137697825586e-05, "vf_loss": 149.18020935058593, "vf_explained_var": 0.004383885860443115, "kl": 3.564934898209193e-06, "entropy": 3.2176652908325196, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 480000, "num_agent_steps_sampled": 960000, "num_steps_trained": 480000, "num_agent_steps_trained": 960000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 47, "training_iteration": 24, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-52-11", "timestamp": 1704423131, "time_this_iter_s": 197.50167393684387, "time_total_s": 4778.513582468033, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B983D700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4778.513582468033, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 27.361648745519712, "ram_util_percent": 76.19318996415771}}
{"episode_reward_max": -200.0, "episode_reward_min": -600.0, "episode_reward_mean": -489.7959183673469, "episode_len_mean": 10001.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"shared_policy": -300.0}, "policy_reward_max": {"shared_policy": -100.0}, "policy_reward_mean": {"shared_policy": -244.89795918367346}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-600.0, -600.0, -600.0, -400.0, -400.0, -600.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -400.0, -400.0, -400.0, -600.0, -400.0, -400.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0, -600.0, -600.0, -600.0, -200.0, -600.0, -600.0, -400.0, -400.0, -400.0, -600.0, -600.0, -600.0, -400.0, -600.0, -400.0, -600.0, -400.0, -600.0, -600.0, -400.0], "episode_lengths": [10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001, 10001], "policy_shared_policy_reward": [-300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -100.0, -100.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -200.0, -200.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -200.0, -200.0, -300.0, -300.0, -300.0, -300.0, -200.0, -200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2586350143276134, "mean_inference_ms": 1.1992528403283453, "mean_action_processing_ms": 0.06524046259448431, "mean_env_wait_ms": 8.206589505821066, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 500000, "timesteps_this_iter": 0, "agent_timesteps_total": 1000000, "timers": {"sample_time_ms": 199501.882, "sample_throughput": 100.25, "load_time_ms": 0.397, "load_throughput": 50388082.653, "learn_time_ms": 1138.032, "learn_throughput": 17574.199, "update_time_ms": 1.577}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 0.0005, "total_loss": 85.6128158569336, "policy_loss": -2.0680694394836775e-05, "vf_loss": 85.64501342773437, "vf_explained_var": 0.003868544101715088, "kl": 3.6582227329995385e-06, "entropy": 3.2177454948425295, "entropy_coeff": 0.01}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 500000, "num_agent_steps_sampled": 1000000, "num_steps_trained": 500000, "num_agent_steps_trained": 1000000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 49, "training_iteration": 25, "trial_id": "45c19_00000", "experiment_id": "21a42826982943e18dfdcdb4cf7e69e5", "date": "2024-01-05_10-55-34", "timestamp": 1704423334, "time_this_iter_s": 202.86565709114075, "time_total_s": 4981.379239559174, "pid": 2212, "hostname": "DESKTOP-CC49RT1", "node_ip": "127.0.0.1", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 20000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "mate", "env_args": {"continuous_actions_camera": false, "continuous_actions_target": false, "discrete_levels": 5, "coop_team": "target", "map_name": "MATE-4v2-9-v0"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": false, "force_coop": true, "local_mode": false, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 1, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 10, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64, "encode_layer": "8-8"}, "algorithm": "mappo", "space_obs": "Dict(obs:Box([ 0.e+00  0.e+00  0.e+00  0.e+00 -2.e+03 -2.e+03 -2.e+03 -2.e+03 -2.e+03\n -2.e+03 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00  0.e+00\n  1.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -1.e+00 -1.e+00 -1.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00\n -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03\n -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03\n  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -2.e+03 -2.e+03  0.e+00 -1.e+00 -1.e+00 -2.e+03 -2.e+03  0.e+00\n -1.e+00 -1.e+00], [    inf     inf     inf     inf 2.0e+03 2.0e+03 2.0e+03 2.0e+03 2.0e+03\n 2.0e+03 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 2.0e+03 1.0e+00 2.0e+03\n 2.0e+00     inf     inf     inf     inf 1.0e+00 1.0e+00 1.0e+00 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 2.0e+03 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03\n 2.0e+03 1.8e+02 1.0e+00 2.0e+03 2.0e+03 1.0e+03 2.0e+03 2.0e+03 1.8e+02\n 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00\n 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03\n 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03\n 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03 1.0e+00 2.0e+03 2.0e+03 1.0e+03\n 1.0e+00 2.0e+03 2.0e+03 2.0e+03 1.0e+00 1.0e+00 2.0e+03 2.0e+03 2.0e+03\n 1.0e+00 1.0e+00], (101,), float64))", "space_act": "Discrete(25)", "num_agents": 2, "episode_limit": 2000, "policy_mapping_info": {"all_scenario": {"description": "mate single team multi-agent scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "mate_MATE-4v2-9-v0", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.MAPPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x00000220B9A0CCA0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 20000, "shuffle_sequences": true, "num_sgd_iter": 5, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 4981.379239559174, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 30.322299651567945, "ram_util_percent": 76.3630662020906}}
